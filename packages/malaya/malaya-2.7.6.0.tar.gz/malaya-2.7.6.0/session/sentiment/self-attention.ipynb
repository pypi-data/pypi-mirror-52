{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import collections\n",
    "from sklearn import metrics\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from unidecode import unidecode\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import malaya"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = malaya.preprocessing._SocialTokenizer().tokenize\n",
    "rules_normalizer = malaya.texts._tatabahasa.rules_normalizer\n",
    "\n",
    "def is_number_regex(s):\n",
    "    if re.match(\"^\\d+?\\.\\d+?$\", s) is None:\n",
    "        return s.isdigit()\n",
    "    return True\n",
    "\n",
    "def detect_money(word):\n",
    "    if word[:2] == 'rm' and is_number_regex(word[2:]):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def preprocessing(string):\n",
    "    tokenized = tokenizer(unidecode(string))\n",
    "    tokenized = [malaya.stem.naive(w) for w in tokenized]\n",
    "    tokenized = [w.lower() for w in tokenized if len(w) > 1]\n",
    "    tokenized = [rules_normalizer.get(w, w) for w in tokenized]\n",
    "    tokenized = ['<NUM>' if is_number_regex(w) else w for w in tokenized]\n",
    "    tokenized = ['<MONEY>' if detect_money(w) else w for w in tokenized]\n",
    "    return tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataset(words, n_words):\n",
    "    count = [['GO', 0], ['PAD', 1], ['EOS', 2], ['UNK', 3]]\n",
    "    counter = collections.Counter(words).most_common(n_words)\n",
    "    count.extend(counter)\n",
    "    dictionary = dict()\n",
    "    for word, _ in count:\n",
    "        dictionary[word] = len(dictionary)\n",
    "    data = list()\n",
    "    unk_count = 0\n",
    "    for word in words:\n",
    "        index = dictionary.get(word, 3)\n",
    "        if index == 0:\n",
    "            unk_count += 1\n",
    "        data.append(index)\n",
    "    count[0][1] = unk_count\n",
    "    reversed_dictionary = dict(zip(dictionary.values(), dictionary.keys()))\n",
    "    return data, count, dictionary, reversed_dictionary\n",
    "\n",
    "def str_idx(corpus, dic, maxlen, UNK = 3):\n",
    "    X = np.zeros((len(corpus), maxlen))\n",
    "    for i in range(len(corpus)):\n",
    "        for no, k in enumerate(corpus[i][:maxlen][::-1]):\n",
    "            X[i, -1 - no] = dic.get(k, UNK)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['raja',\n",
       " 'benar',\n",
       " 'sangat',\n",
       " 'benci',\n",
       " 'rakyat',\n",
       " 'minyak',\n",
       " 'naik',\n",
       " 'gala',\n",
       " 'jadi']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessing('kerajaan sebenarnya sangat bencikan rakyatnya, minyak naik dan segalanya jd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('tokenization.json') as fopen:\n",
    "    dataset = json.load(fopen)\n",
    "texts = dataset['texts']\n",
    "labels = dataset['labels']\n",
    "del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('sentiment-dictionary.json') as fopen:\n",
    "    d = json.load(fopen)\n",
    "dictionary = d['dictionary']\n",
    "rev_dictionary = d['reverse_dictionary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def position_encoding(inputs):\n",
    "    T = tf.shape(inputs)[1]\n",
    "    repr_dim = inputs.get_shape()[-1].value\n",
    "    pos = tf.reshape(tf.range(0.0, tf.to_float(T), dtype=tf.float32), [-1, 1])\n",
    "    i = np.arange(0, repr_dim, 2, np.float32)\n",
    "    denom = np.reshape(np.power(10000.0, i / repr_dim), [1, -1])\n",
    "    enc = tf.expand_dims(tf.concat([tf.sin(pos / denom), tf.cos(pos / denom)], 1), 0)\n",
    "    return tf.tile(enc, [tf.shape(inputs)[0], 1, 1])\n",
    "\n",
    "def layer_norm(inputs, epsilon=1e-8):\n",
    "    mean, variance = tf.nn.moments(inputs, [-1], keep_dims=True)\n",
    "    normalized = (inputs - mean) / (tf.sqrt(variance + epsilon))\n",
    "    params_shape = inputs.get_shape()[-1:]\n",
    "    gamma = tf.get_variable('gamma', params_shape, tf.float32, tf.ones_initializer())\n",
    "    beta = tf.get_variable('beta', params_shape, tf.float32, tf.zeros_initializer())\n",
    "    return gamma * normalized + beta\n",
    "\n",
    "def Attention(inputs, num_units, num_heads = 8, activation = None):\n",
    "    inputs = tf.layers.dropout(inputs, 0.3, training=True)\n",
    "    T_q = T_k = tf.shape(inputs)[1]\n",
    "    Q_K_V = tf.layers.dense(inputs, 3*num_units, activation)\n",
    "    Q, K, V = tf.split(Q_K_V, 3, -1)\n",
    "    Q_ = tf.concat(tf.split(Q, num_heads, axis=2), 0)\n",
    "    K_ = tf.concat(tf.split(K, num_heads, axis=2), 0)\n",
    "    V_ = tf.concat(tf.split(V, num_heads, axis=2), 0)\n",
    "    align = tf.matmul(Q_, K_, transpose_b=True)\n",
    "    align *= tf.rsqrt(tf.to_float(K_.get_shape()[-1].value))\n",
    "    paddings = tf.fill(tf.shape(align), float('-inf'))\n",
    "    lower_tri = tf.ones([T_q, T_k])\n",
    "    lower_tri = tf.linalg.LinearOperatorLowerTriangular(lower_tri).to_dense()\n",
    "    masks = tf.tile(tf.expand_dims(lower_tri,0), [tf.shape(align)[0],1,1])\n",
    "    align = tf.where(tf.equal(masks, 0), paddings, align)\n",
    "    align = tf.nn.softmax(align)\n",
    "    alignments = tf.transpose(align, [0, 2, 1]) \n",
    "    x = tf.matmul(align, V_)\n",
    "    x = tf.concat(tf.split(x, num_heads, axis=0), 2)\n",
    "    x += inputs\n",
    "    x = layer_norm(x)\n",
    "    return x, alignments\n",
    "\n",
    "class Model:\n",
    "    def __init__(self, size_layer, embed_size, dict_size, dimension_output, learning_rate = 1e-3):\n",
    "        self.X = tf.placeholder(tf.int32, [None, None])\n",
    "        self.Y = tf.placeholder(tf.int32, [None])\n",
    "        \n",
    "        encoder_embeddings = tf.Variable(tf.random_uniform([dict_size, embed_size], -1, 1))\n",
    "        x = tf.nn.embedding_lookup(encoder_embeddings, self.X)\n",
    "        x += position_encoding(x)\n",
    "        x = tf.layers.dropout(x, 0.3, training=True) \n",
    "        \n",
    "        x, self.alignments = Attention(x, size_layer)\n",
    "        self.logits_seq = tf.layers.dense(x, dimension_output)\n",
    "        self.logits_seq = tf.identity(self.logits_seq, name = 'logits_seq')\n",
    "        self.logits = self.logits_seq[:,-1]\n",
    "        self.logits = tf.identity(self.logits, name = 'logits')\n",
    "\n",
    "        self.cost = tf.reduce_mean(\n",
    "            tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "                logits = self.logits, labels = self.Y\n",
    "            )\n",
    "        )\n",
    "        self.optimizer = tf.train.AdamOptimizer(learning_rate).minimize(\n",
    "            self.cost\n",
    "        )\n",
    "        correct_pred = tf.equal(\n",
    "            tf.argmax(self.logits, 1, output_type = tf.int32), self.Y\n",
    "        )\n",
    "        self.accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "        self.attention = tf.identity(tf.reduce_mean(self.alignments[0], 1), name = 'alphas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'only-attention/model.ckpt'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size_layer = 256\n",
    "dimension_output = 2\n",
    "learning_rate = 1e-4\n",
    "batch_size = 32\n",
    "maxlen = 100\n",
    "\n",
    "tf.reset_default_graph()\n",
    "sess = tf.InteractiveSession()\n",
    "model = Model(\n",
    "    size_layer,\n",
    "    size_layer,\n",
    "    len(dictionary),\n",
    "    dimension_output,\n",
    "    learning_rate,\n",
    ")\n",
    "sess.run(tf.global_variables_initializer())\n",
    "saver = tf.train.Saver(tf.trainable_variables())\n",
    "saver.save(sess, 'only-attention/model.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "strings = ','.join(\n",
    "    [\n",
    "        n.name\n",
    "        for n in tf.get_default_graph().as_graph_def().node\n",
    "        if ('Variable' in n.op\n",
    "        or 'Placeholder' in n.name\n",
    "        or 'logits' in n.name\n",
    "        or 'alphas' in n.name)\n",
    "        and 'Adam' not in n.name\n",
    "        and '_power' not in n.name\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Placeholder',\n",
       " 'Placeholder_1',\n",
       " 'Variable',\n",
       " 'dense/kernel',\n",
       " 'dense/bias',\n",
       " 'gamma',\n",
       " 'beta',\n",
       " 'dense_1/kernel',\n",
       " 'dense_1/bias',\n",
       " 'logits_seq',\n",
       " 'logits',\n",
       " 'alphas']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strings.split(',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'Variable:0' shape=(124794, 256) dtype=float32_ref>,\n",
       " <tf.Variable 'dense/kernel:0' shape=(256, 768) dtype=float32_ref>,\n",
       " <tf.Variable 'dense/bias:0' shape=(768,) dtype=float32_ref>,\n",
       " <tf.Variable 'gamma:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'beta:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'dense_1/kernel:0' shape=(256, 2) dtype=float32_ref>,\n",
       " <tf.Variable 'dense_1/bias:0' shape=(2,) dtype=float32_ref>]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.trainable_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, test_X, train_Y, test_Y = train_test_split(\n",
    "    texts, labels, test_size = 0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train minibatch loop: 100%|██████████| 16876/16876 [13:57<00:00, 20.14it/s, accuracy=0.833, cost=0.42] \n",
      "test minibatch loop: 100%|██████████| 4219/4219 [00:35<00:00, 118.07it/s, accuracy=0.724, cost=0.549]\n",
      "train minibatch loop:   0%|          | 3/16876 [00:00<13:58, 20.12it/s, accuracy=0.594, cost=0.601]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, pass acc: 0.000000, current acc: 0.715723\n",
      "time taken: 873.6518127918243\n",
      "epoch: 0, training loss: 0.595912, training acc: 0.675681, valid loss: 0.551319, valid acc: 0.715723\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train minibatch loop: 100%|██████████| 16876/16876 [13:57<00:00, 20.15it/s, accuracy=0.778, cost=0.419]\n",
      "test minibatch loop: 100%|██████████| 4219/4219 [00:35<00:00, 118.83it/s, accuracy=0.724, cost=0.492]\n",
      "train minibatch loop:   0%|          | 3/16876 [00:00<14:01, 20.06it/s, accuracy=0.719, cost=0.49] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1, pass acc: 0.715723, current acc: 0.737070\n",
      "time taken: 872.8621339797974\n",
      "epoch: 1, training loss: 0.538746, training acc: 0.726348, valid loss: 0.524194, valid acc: 0.737070\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train minibatch loop: 100%|██████████| 16876/16876 [13:57<00:00, 20.15it/s, accuracy=0.944, cost=0.335]\n",
      "test minibatch loop: 100%|██████████| 4219/4219 [00:35<00:00, 118.67it/s, accuracy=0.759, cost=0.437]\n",
      "train minibatch loop:   0%|          | 3/16876 [00:00<13:59, 20.10it/s, accuracy=0.75, cost=0.524] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2, pass acc: 0.737070, current acc: 0.747819\n",
      "time taken: 872.872700214386\n",
      "epoch: 2, training loss: 0.516308, training acc: 0.743540, valid loss: 0.508608, valid acc: 0.747819\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train minibatch loop: 100%|██████████| 16876/16876 [13:57<00:00, 20.46it/s, accuracy=0.944, cost=0.29] \n",
      "test minibatch loop: 100%|██████████| 4219/4219 [00:35<00:00, 118.83it/s, accuracy=0.759, cost=0.447]\n",
      "train minibatch loop:   0%|          | 2/16876 [00:00<14:38, 19.22it/s, accuracy=0.906, cost=0.394]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3, pass acc: 0.747819, current acc: 0.753670\n",
      "time taken: 872.786773443222\n",
      "epoch: 3, training loss: 0.503027, training acc: 0.753103, valid loss: 0.500447, valid acc: 0.753670\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train minibatch loop: 100%|██████████| 16876/16876 [13:57<00:00, 20.15it/s, accuracy=0.833, cost=0.332]\n",
      "test minibatch loop: 100%|██████████| 4219/4219 [00:35<00:00, 118.86it/s, accuracy=0.828, cost=0.436]\n",
      "train minibatch loop:   0%|          | 3/16876 [00:00<13:56, 20.17it/s, accuracy=0.844, cost=0.389]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4, pass acc: 0.753670, current acc: 0.759175\n",
      "time taken: 872.8474028110504\n",
      "epoch: 4, training loss: 0.494213, training acc: 0.759081, valid loss: 0.493601, valid acc: 0.759175\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train minibatch loop: 100%|██████████| 16876/16876 [13:57<00:00, 20.44it/s, accuracy=0.833, cost=0.341]\n",
      "test minibatch loop: 100%|██████████| 4219/4219 [00:35<00:00, 118.63it/s, accuracy=0.759, cost=0.447]\n",
      "train minibatch loop:   0%|          | 3/16876 [00:00<13:58, 20.12it/s, accuracy=0.75, cost=0.478] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 5, pass acc: 0.759175, current acc: 0.763107\n",
      "time taken: 873.0266923904419\n",
      "epoch: 5, training loss: 0.487159, training acc: 0.764167, valid loss: 0.487517, valid acc: 0.763107\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train minibatch loop: 100%|██████████| 16876/16876 [13:57<00:00, 20.15it/s, accuracy=0.833, cost=0.305]\n",
      "test minibatch loop: 100%|██████████| 4219/4219 [00:35<00:00, 118.87it/s, accuracy=0.759, cost=0.44] \n",
      "train minibatch loop:   0%|          | 3/16876 [00:00<13:58, 20.13it/s, accuracy=0.906, cost=0.404]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 6, pass acc: 0.763107, current acc: 0.764522\n",
      "time taken: 872.9059422016144\n",
      "epoch: 6, training loss: 0.481288, training acc: 0.767570, valid loss: 0.484200, valid acc: 0.764522\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train minibatch loop: 100%|██████████| 16876/16876 [13:57<00:00, 20.15it/s, accuracy=0.944, cost=0.254]\n",
      "test minibatch loop: 100%|██████████| 4219/4219 [00:35<00:00, 118.72it/s, accuracy=0.69, cost=0.49]  \n",
      "train minibatch loop:   0%|          | 3/16876 [00:00<13:57, 20.14it/s, accuracy=0.75, cost=0.421] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 7, pass acc: 0.764522, current acc: 0.768298\n",
      "time taken: 872.9461388587952\n",
      "epoch: 7, training loss: 0.476970, training acc: 0.770630, valid loss: 0.480285, valid acc: 0.768298\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train minibatch loop: 100%|██████████| 16876/16876 [13:57<00:00, 20.15it/s, accuracy=0.944, cost=0.238]\n",
      "test minibatch loop: 100%|██████████| 4219/4219 [00:35<00:00, 118.74it/s, accuracy=0.759, cost=0.447]\n",
      "train minibatch loop:   0%|          | 3/16876 [00:00<13:56, 20.18it/s, accuracy=0.812, cost=0.419]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 8, pass acc: 0.768298, current acc: 0.769396\n",
      "time taken: 873.0376634597778\n",
      "epoch: 8, training loss: 0.473226, training acc: 0.772856, valid loss: 0.477995, valid acc: 0.769396\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train minibatch loop: 100%|██████████| 16876/16876 [13:57<00:00, 20.15it/s, accuracy=0.944, cost=0.293]\n",
      "test minibatch loop: 100%|██████████| 4219/4219 [00:35<00:00, 118.68it/s, accuracy=0.828, cost=0.422]\n",
      "train minibatch loop:   0%|          | 3/16876 [00:00<14:00, 20.08it/s, accuracy=0.875, cost=0.35]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 9, pass acc: 0.769396, current acc: 0.770027\n",
      "time taken: 873.0693907737732\n",
      "epoch: 9, training loss: 0.469894, training acc: 0.774875, valid loss: 0.475846, valid acc: 0.770027\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train minibatch loop: 100%|██████████| 16876/16876 [13:57<00:00, 20.15it/s, accuracy=0.944, cost=0.269]\n",
      "test minibatch loop: 100%|██████████| 4219/4219 [00:35<00:00, 118.65it/s, accuracy=0.655, cost=0.495]\n",
      "train minibatch loop:   0%|          | 3/16876 [00:00<13:55, 20.19it/s, accuracy=0.844, cost=0.391]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 10, pass acc: 0.770027, current acc: 0.770912\n",
      "time taken: 873.1026468276978\n",
      "epoch: 10, training loss: 0.466412, training acc: 0.777606, valid loss: 0.474340, valid acc: 0.770912\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train minibatch loop: 100%|██████████| 16876/16876 [13:57<00:00, 20.43it/s, accuracy=0.889, cost=0.301]\n",
      "test minibatch loop: 100%|██████████| 4219/4219 [00:35<00:00, 118.63it/s, accuracy=0.828, cost=0.427]\n",
      "train minibatch loop:   0%|          | 3/16876 [00:00<13:54, 20.23it/s, accuracy=0.812, cost=0.41] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 11, pass acc: 0.770912, current acc: 0.771190\n",
      "time taken: 873.1505410671234\n",
      "epoch: 11, training loss: 0.463504, training acc: 0.779456, valid loss: 0.474276, valid acc: 0.771190\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train minibatch loop: 100%|██████████| 16876/16876 [13:57<00:00, 20.44it/s, accuracy=0.944, cost=0.228]\n",
      "test minibatch loop: 100%|██████████| 4219/4219 [00:35<00:00, 118.84it/s, accuracy=0.724, cost=0.424]\n",
      "train minibatch loop:   0%|          | 3/16876 [00:00<13:55, 20.20it/s, accuracy=0.812, cost=0.437]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 12, pass acc: 0.771190, current acc: 0.773262\n",
      "time taken: 873.0738255977631\n",
      "epoch: 12, training loss: 0.461311, training acc: 0.780315, valid loss: 0.471637, valid acc: 0.773262\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train minibatch loop: 100%|██████████| 16876/16876 [13:57<00:00, 20.15it/s, accuracy=0.944, cost=0.244]\n",
      "test minibatch loop: 100%|██████████| 4219/4219 [00:35<00:00, 118.80it/s, accuracy=0.793, cost=0.419]\n",
      "train minibatch loop:   0%|          | 3/16876 [00:00<13:55, 20.21it/s, accuracy=0.812, cost=0.389]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 13, pass acc: 0.773262, current acc: 0.774974\n",
      "time taken: 873.0719096660614\n",
      "epoch: 13, training loss: 0.458761, training acc: 0.782322, valid loss: 0.469102, valid acc: 0.774974\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train minibatch loop: 100%|██████████| 16876/16876 [13:57<00:00, 20.15it/s, accuracy=0.944, cost=0.232]\n",
      "test minibatch loop: 100%|██████████| 4219/4219 [00:35<00:00, 118.58it/s, accuracy=0.793, cost=0.393]\n",
      "train minibatch loop:   0%|          | 3/16876 [00:00<13:56, 20.18it/s, accuracy=0.781, cost=0.448]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken: 873.2016248703003\n",
      "epoch: 14, training loss: 0.456533, training acc: 0.783382, valid loss: 0.469040, valid acc: 0.773382\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train minibatch loop: 100%|██████████| 16876/16876 [13:57<00:00, 20.15it/s, accuracy=1, cost=0.257]    \n",
      "test minibatch loop: 100%|██████████| 4219/4219 [00:35<00:00, 118.64it/s, accuracy=0.724, cost=0.475]\n",
      "train minibatch loop:   0%|          | 3/16876 [00:00<13:53, 20.24it/s, accuracy=0.75, cost=0.446] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 15, pass acc: 0.774974, current acc: 0.775913\n",
      "time taken: 873.0704691410065\n",
      "epoch: 15, training loss: 0.453938, training acc: 0.784770, valid loss: 0.468686, valid acc: 0.775913\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train minibatch loop: 100%|██████████| 16876/16876 [13:57<00:00, 20.15it/s, accuracy=1, cost=0.221]    \n",
      "test minibatch loop: 100%|██████████| 4219/4219 [00:35<00:00, 118.76it/s, accuracy=0.724, cost=0.448]\n",
      "train minibatch loop:   0%|          | 3/16876 [00:00<13:55, 20.20it/s, accuracy=0.844, cost=0.366]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken: 873.0411856174469\n",
      "epoch: 16, training loss: 0.452284, training acc: 0.786289, valid loss: 0.466593, valid acc: 0.775839\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train minibatch loop: 100%|██████████| 16876/16876 [13:57<00:00, 20.15it/s, accuracy=1, cost=0.224]    \n",
      "test minibatch loop: 100%|██████████| 4219/4219 [00:35<00:00, 118.62it/s, accuracy=0.759, cost=0.431]\n",
      "train minibatch loop:   0%|          | 2/16876 [00:00<14:11, 19.81it/s, accuracy=0.844, cost=0.343]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 17, pass acc: 0.775913, current acc: 0.776062\n",
      "time taken: 873.122752904892\n",
      "epoch: 17, training loss: 0.451134, training acc: 0.786990, valid loss: 0.467707, valid acc: 0.776062\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train minibatch loop: 100%|██████████| 16876/16876 [13:57<00:00, 20.15it/s, accuracy=1, cost=0.218]    \n",
      "test minibatch loop: 100%|██████████| 4219/4219 [00:35<00:00, 118.65it/s, accuracy=0.724, cost=0.463]\n",
      "train minibatch loop:   0%|          | 3/16876 [00:00<13:55, 20.19it/s, accuracy=0.844, cost=0.364]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 18, pass acc: 0.776062, current acc: 0.776773\n",
      "time taken: 873.0830545425415\n",
      "epoch: 18, training loss: 0.448639, training acc: 0.788359, valid loss: 0.467222, valid acc: 0.776773\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train minibatch loop: 100%|██████████| 16876/16876 [13:57<00:00, 20.15it/s, accuracy=1, cost=0.22]     \n",
      "test minibatch loop: 100%|██████████| 4219/4219 [00:35<00:00, 118.44it/s, accuracy=0.724, cost=0.422]\n",
      "train minibatch loop:   0%|          | 3/16876 [00:00<13:54, 20.21it/s, accuracy=0.938, cost=0.347]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 19, pass acc: 0.776773, current acc: 0.776832\n",
      "time taken: 873.164381980896\n",
      "epoch: 19, training loss: 0.447150, training acc: 0.789168, valid loss: 0.466600, valid acc: 0.776832\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train minibatch loop: 100%|██████████| 16876/16876 [13:57<00:00, 20.15it/s, accuracy=0.889, cost=0.257]\n",
      "test minibatch loop: 100%|██████████| 4219/4219 [00:35<00:00, 118.68it/s, accuracy=0.724, cost=0.431]\n",
      "train minibatch loop:   0%|          | 3/16876 [00:00<13:59, 20.09it/s, accuracy=0.812, cost=0.388]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 20, pass acc: 0.776832, current acc: 0.777884\n",
      "time taken: 873.1035535335541\n",
      "epoch: 20, training loss: 0.445555, training acc: 0.790610, valid loss: 0.465082, valid acc: 0.777884\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train minibatch loop: 100%|██████████| 16876/16876 [13:57<00:00, 20.15it/s, accuracy=0.944, cost=0.213]\n",
      "test minibatch loop: 100%|██████████| 4219/4219 [00:35<00:00, 118.73it/s, accuracy=0.724, cost=0.44] \n",
      "train minibatch loop:   0%|          | 3/16876 [00:00<13:54, 20.21it/s, accuracy=0.812, cost=0.429]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken: 873.0824906826019\n",
      "epoch: 21, training loss: 0.444026, training acc: 0.791076, valid loss: 0.464617, valid acc: 0.777632\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train minibatch loop: 100%|██████████| 16876/16876 [13:57<00:00, 20.44it/s, accuracy=1, cost=0.231]    \n",
      "test minibatch loop: 100%|██████████| 4219/4219 [00:35<00:00, 118.90it/s, accuracy=0.759, cost=0.431]\n",
      "train minibatch loop:   0%|          | 3/16876 [00:00<13:55, 20.19it/s, accuracy=0.844, cost=0.366]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 22, pass acc: 0.777884, current acc: 0.778025\n",
      "time taken: 873.1131408214569\n",
      "epoch: 22, training loss: 0.442452, training acc: 0.791935, valid loss: 0.464123, valid acc: 0.778025\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train minibatch loop: 100%|██████████| 16876/16876 [13:57<00:00, 20.15it/s, accuracy=0.944, cost=0.28] \n",
      "test minibatch loop: 100%|██████████| 4219/4219 [00:35<00:00, 118.59it/s, accuracy=0.655, cost=0.534]\n",
      "train minibatch loop:   0%|          | 3/16876 [00:00<13:59, 20.11it/s, accuracy=0.781, cost=0.428]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 23, pass acc: 0.778025, current acc: 0.778756\n",
      "time taken: 873.0947358608246\n",
      "epoch: 23, training loss: 0.441143, training acc: 0.792680, valid loss: 0.463258, valid acc: 0.778756\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train minibatch loop: 100%|██████████| 16876/16876 [13:57<00:00, 20.15it/s, accuracy=0.944, cost=0.253]\n",
      "test minibatch loop: 100%|██████████| 4219/4219 [00:35<00:00, 118.73it/s, accuracy=0.793, cost=0.455]\n",
      "train minibatch loop:   0%|          | 3/16876 [00:00<13:55, 20.19it/s, accuracy=0.875, cost=0.367]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 24, pass acc: 0.778756, current acc: 0.778967\n",
      "time taken: 873.1105782985687\n",
      "epoch: 24, training loss: 0.439897, training acc: 0.793989, valid loss: 0.462837, valid acc: 0.778967\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train minibatch loop: 100%|██████████| 16876/16876 [13:57<00:00, 20.15it/s, accuracy=0.889, cost=0.249]\n",
      "test minibatch loop: 100%|██████████| 4219/4219 [00:35<00:00, 118.60it/s, accuracy=0.724, cost=0.513]\n",
      "train minibatch loop:   0%|          | 3/16876 [00:00<14:02, 20.03it/s, accuracy=0.844, cost=0.428]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken: 873.0930559635162\n",
      "epoch: 25, training loss: 0.438801, training acc: 0.794719, valid loss: 0.463401, valid acc: 0.778084\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train minibatch loop: 100%|██████████| 16876/16876 [13:57<00:00, 20.15it/s, accuracy=0.889, cost=0.272]\n",
      "test minibatch loop:  51%|█████     | 2152/4219 [00:18<00:17, 118.44it/s, accuracy=0.812, cost=0.469]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "train minibatch loop:  67%|██████▋   | 11315/16876 [09:21<04:35, 20.15it/s, accuracy=0.781, cost=0.481]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "test minibatch loop:  99%|█████████▉| 4176/4219 [00:34<00:00, 120.00it/s, accuracy=0.875, cost=0.301]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "EARLY_STOPPING, CURRENT_CHECKPOINT, CURRENT_ACC, EPOCH = 3, 0, 0, 0\n",
    "\n",
    "while True:\n",
    "    lasttime = time.time()\n",
    "    if CURRENT_CHECKPOINT == EARLY_STOPPING:\n",
    "        print('break epoch:%d\\n' % (EPOCH))\n",
    "        break\n",
    "\n",
    "    train_acc, train_loss, test_acc, test_loss = 0, 0, 0, 0\n",
    "    pbar = tqdm(\n",
    "        range(0, len(train_X), batch_size), desc = 'train minibatch loop'\n",
    "    )\n",
    "    for i in pbar:\n",
    "        batch_x = str_idx(train_X[i : min(i + batch_size, len(train_X))], dictionary, maxlen)\n",
    "        batch_y = train_Y[i : min(i + batch_size, len(train_X))]\n",
    "        batch_x_expand = np.expand_dims(batch_x,axis = 1)\n",
    "        acc, cost, _ = sess.run(\n",
    "            [model.accuracy, model.cost, model.optimizer],\n",
    "            feed_dict = {\n",
    "                model.Y: batch_y,\n",
    "                model.X: batch_x\n",
    "            },\n",
    "        )\n",
    "        assert not np.isnan(cost)\n",
    "        train_loss += cost\n",
    "        train_acc += acc\n",
    "        pbar.set_postfix(cost = cost, accuracy = acc)\n",
    "\n",
    "    pbar = tqdm(range(0, len(test_X), batch_size), desc = 'test minibatch loop')\n",
    "    for i in pbar:\n",
    "        batch_x = str_idx(test_X[i : min(i + batch_size, len(test_X))], dictionary, maxlen)\n",
    "        batch_y = test_Y[i : min(i + batch_size, len(test_X))]\n",
    "        batch_x_expand = np.expand_dims(batch_x,axis = 1)\n",
    "        acc, cost = sess.run(\n",
    "            [model.accuracy, model.cost],\n",
    "            feed_dict = {\n",
    "                model.Y: batch_y,\n",
    "                model.X: batch_x\n",
    "            },\n",
    "        )\n",
    "        test_loss += cost\n",
    "        test_acc += acc\n",
    "        pbar.set_postfix(cost = cost, accuracy = acc)\n",
    "\n",
    "    train_loss /= len(train_X) / batch_size\n",
    "    train_acc /= len(train_X) / batch_size\n",
    "    test_loss /= len(test_X) / batch_size\n",
    "    test_acc /= len(test_X) / batch_size\n",
    "\n",
    "    if test_acc > CURRENT_ACC:\n",
    "        print(\n",
    "            'epoch: %d, pass acc: %f, current acc: %f'\n",
    "            % (EPOCH, CURRENT_ACC, test_acc)\n",
    "        )\n",
    "        CURRENT_ACC = test_acc\n",
    "        CURRENT_CHECKPOINT = 0\n",
    "    else:\n",
    "        CURRENT_CHECKPOINT += 1\n",
    "        \n",
    "    print('time taken:', time.time() - lasttime)\n",
    "    print(\n",
    "        'epoch: %d, training loss: %f, training acc: %f, valid loss: %f, valid acc: %f\\n'\n",
    "        % (EPOCH, train_loss, train_acc, test_loss, test_acc)\n",
    "    )\n",
    "    EPOCH += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'only-attention/model.ckpt'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saver.save(sess, 'only-attention/model.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.83869356, 0.16130647]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = preprocessing('kerajaan sebenarnya sangat bencikan rakyatnya, minyak naik dan segalanya')\n",
    "new_vector = str_idx([text], dictionary, len(text))\n",
    "sess.run(tf.nn.softmax(model.logits), feed_dict={model.X:new_vector})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[[0.04035725, 0.95964277],\n",
       "         [0.3335168 , 0.66648316],\n",
       "         [0.5767256 , 0.42327443],\n",
       "         [0.988713  , 0.01128694],\n",
       "         [0.8683654 , 0.13163453],\n",
       "         [0.867992  , 0.13200802],\n",
       "         [0.99281424, 0.00718583],\n",
       "         [0.9350784 , 0.06492158]]], dtype=float32),\n",
       " array([2.8282857e-01, 5.0085597e-02, 1.7758933e-01, 4.7541022e-01,\n",
       "        7.7311522e-03, 1.9795415e-03, 3.9819553e-03, 3.9367162e-04],\n",
       "       dtype=float32)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = preprocessing('kerajaan sebenarnya sangat bencikan rakyatnya, minyak naik dan segalanya')\n",
    "new_vector = str_idx([text], dictionary, len(text))\n",
    "sess.run([tf.nn.softmax(model.logits_seq), model.attention], feed_dict={model.X:new_vector})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "validation minibatch loop: 100%|██████████| 4219/4219 [00:30<00:00, 139.05it/s]\n"
     ]
    }
   ],
   "source": [
    "real_Y, predict_Y = [], []\n",
    "\n",
    "pbar = tqdm(\n",
    "    range(0, len(test_X), batch_size), desc = 'validation minibatch loop'\n",
    ")\n",
    "for i in pbar:\n",
    "    batch_x = str_idx(test_X[i : min(i + batch_size, len(test_X))], dictionary, maxlen)\n",
    "    batch_y = test_Y[i : min(i + batch_size, len(test_X))]\n",
    "    predict_Y += np.argmax(\n",
    "        sess.run(\n",
    "            model.logits, feed_dict = {model.X: batch_x, model.Y: batch_y}\n",
    "        ),\n",
    "        1,\n",
    "    ).tolist()\n",
    "    real_Y += batch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "   negative       0.77      0.82      0.80     70708\n",
      "   positive       0.79      0.74      0.76     64297\n",
      "\n",
      "avg / total       0.78      0.78      0.78    135005\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    metrics.classification_report(\n",
    "        real_Y, predict_Y, target_names = ['negative', 'positive']\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freeze_graph(model_dir, output_node_names):\n",
    "\n",
    "    if not tf.gfile.Exists(model_dir):\n",
    "        raise AssertionError(\n",
    "            \"Export directory doesn't exists. Please specify an export \"\n",
    "            'directory: %s' % model_dir\n",
    "        )\n",
    "\n",
    "    checkpoint = tf.train.get_checkpoint_state(model_dir)\n",
    "    input_checkpoint = checkpoint.model_checkpoint_path\n",
    "\n",
    "    absolute_model_dir = '/'.join(input_checkpoint.split('/')[:-1])\n",
    "    output_graph = absolute_model_dir + '/frozen_model.pb'\n",
    "    clear_devices = True\n",
    "    with tf.Session(graph = tf.Graph()) as sess:\n",
    "        saver = tf.train.import_meta_graph(\n",
    "            input_checkpoint + '.meta', clear_devices = clear_devices\n",
    "        )\n",
    "        saver.restore(sess, input_checkpoint)\n",
    "        output_graph_def = tf.graph_util.convert_variables_to_constants(\n",
    "            sess,\n",
    "            tf.get_default_graph().as_graph_def(),\n",
    "            output_node_names.split(','),\n",
    "        )\n",
    "        with tf.gfile.GFile(output_graph, 'wb') as f:\n",
    "            f.write(output_graph_def.SerializeToString())\n",
    "        print('%d ops in the final graph.' % len(output_graph_def.node))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from only-attention/model.ckpt\n",
      "INFO:tensorflow:Froze 7 variables.\n",
      "INFO:tensorflow:Converted 7 variables to const ops.\n",
      "248 ops in the final graph.\n"
     ]
    }
   ],
   "source": [
    "freeze_graph('only-attention', strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_graph(frozen_graph_filename):\n",
    "    with tf.gfile.GFile(frozen_graph_filename, 'rb') as f:\n",
    "        graph_def = tf.GraphDef()\n",
    "        graph_def.ParseFromString(f.read())\n",
    "    with tf.Graph().as_default() as graph:\n",
    "        tf.import_graph_def(graph_def)\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = load_graph('only-attention/frozen_model.pb')\n",
    "x = g.get_tensor_by_name('import/Placeholder:0')\n",
    "logits_seq = g.get_tensor_by_name('import/logits_seq:0')\n",
    "logits = g.get_tensor_by_name('import/logits:0')\n",
    "alphas = g.get_tensor_by_name('import/alphas:0')\n",
    "test_sess = tf.InteractiveSession(graph = g)\n",
    "result = test_sess.run([logits, alphas, logits_seq], feed_dict = {x: new_vector})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_string = 'Kerajaan juga perlu prihatin dan peka terhadap nasib para nelayan yang bergantung rezeki sepenuhnya kepada sumber hasil laut. Malah, projek ini memberikan kesan buruk yang berpanjangan kepada alam sekitar selain menjejaskan mata pencarian para nelayan'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = preprocessing(news_string)\n",
    "new_vector = str_idx([text], dictionary, len(text))\n",
    "result = test_sess.run([tf.nn.softmax(logits), alphas, tf.nn.softmax(logits_seq)], feed_dict = {x: new_vector})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (15, 7))\n",
    "labels = [word for word in text]\n",
    "val = [val for val in result[1]]\n",
    "plt.bar(np.arange(len(labels)), val)\n",
    "plt.xticks(np.arange(len(labels)), labels, rotation = 'vertical')\n",
    "plt.title('negative %f positive %f' % (result[0][0,0], result[0][0,1]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
