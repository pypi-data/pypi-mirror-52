{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('gsd-ud-train.conllu.txt') as fopen:\n",
    "    corpus = fopen.read().split('\\n')\n",
    "    \n",
    "with open('gsd-ud-test.conllu.txt') as fopen:\n",
    "    corpus.extend(fopen.read().split('\\n'))\n",
    "    \n",
    "with open('gsd-ud-dev.conllu.txt') as fopen:\n",
    "    corpus.extend(fopen.read().split('\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_string(string):\n",
    "    string = re.sub('[^A-Za-z0-9\\-\\/ ]+', ' ', string).split()\n",
    "    return [to_title(y.strip()) for y in string]\n",
    "\n",
    "def to_title(string):\n",
    "    if string.isupper():\n",
    "        string = string.title()\n",
    "    return string\n",
    "\n",
    "def process_corpus(corpus, until = None):\n",
    "    sentences, words, depends, labels = [], [], [], []\n",
    "    temp_sentence, temp_word, temp_depend, temp_label = [], [], [], []\n",
    "    for sentence in corpus:\n",
    "        if len(sentence):\n",
    "            if sentence[0] == '#':\n",
    "                continue\n",
    "            sentence = sentence.split('\\t')\n",
    "            temp = process_string(sentence[1])\n",
    "            if not len(temp):\n",
    "                sentence[1] = 'EMPTY'\n",
    "            sentence[1] = process_string(sentence[1])[0]\n",
    "            temp_word.append(sentence[1])\n",
    "            temp_depend.append(str(int(sentence[6])))\n",
    "            temp_label.append(sentence[7])\n",
    "            temp_sentence.append(sentence[1])\n",
    "        else:\n",
    "            words.append(temp_word)\n",
    "            depends.append(temp_depend)\n",
    "            labels.append(temp_label)\n",
    "            sentences.append(temp_sentence)\n",
    "            temp_word = []\n",
    "            temp_depend = []\n",
    "            temp_label = []\n",
    "            temp_sentence = []\n",
    "    return sentences[:-1], words[:-1], depends[:-1], labels[:-1]\n",
    "\n",
    "sentences, words, depends, labels = process_corpus(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx2tag = {0: 'PAD',\n",
    " 1: 'nsubj',\n",
    " 2: 'cop',\n",
    " 3: 'det',\n",
    " 4: 'root',\n",
    " 5: 'nsubj:pass',\n",
    " 6: 'acl',\n",
    " 7: 'case',\n",
    " 8: 'obl',\n",
    " 9: 'flat',\n",
    " 10: 'punct',\n",
    " 11: 'appos',\n",
    " 12: 'amod',\n",
    " 13: 'compound',\n",
    " 14: 'advmod',\n",
    " 15: 'cc',\n",
    " 16: 'obj',\n",
    " 17: 'conj',\n",
    " 18: 'mark',\n",
    " 19: 'advcl',\n",
    " 20: 'nmod',\n",
    " 21: 'nummod',\n",
    " 22: 'dep',\n",
    " 23: 'xcomp',\n",
    " 24: 'ccomp',\n",
    " 25: 'parataxis',\n",
    " 26: 'compound:plur',\n",
    " 27: 'fixed',\n",
    " 28: 'aux',\n",
    " 29: 'csubj',\n",
    " 30: 'iobj',\n",
    " 31: 'csubj:pass'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['4',\n",
       " '4',\n",
       " '4',\n",
       " '0',\n",
       " '6',\n",
       " '4',\n",
       " '8',\n",
       " '6',\n",
       " '8',\n",
       " '8',\n",
       " '8',\n",
       " '11',\n",
       " '11',\n",
       " '11',\n",
       " '14',\n",
       " '14',\n",
       " '14',\n",
       " '4']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "depends[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Sembungan',\n",
       " 'adalah',\n",
       " 'sebuah',\n",
       " 'desa',\n",
       " 'yang',\n",
       " 'terletak',\n",
       " 'di',\n",
       " 'kecamatan',\n",
       " 'Kejajar',\n",
       " 'Empty',\n",
       " 'kabupaten',\n",
       " 'Wonosobo',\n",
       " 'Empty',\n",
       " 'Jawa',\n",
       " 'Tengah',\n",
       " 'Empty',\n",
       " 'Indonesia',\n",
       " 'Empty']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('augmented-dependency.json') as fopen:\n",
    "    augmented = json.load(fopen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_X(texts):\n",
    "    sentences = []\n",
    "    for no, text in enumerate(texts):\n",
    "        s = process_string(text)\n",
    "        sentences.append(s)\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_augmented = []\n",
    "for a in augmented:\n",
    "    text_augmented.extend(a[0])\n",
    "    depends.extend([list(map(str, i)) for i in a[1]])\n",
    "    u = []\n",
    "    for i in a[2]:\n",
    "        u.append([idx2tag[a] for a in i])\n",
    "    labels.extend(u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_sentences = parse_X(text_augmented)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "words.extend(new_sentences)\n",
    "sentences.extend(new_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50365, 50365, 50365, 50365)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words), len(depends), len(labels), len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tag.util import untag\n",
    "\n",
    "def features(sentence, index):\n",
    "    \"\"\" sentence: [w1, w2, ...], index: the index of the word \"\"\"\n",
    "    return {\n",
    "        'word': sentence[index],\n",
    "        'is_first': index == 0,\n",
    "        'is_last': index == len(sentence) - 1,\n",
    "        'prefix-1': sentence[index][0],\n",
    "        'prefix-2': sentence[index][:2],\n",
    "        'prefix-3': sentence[index][:3],\n",
    "        'suffix-1': sentence[index][-1],\n",
    "        'suffix-2': sentence[index][-2:],\n",
    "        'suffix-3': sentence[index][-3:],\n",
    "        'prev_word': '' if index == 0 else sentence[index - 1],\n",
    "        'prev_word-prefix-1': '' if index == 0 else sentence[index - 1][0],\n",
    "        'prev_word-prefix-2': '' if index == 0 else sentence[index - 1][:2],\n",
    "        'prev_word-prefix-3': '' if index == 0 else sentence[index - 1][:3],\n",
    "        'prev_word-suffix-1': '' if index == 0 else sentence[index - 1][-1],\n",
    "        'prev_word-suffix-2': '' if index == 0 else sentence[index - 1][-2:],\n",
    "        'prev_word-suffix-3': '' if index == 0 else sentence[index - 1][-3:],\n",
    "        'next_word-prefix-1': '' if index == len(sentence) - 1 else sentence[index + 1][0],\n",
    "        'next_word-prefix-2': '' if index == len(sentence) - 1 else sentence[index + 1][:2],\n",
    "        'next_word-prefix-3': '' if index == len(sentence) - 1 else sentence[index + 1][:3],\n",
    "        'next_word-suffix-1': '' if index == len(sentence) - 1 else sentence[index + 1][-1],\n",
    "        'next_word-suffix-2': '' if index == len(sentence) - 1 else sentence[index + 1][-2:],\n",
    "        'next_word-suffix-3': '' if index == len(sentence) - 1 else sentence[index + 1][-3:],\n",
    "        'next_word': '' if index == len(sentence) - 1 else sentence[index + 1],\n",
    "        'has_hyphen': '-' in sentence[index],\n",
    "        'is_numeric': sentence[index].isdigit(),\n",
    "    }\n",
    "\n",
    "def features_crf_dependency(sentence, tag, index):\n",
    "    return {\n",
    "        'word': sentence[index],\n",
    "        'tag': tag[index],\n",
    "        'is_first': index == 0,\n",
    "        'is_last': index == len(sentence) - 1,\n",
    "        'prefix-1': sentence[index][0],\n",
    "        'prefix-2': sentence[index][:2],\n",
    "        'prefix-3': sentence[index][:3],\n",
    "        'suffix-1': sentence[index][-1],\n",
    "        'suffix-2': sentence[index][-2:],\n",
    "        'suffix-3': sentence[index][-3:],\n",
    "        'prev_word': '' if index == 0 else sentence[index - 1],\n",
    "        'prev_word-prefix-1': '' if index == 0 else sentence[index - 1][0],\n",
    "        'prev_word-prefix-2': '' if index == 0 else sentence[index - 1][:2],\n",
    "        'prev_word-prefix-3': '' if index == 0 else sentence[index - 1][:3],\n",
    "        'prev_word-suffix-1': '' if index == 0 else sentence[index - 1][-1],\n",
    "        'prev_word-suffix-2': '' if index == 0 else sentence[index - 1][-2:],\n",
    "        'prev_word-suffix-3': '' if index == 0 else sentence[index - 1][-3:],\n",
    "        'next_word-prefix-1': ''\n",
    "        if index == len(sentence) - 1\n",
    "        else sentence[index + 1][0],\n",
    "        'next_word-prefix-2': ''\n",
    "        if index == len(sentence) - 1\n",
    "        else sentence[index + 1][:2],\n",
    "        'next_word-prefix-3': ''\n",
    "        if index == len(sentence) - 1\n",
    "        else sentence[index + 1][:3],\n",
    "        'next_word-suffix-1': ''\n",
    "        if index == len(sentence) - 1\n",
    "        else sentence[index + 1][-1],\n",
    "        'next_word-suffix-2': ''\n",
    "        if index == len(sentence) - 1\n",
    "        else sentence[index + 1][-2:],\n",
    "        'next_word-suffix-3': ''\n",
    "        if index == len(sentence) - 1\n",
    "        else sentence[index + 1][-3:],\n",
    "        'next_word': '' if index == len(sentence) - 1 else sentence[index + 1],\n",
    "        'has_hyphen': '-' in sentence[index],\n",
    "        'is_numeric': sentence[index].isdigit(),\n",
    "    }\n",
    "\n",
    "def transform_to_dataset(words, labels):\n",
    "    X, y = [], []\n",
    " \n",
    "    for no, tagged in enumerate(labels):\n",
    "        X.append([features(words[no], index) for index in range(len(words[no]))])\n",
    "        y.append([tag for tag in tagged])\n",
    " \n",
    "    return X, y\n",
    "\n",
    "def transform_to_dataset_depend(words, labels, depends):\n",
    "    X, y = [], []\n",
    " \n",
    "    for no, tagged in enumerate(labels):\n",
    "        X.append([features_crf_dependency(words[no], depends[no], index) for index in range(len(words[no]))])\n",
    "        y.append([tag for tag in tagged])\n",
    " \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = transform_to_dataset(words, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn_crfsuite\n",
    "from sklearn_crfsuite import scorers\n",
    "from sklearn_crfsuite import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/husein/.local/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "train_X, test_X, train_Y, test_Y = train_test_split(X, Y,test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13min 41s, sys: 328 ms, total: 13min 41s\n",
      "Wall time: 13min 40s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "crf = sklearn_crfsuite.CRF(\n",
    "    algorithm='lbfgs',\n",
    "    c1=0.1,\n",
    "    c2=0.1,\n",
    "    max_iterations=100,\n",
    "    all_possible_transitions=True\n",
    ")\n",
    "crf.fit(train_X, train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8953045920285301"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = crf.predict(test_X)\n",
    "metrics.flat_f1_score(test_Y, y_pred,\n",
    "                      average='weighted', labels = list(crf.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "         case     0.9584    0.9687    0.9635     11014\n",
      "          obl     0.8045    0.8274    0.8158      5810\n",
      "         flat     0.9469    0.9551    0.9510     10648\n",
      "           cc     0.9538    0.9652    0.9595      3336\n",
      "         conj     0.8684    0.8482    0.8582      4560\n",
      "        punct     0.9848    0.9963    0.9905     17017\n",
      "   nsubj:pass     0.8336    0.7640    0.7973      2059\n",
      "         root     0.7960    0.8453    0.8199      5037\n",
      "       nummod     0.9334    0.9359    0.9347      4088\n",
      "         mark     0.8739    0.8865    0.8802      1392\n",
      "        advcl     0.7649    0.6508    0.7033      1200\n",
      "       advmod     0.8932    0.8924    0.8928      4769\n",
      "         nmod     0.7762    0.7355    0.7553      4215\n",
      "        nsubj     0.8600    0.8835    0.8716      6388\n",
      "          det     0.9020    0.8868    0.8943      4142\n",
      "     compound     0.8776    0.8974    0.8874      6869\n",
      "         amod     0.8677    0.8530    0.8602      4128\n",
      "          obj     0.8749    0.8765    0.8757      5256\n",
      "          acl     0.8375    0.8094    0.8232      3075\n",
      "        xcomp     0.8082    0.8070    0.8076      1264\n",
      "    parataxis     0.7636    0.6208    0.6848       385\n",
      "        appos     0.8221    0.8177    0.8199      2425\n",
      "          cop     0.9350    0.9498    0.9423      1015\n",
      "        fixed     0.8569    0.8056    0.8305       602\n",
      "        ccomp     0.7516    0.5576    0.6402       434\n",
      "compound:plur     0.9154    0.9498    0.9323       638\n",
      "          dep     0.7820    0.5275    0.6300       510\n",
      "        csubj     0.8750    0.8400    0.8571        25\n",
      "         iobj     0.9375    0.6818    0.7895        22\n",
      "   csubj:pass     1.0000    0.8000    0.8889         5\n",
      "          aux     0.5000    0.2500    0.3333         4\n",
      "\n",
      "  avg / total     0.8953    0.8961    0.8953    112332\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.flat_classification_report(\n",
    "    test_Y, y_pred, labels=list(crf.classes_), digits=4\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('crf-label.pkl','wb') as fopen:\n",
    "    pickle.dump(crf,fopen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_depend, Y_depend = transform_to_dataset_depend(words, depends, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "train_X_depend, test_X_depend, train_Y_depend, test_Y_depend = train_test_split(X_depend, Y_depend,test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2h 54min 38s, sys: 412 ms, total: 2h 54min 38s\n",
      "Wall time: 2h 54min 18s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "crf_depend = sklearn_crfsuite.CRF(\n",
    "    algorithm='lbfgs',\n",
    "    c1=0.1,\n",
    "    c2=0.1,\n",
    "    max_iterations=100,\n",
    "    all_possible_transitions=True\n",
    ")\n",
    "crf_depend.fit(train_X_depend, train_Y_depend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/husein/.local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/husein/.local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5836390645242469"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = crf_depend.predict(test_X_depend)\n",
    "metrics.flat_f1_score(test_Y_depend, y_pred,\n",
    "                      average='weighted', labels = list(crf_depend.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          5     0.5452    0.5875    0.5656      5964\n",
      "          2     0.6193    0.7164    0.6643      4365\n",
      "          1     0.8839    0.9031    0.8934      4942\n",
      "          7     0.5181    0.5460    0.5317      5505\n",
      "          9     0.5569    0.5504    0.5536      4804\n",
      "         12     0.5421    0.5309    0.5364      3760\n",
      "         15     0.5556    0.5105    0.5321      3181\n",
      "          4     0.5195    0.6219    0.5661      6241\n",
      "          6     0.5346    0.5571    0.5456      5942\n",
      "         11     0.5350    0.5581    0.5463      4150\n",
      "         14     0.5425    0.5109    0.5262      3251\n",
      "          8     0.5463    0.5414    0.5438      5395\n",
      "         10     0.5705    0.5252    0.5469      4682\n",
      "         13     0.5506    0.5199    0.5348      3537\n",
      "          3     0.5871    0.6077    0.5972      5068\n",
      "         18     0.5613    0.5232    0.5415      2504\n",
      "         20     0.5772    0.5315    0.5534      2109\n",
      "         23     0.6065    0.5814    0.5937      1689\n",
      "         26     0.5820    0.5861    0.5841      1138\n",
      "         29     0.6089    0.5874    0.5980      1047\n",
      "         32     0.6459    0.6241    0.6348       798\n",
      "         35     0.6659    0.5931    0.6274       521\n",
      "         36     0.6312    0.6406    0.6359       537\n",
      "         40     0.6039    0.6620    0.6316       426\n",
      "         17     0.5513    0.5303    0.5406      2674\n",
      "         22     0.5889    0.5238    0.5545      1827\n",
      "         25     0.5898    0.5967    0.5932      1381\n",
      "         27     0.5802    0.5588    0.5693      1088\n",
      "         28     0.6101    0.6082    0.6092       970\n",
      "         34     0.6011    0.6029    0.6020       695\n",
      "         39     0.6711    0.5884    0.6270       430\n",
      "         37     0.6675    0.5876    0.6250       468\n",
      "         42     0.6975    0.6323    0.6633       310\n",
      "         43     0.6504    0.6584    0.6544       243\n",
      "         44     0.7205    0.6221    0.6677       344\n",
      "         47     0.6667    0.7077    0.6866       260\n",
      "         49     0.6903    0.7290    0.7091       214\n",
      "         51     0.6829    0.7368    0.7089       190\n",
      "         53     0.7483    0.6730    0.7086       159\n",
      "         55     0.7143    0.6936    0.7038       173\n",
      "         57     0.7093    0.6224    0.6630        98\n",
      "         59     0.7652    0.6779    0.7189       149\n",
      "         60     0.7253    0.7174    0.7213        92\n",
      "         61     0.7658    0.7516    0.7586       161\n",
      "         62     0.6500    0.5571    0.6000        70\n",
      "         63     0.7257    0.7736    0.7489       106\n",
      "         64     0.8730    0.7971    0.8333        69\n",
      "         65     0.8533    0.6667    0.7485        96\n",
      "         66     0.7097    0.8354    0.7674        79\n",
      "         67     0.5965    0.6415    0.6182        53\n",
      "         72     0.9362    0.6769    0.7857        65\n",
      "         70     0.9024    0.5968    0.7184        62\n",
      "         75     0.9348    0.7414    0.8269        58\n",
      "         77     0.7838    0.8286    0.8056        35\n",
      "         78     0.8750    0.8750    0.8750        16\n",
      "         80     0.7200    0.8000    0.7579        45\n",
      "         82     0.7027    0.7222    0.7123        36\n",
      "         83     0.6923    0.7200    0.7059        25\n",
      "         84     0.7407    0.5000    0.5970        40\n",
      "         85     0.6923    0.8571    0.7660        21\n",
      "         86     0.9091    0.6061    0.7273        33\n",
      "         87     0.5833    0.5000    0.5385        28\n",
      "         88     0.8333    0.4412    0.5769        34\n",
      "         89     0.7619    0.9412    0.8421        17\n",
      "         90     0.9143    0.7805    0.8421        41\n",
      "         91     0.6923    0.8182    0.7500        22\n",
      "         92     1.0000    0.8519    0.9200        27\n",
      "         93     1.0000    0.7273    0.8421        22\n",
      "         94     0.9333    0.6364    0.7568        22\n",
      "         95     1.0000    0.6250    0.7692        16\n",
      "         96     0.8000    0.6857    0.7385        35\n",
      "         97     0.9500    0.8261    0.8837        23\n",
      "        100     1.0000    0.6667    0.8000         6\n",
      "        103     1.0000    0.7857    0.8800        14\n",
      "        104     1.0000    0.6000    0.7500        15\n",
      "        101     0.9574    0.8491    0.9000        53\n",
      "        107     0.8846    0.8214    0.8519        28\n",
      "        112     0.8000    0.8000    0.8000        10\n",
      "        115     1.0000    0.5556    0.7143         9\n",
      "        120     0.6667    0.6667    0.6667         6\n",
      "        122     0.5556    0.7143    0.6250         7\n",
      "        124     1.0000    0.2857    0.4444         7\n",
      "        125     0.2857    0.4000    0.3333         5\n",
      "        126     0.5455    0.3529    0.4286        17\n",
      "        127     0.6667    1.0000    0.8000         4\n",
      "        128     1.0000    0.3500    0.5185        20\n",
      "        129     0.7000    0.7778    0.7368         9\n",
      "        130     0.8667    0.9286    0.8966        14\n",
      "        132     1.0000    0.7143    0.8333         7\n",
      "        133     0.5714    1.0000    0.7273         4\n",
      "        134     1.0000    1.0000    1.0000         2\n",
      "        138     0.9091    0.7692    0.8333        13\n",
      "        147     1.0000    0.5789    0.7333        19\n",
      "        149     0.6667    1.0000    0.8000         2\n",
      "        150     0.6667    1.0000    0.8000         2\n",
      "         21     0.5698    0.5552    0.5624      1940\n",
      "         24     0.5665    0.5503    0.5583      1501\n",
      "         30     0.6101    0.5757    0.5924       905\n",
      "         19     0.5310    0.5163    0.5236      2142\n",
      "         16     0.5312    0.5369    0.5340      2917\n",
      "         38     0.6839    0.6005    0.6395       418\n",
      "         33     0.6255    0.5951    0.6100       741\n",
      "         41     0.6913    0.6341    0.6614       399\n",
      "          0     0.4083    0.0926    0.1510       529\n",
      "         31     0.5924    0.5625    0.5771       752\n",
      "         48     0.6432    0.6010    0.6214       198\n",
      "         50     0.7320    0.6222    0.6727       180\n",
      "         52     0.6685    0.6538    0.6611       182\n",
      "         54     0.7024    0.6705    0.6860       176\n",
      "         68     0.7791    0.6262    0.6943       107\n",
      "         79     0.9020    0.8214    0.8598        56\n",
      "         46     0.8037    0.6187    0.6992       278\n",
      "         56     0.7721    0.7095    0.7394       148\n",
      "         98     0.8000    0.5926    0.6809        27\n",
      "         45     0.6513    0.6804    0.6655       291\n",
      "         73     0.8261    0.7451    0.7835        51\n",
      "        105     0.8571    0.7500    0.8000         8\n",
      "        108     0.9091    0.8333    0.8696        12\n",
      "        110     0.8462    0.7857    0.8148        14\n",
      "        114     0.7778    0.4375    0.5600        16\n",
      "        123     0.7500    0.5000    0.6000         6\n",
      "        135     1.0000    0.5625    0.7200        16\n",
      "        139     0.0000    0.0000    0.0000         1\n",
      "        142     1.0000    0.7500    0.8571         4\n",
      "        146     1.0000    1.0000    1.0000         3\n",
      "        151     1.0000    0.5000    0.6667         2\n",
      "         76     0.8400    0.7000    0.7636        30\n",
      "         58     0.6838    0.7207    0.7018       111\n",
      "         69     0.6824    0.7838    0.7296        74\n",
      "         74     0.8605    0.8043    0.8315        46\n",
      "         71     0.8077    0.7778    0.7925        81\n",
      "        109     0.8889    0.7273    0.8000        11\n",
      "         99     0.8889    0.6667    0.7619        12\n",
      "        117     1.0000    0.1429    0.2500         7\n",
      "        116     0.6000    0.6667    0.6316         9\n",
      "        113     0.5833    0.2917    0.3889        24\n",
      "        121     0.7500    0.5000    0.6000         6\n",
      "        131     0.8333    1.0000    0.9091         5\n",
      "        137     1.0000    0.7500    0.8571         4\n",
      "         81     0.9375    0.6522    0.7692        46\n",
      "        118     0.5000    0.5000    0.5000         6\n",
      "        111     0.6000    0.6000    0.6000         5\n",
      "        102     1.0000    0.7143    0.8333         7\n",
      "        106     1.0000    0.7727    0.8718        22\n",
      "        136     0.7778    0.2800    0.4118        25\n",
      "        140     1.0000    0.5000    0.6667         2\n",
      "        141     0.0000    0.0000    0.0000         5\n",
      "        144     1.0000    0.3000    0.4615        10\n",
      "        152     0.0000    0.0000    0.0000         1\n",
      "        153     0.0000    0.0000    0.0000         1\n",
      "        158     1.0000    0.6250    0.7692         8\n",
      "        156     0.9091    0.4762    0.6250        21\n",
      "        160     1.0000    1.0000    1.0000         2\n",
      "        164     1.0000    1.0000    1.0000         2\n",
      "        143     0.0000    0.0000    0.0000         0\n",
      "        155     0.0000    0.0000    0.0000         0\n",
      "        157     0.5000    0.2500    0.3333         4\n",
      "        161     0.0000    0.0000    0.0000         0\n",
      "        162     1.0000    0.2500    0.4000        12\n",
      "        166     0.0000    0.0000    0.0000         0\n",
      "        175     0.0000    0.0000    0.0000         0\n",
      "        173     0.0000    0.0000    0.0000         0\n",
      "        176     1.0000    1.0000    1.0000        16\n",
      "        177     1.0000    1.0000    1.0000         8\n",
      "        178     1.0000    1.0000    1.0000         4\n",
      "        181     0.0000    0.0000    0.0000         0\n",
      "        182     1.0000    1.0000    1.0000        16\n",
      "        119     1.0000    0.7143    0.8333        21\n",
      "        148     0.0000    0.0000    0.0000         0\n",
      "        154     1.0000    0.7500    0.8571         8\n",
      "        159     1.0000    0.2500    0.4000         4\n",
      "        163     0.0000    0.0000    0.0000         8\n",
      "        167     1.0000    1.0000    1.0000        16\n",
      "        174     1.0000    1.0000    1.0000         8\n",
      "        179     1.0000    1.0000    1.0000         4\n",
      "        183     1.0000    1.0000    1.0000        16\n",
      "        145     0.0000    0.0000    0.0000         0\n",
      "\n",
      "avg / total     0.5859    0.5847    0.5836    109699\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/husein/.local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/husein/.local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(metrics.flat_classification_report(\n",
    "    test_Y_depend, y_pred, labels=list(crf_depend.classes_), digits=4\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "string = 'Dr Mahathir menasihati mereka supaya berhenti berehat dan tidur sebentar sekiranya mengantuk ketika memandu.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dr det\n",
      "Mahathir nsubj\n",
      "menasihati conj\n",
      "mereka obj\n",
      "supaya case\n",
      "berhenti xcomp\n",
      "berehat advcl\n",
      "dan cc\n",
      "tidur conj\n",
      "sebentar advmod\n",
      "sekiranya advmod\n",
      "mengantuk root\n",
      "ketika case\n",
      "memandu xcomp\n"
     ]
    }
   ],
   "source": [
    "processed = process_string(string)\n",
    "result = crf.predict_single([features(processed, index) for index in range(len(processed))])\n",
    "for no, i in enumerate(result):\n",
    "    print(processed[no],i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_d = crf_depend.predict_single([features_crf_dependency(processed, result, index) for index in range(len(processed))])\n",
    "result_d = [int(i) for i in result_d]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(result)):\n",
    "    if result_d[i] == 0 and result[i] != 'root':\n",
    "        result[i] = 'UNK'\n",
    "    if result_d[i] != 0 and result[i] == 'root':\n",
    "        result[i] = 'UNK'\n",
    "    if result_d[i] > len(result):\n",
    "        result_d[i] = len(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dr 5 det\n",
      "Mahathir 10 nsubj\n",
      "menasihati 8 conj\n",
      "mereka 8 obj\n",
      "supaya 8 case\n",
      "berhenti 10 xcomp\n",
      "berehat 10 advcl\n",
      "dan 14 cc\n",
      "tidur 4 conj\n",
      "sebentar 12 advmod\n",
      "sekiranya 9 advmod\n",
      "mengantuk 1 UNK\n",
      "ketika 9 case\n",
      "memandu 7 xcomp\n"
     ]
    }
   ],
   "source": [
    "for no, i in enumerate(result):\n",
    "    print(processed[no],result_d[no], i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('crf-depend.pkl','wb') as fopen:\n",
    "    pickle.dump(crf_depend,fopen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
