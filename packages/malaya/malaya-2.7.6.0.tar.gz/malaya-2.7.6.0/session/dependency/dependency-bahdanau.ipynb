{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('id_gsd-ud-train.conllu.txt') as fopen:\n",
    "    corpus = fopen.read().split('\\n')\n",
    "    \n",
    "with open('id_gsd-ud-test.conllu.txt') as fopen:\n",
    "    corpus.extend(fopen.read().split('\\n'))\n",
    "    \n",
    "with open('id_gsd-ud-dev.conllu.txt') as fopen:\n",
    "    corpus.extend(fopen.read().split('\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2idx = {'PAD': 0,'NUM':1,'UNK':2}\n",
    "tag2idx = {'PAD': 0}\n",
    "char2idx = {'PAD': 0,'NUM':1,'UNK':2}\n",
    "word_idx = 3\n",
    "tag_idx = 1\n",
    "char_idx = 3\n",
    "\n",
    "def process_string(string):\n",
    "    string = re.sub('[^A-Za-z0-9\\-\\/ ]+', ' ', string).split()\n",
    "    return [to_title(y.strip()) for y in string]\n",
    "\n",
    "def to_title(string):\n",
    "    if string.isupper():\n",
    "        string = string.title()\n",
    "    return string\n",
    "\n",
    "def process_corpus(corpus, until = None):\n",
    "    global word2idx, tag2idx, char2idx, word_idx, tag_idx, char_idx\n",
    "    sentences, words, depends, labels, pos = [], [], [], [], []\n",
    "    temp_sentence, temp_word, temp_depend, temp_label, temp_pos = [], [], [], [], []\n",
    "    for sentence in corpus:\n",
    "        if len(sentence):\n",
    "            if sentence[0] == '#':\n",
    "                continue\n",
    "            sentence = sentence.split('\\t')\n",
    "            temp = process_string(sentence[1])\n",
    "            if not len(temp):\n",
    "                sentence[1] = 'EMPTY'\n",
    "            sentence[1] = process_string(sentence[1])[0]\n",
    "            for c in sentence[1]:\n",
    "                if c not in char2idx:\n",
    "                    char2idx[c] = char_idx\n",
    "                    char_idx += 1\n",
    "            if sentence[7] not in tag2idx:\n",
    "                tag2idx[sentence[7]] = tag_idx\n",
    "                tag_idx += 1\n",
    "            if sentence[1] not in word2idx:\n",
    "                word2idx[sentence[1]] = word_idx\n",
    "                word_idx += 1\n",
    "            temp_word.append(word2idx[sentence[1]])\n",
    "            temp_depend.append(int(sentence[6]) + 1)\n",
    "            temp_label.append(tag2idx[sentence[7]])\n",
    "            temp_sentence.append(sentence[1])\n",
    "            temp_pos.append(sentence[3])\n",
    "        else:\n",
    "            words.append(temp_word)\n",
    "            depends.append(temp_depend)\n",
    "            labels.append(temp_label)\n",
    "            sentences.append(temp_sentence)\n",
    "            pos.append(temp_pos)\n",
    "            temp_word = []\n",
    "            temp_depend = []\n",
    "            temp_label = []\n",
    "            temp_sentence = []\n",
    "            temp_pos = []\n",
    "    return sentences[:-1], words[:-1], depends[:-1], labels[:-1], pos[:-1]\n",
    "        \n",
    "sentences, words, depends, labels, pos = process_corpus(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('augmented.json') as fopen:\n",
    "    augmented = json.load(fopen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_XY(texts):\n",
    "    global word2idx, tag2idx, char2idx, word_idx, tag_idx, char_idx\n",
    "    outside, sentences = [], []\n",
    "    for no, text in enumerate(texts):\n",
    "        s = process_string(text)\n",
    "        sentences.append(s)\n",
    "        inside = []\n",
    "        for w in s:\n",
    "            for c in w:\n",
    "                if c not in char2idx:\n",
    "                    char2idx[c] = char_idx\n",
    "                    char_idx += 1\n",
    "            \n",
    "            if w not in word2idx:\n",
    "                word2idx[w] = word_idx\n",
    "                word_idx += 1\n",
    "                \n",
    "            inside.append(word2idx[w])\n",
    "        outside.append(inside)\n",
    "    return outside, sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_augmented = []\n",
    "for a in augmented:\n",
    "    text_augmented.extend(a[0])\n",
    "    depends.extend(a[1])\n",
    "    labels.extend(a[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "outside, new_sentences = parse_XY(text_augmented)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "words.extend(outside)\n",
    "sentences.extend(new_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50365, 50365, 50365, 50365)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words), len(depends), len(labels), len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_char_seq(batch, UNK = 2):\n",
    "    maxlen_c = max([len(k) for k in batch])\n",
    "    x = [[len(i) for i in k] for k in batch]\n",
    "    maxlen = max([j for i in x for j in i])\n",
    "    temp = np.zeros((len(batch),maxlen_c,maxlen),dtype=np.int32)\n",
    "    for i in range(len(batch)):\n",
    "        for k in range(len(batch[i])):\n",
    "            for no, c in enumerate(batch[i][k][:maxlen][::-1]):\n",
    "                temp[i,k,-1-no] = char2idx.get(c, UNK)\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx2word = {idx: tag for tag, idx in word2idx.items()}\n",
    "idx2tag = {i: w for w, i in tag2idx.items()}\n",
    "char = generate_char_seq(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50365, 189)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = pad_sequences(words,padding='post')\n",
    "depends = pad_sequences(depends,padding='post')\n",
    "labels = pad_sequences(labels,padding='post')\n",
    "words.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "train_X, test_X, train_Y, test_Y, train_depends, test_depends, train_char, test_char = train_test_split(\n",
    "                                                                           words,\n",
    "                                                                           labels,\n",
    "                                                                           depends,\n",
    "                                                                           char,\n",
    "                                                                           test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(\n",
    "        self,\n",
    "        dim_word,\n",
    "        dim_char,\n",
    "        dropout,\n",
    "        learning_rate,\n",
    "        hidden_size_char,\n",
    "        hidden_size_word,\n",
    "        num_layers,\n",
    "        maxlen\n",
    "    ):\n",
    "        def cells(size, reuse = False):\n",
    "            return tf.contrib.rnn.DropoutWrapper(\n",
    "                tf.nn.rnn_cell.LSTMCell(\n",
    "                    size,\n",
    "                    initializer = tf.orthogonal_initializer(),\n",
    "                    reuse = reuse,\n",
    "                ),\n",
    "                output_keep_prob = dropout,\n",
    "            )\n",
    "\n",
    "        def bahdanau(embedded, size):\n",
    "            attention_mechanism = tf.contrib.seq2seq.BahdanauAttention(\n",
    "                num_units = hidden_size_word, memory = embedded\n",
    "            )\n",
    "            return tf.contrib.seq2seq.AttentionWrapper(\n",
    "                cell = cells(hidden_size_word),\n",
    "                attention_mechanism = attention_mechanism,\n",
    "                attention_layer_size = hidden_size_word,\n",
    "            )\n",
    "        self.word_ids = tf.placeholder(tf.int32, shape = [None, None])\n",
    "        self.char_ids = tf.placeholder(tf.int32, shape = [None, None, None])\n",
    "        self.labels = tf.placeholder(tf.int32, shape = [None, None])\n",
    "        self.depends = tf.placeholder(tf.int32, shape = [None, None])\n",
    "        self.maxlen = tf.shape(self.word_ids)[1]\n",
    "        self.lengths = tf.count_nonzero(self.word_ids, 1)\n",
    "\n",
    "        self.word_embeddings = tf.Variable(\n",
    "            tf.truncated_normal(\n",
    "                [len(word2idx), dim_word], stddev = 1.0 / np.sqrt(dim_word)\n",
    "            )\n",
    "        )\n",
    "        self.char_embeddings = tf.Variable(\n",
    "            tf.truncated_normal(\n",
    "                [len(char2idx), dim_char], stddev = 1.0 / np.sqrt(dim_char)\n",
    "            )\n",
    "        )\n",
    "\n",
    "        word_embedded = tf.nn.embedding_lookup(\n",
    "            self.word_embeddings, self.word_ids\n",
    "        )\n",
    "        char_embedded = tf.nn.embedding_lookup(\n",
    "            self.char_embeddings, self.char_ids\n",
    "        )\n",
    "        s = tf.shape(char_embedded)\n",
    "        char_embedded = tf.reshape(\n",
    "            char_embedded, shape = [s[0] * s[1], s[-2], dim_char]\n",
    "        )\n",
    "        for n in range(num_layers):\n",
    "            (out_fw, out_bw), (\n",
    "                state_fw,\n",
    "                state_bw,\n",
    "            ) = tf.nn.bidirectional_dynamic_rnn(\n",
    "                cell_fw = cells(hidden_size_char),\n",
    "                cell_bw = cells(hidden_size_char),\n",
    "                inputs = char_embedded,\n",
    "                dtype = tf.float32,\n",
    "                scope = 'bidirectional_rnn_char_%d' % (n),\n",
    "            )\n",
    "            char_embedded = tf.concat((out_fw, out_bw), 2)\n",
    "        output = tf.reshape(\n",
    "            char_embedded[:, -1], shape = [s[0], s[1], 2 * hidden_size_char]\n",
    "        )\n",
    "        word_embedded = tf.concat([word_embedded, output], axis = -1)\n",
    "\n",
    "        for n in range(num_layers):\n",
    "            (out_fw, out_bw), (\n",
    "                state_fw,\n",
    "                state_bw,\n",
    "            ) = tf.nn.bidirectional_dynamic_rnn(\n",
    "                cell_fw = bahdanau(word_embedded, hidden_size_word),\n",
    "                cell_bw = bahdanau(word_embedded, hidden_size_word),\n",
    "                inputs = word_embedded,\n",
    "                dtype = tf.float32,\n",
    "                scope = 'bidirectional_rnn_word_%d' % (n),\n",
    "            )\n",
    "            word_embedded = tf.concat((out_fw, out_bw), 2)\n",
    "\n",
    "        logits = tf.layers.dense(word_embedded, len(idx2tag))\n",
    "        \n",
    "        tag_embeddings = tf.Variable(\n",
    "            tf.truncated_normal(\n",
    "                [len(idx2tag), dim_word], stddev = 1.0 / np.sqrt(dim_word)\n",
    "            )\n",
    "        )\n",
    "        logits_max = tf.argmax(logits,axis=2,output_type=tf.int32)\n",
    "        lookup_logits = tf.nn.embedding_lookup(\n",
    "            tag_embeddings, logits_max\n",
    "        )\n",
    "        (out_fw, out_bw), _ = tf.nn.bidirectional_dynamic_rnn(\n",
    "                cell_fw = cells(hidden_size_word),\n",
    "                cell_bw = cells(hidden_size_word),\n",
    "                inputs = word_embedded,\n",
    "                dtype = tf.float32,\n",
    "                scope = 'bidirectional_rnn_word_%d' % (n),\n",
    "            )\n",
    "        \n",
    "        cast_mask = tf.cast(tf.sequence_mask(self.lengths + 1, maxlen = maxlen), dtype = tf.float32)\n",
    "        cast_mask = tf.tile(tf.expand_dims(cast_mask,axis=1),[1,self.maxlen,1]) * 10\n",
    "        \n",
    "        lookup_logits = tf.concat((out_fw, out_bw), 2)\n",
    "        logits_depends = tf.layers.dense(lookup_logits, maxlen)\n",
    "        \n",
    "        logits_depends = tf.multiply(logits_depends, cast_mask)\n",
    "        \n",
    "        log_likelihood, transition_params = tf.contrib.crf.crf_log_likelihood(\n",
    "            logits, self.labels, self.lengths\n",
    "        )\n",
    "        with tf.variable_scope(\"depends\"):\n",
    "            log_likelihood_depends, transition_params_depends = tf.contrib.crf.crf_log_likelihood(\n",
    "                logits_depends, self.depends, self.lengths\n",
    "            )\n",
    "        self.cost = tf.reduce_mean(-log_likelihood) + tf.reduce_mean(-log_likelihood_depends)\n",
    "        self.optimizer = tf.train.AdamOptimizer(\n",
    "            learning_rate = learning_rate\n",
    "        ).minimize(self.cost)\n",
    "        \n",
    "        mask = tf.sequence_mask(self.lengths, maxlen = self.maxlen)\n",
    "        \n",
    "        self.tags_seq, _ = tf.contrib.crf.crf_decode(\n",
    "            logits, transition_params, self.lengths\n",
    "        )\n",
    "        self.tags_seq = tf.identity(self.tags_seq, name = 'logits')\n",
    "        \n",
    "        self.tags_seq_depends, _ = tf.contrib.crf.crf_decode(\n",
    "            logits_depends, transition_params_depends, self.lengths\n",
    "        )\n",
    "        self.tags_seq_depends = tf.identity(self.tags_seq_depends, name = 'logits_depends')\n",
    "\n",
    "        self.prediction = tf.boolean_mask(self.tags_seq, mask)\n",
    "        mask_label = tf.boolean_mask(self.labels, mask)\n",
    "        correct_pred = tf.equal(self.prediction, mask_label)\n",
    "        correct_index = tf.cast(correct_pred, tf.float32)\n",
    "        self.accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "        \n",
    "        self.prediction = tf.boolean_mask(self.tags_seq_depends, mask)\n",
    "        mask_label = tf.boolean_mask(self.depends, mask)\n",
    "        correct_pred = tf.equal(self.prediction, mask_label)\n",
    "        correct_index = tf.cast(correct_pred, tf.float32)\n",
    "        self.accuracy_depends = tf.reduce_mean(tf.cast(correct_pred, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_impl.py:112: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "dim_word = 128\n",
    "dim_char = 256\n",
    "dropout = 0.85\n",
    "learning_rate = 1e-3\n",
    "hidden_size_char = 128\n",
    "hidden_size_word = 64\n",
    "num_layers = 2\n",
    "batch_size = 16\n",
    "\n",
    "model = Model(dim_word,dim_char,dropout,learning_rate,hidden_size_char,hidden_size_word,num_layers,\n",
    "             words.shape[1])\n",
    "sess.run(tf.global_variables_initializer())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train minibatch loop: 100%|██████████| 2833/2833 [1:20:12<00:00,  1.70s/it, accuracy=0.812, accuracy_depends=0.547, cost=46]  \n",
      "test minibatch loop: 100%|██████████| 315/315 [03:16<00:00,  1.63it/s, accuracy=0.896, accuracy_depends=0.656, cost=28.5]\n",
      "train minibatch loop:   0%|          | 0/2833 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken: 5008.040819406509\n",
      "epoch: 0, training loss: 62.484219, training acc: 0.687616, training depends: 0.412115, valid loss: 35.875297, valid acc: 0.836436, valid depends: 0.645364\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train minibatch loop: 100%|██████████| 2833/2833 [1:20:11<00:00,  1.68s/it, accuracy=0.888, accuracy_depends=0.781, cost=25.5]\n",
      "test minibatch loop: 100%|██████████| 315/315 [03:15<00:00,  1.63it/s, accuracy=0.948, accuracy_depends=0.793, cost=16.7]\n",
      "train minibatch loop:   0%|          | 0/2833 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken: 5006.738508939743\n",
      "epoch: 1, training loss: 27.094490, training acc: 0.875416, training depends: 0.729413, valid loss: 21.630555, valid acc: 0.889475, valid depends: 0.800033\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train minibatch loop: 100%|██████████| 2833/2833 [1:20:13<00:00,  1.69s/it, accuracy=0.924, accuracy_depends=0.878, cost=16.5]\n",
      "test minibatch loop: 100%|██████████| 315/315 [03:15<00:00,  1.64it/s, accuracy=0.967, accuracy_depends=0.896, cost=9.21]\n",
      "train minibatch loop:   0%|          | 0/2833 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken: 5008.577131271362\n",
      "epoch: 2, training loss: 15.925178, training acc: 0.922652, training depends: 0.847503, valid loss: 15.807395, valid acc: 0.915586, valid depends: 0.866298\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train minibatch loop: 100%|██████████| 2833/2833 [1:20:14<00:00,  1.69s/it, accuracy=0.956, accuracy_depends=0.911, cost=11.3]\n",
      "test minibatch loop: 100%|██████████| 315/315 [03:15<00:00,  1.63it/s, accuracy=0.959, accuracy_depends=0.926, cost=8.56]\n",
      "train minibatch loop:   0%|          | 0/2833 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken: 5010.133793115616\n",
      "epoch: 3, training loss: 10.878052, training acc: 0.946691, training depends: 0.894082, valid loss: 13.006711, valid acc: 0.929738, valid depends: 0.899279\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train minibatch loop: 100%|██████████| 2833/2833 [1:20:13<00:00,  1.69s/it, accuracy=0.938, accuracy_depends=0.935, cost=8.81]\n",
      "test minibatch loop: 100%|██████████| 315/315 [03:15<00:00,  1.63it/s, accuracy=0.978, accuracy_depends=0.948, cost=4.36]\n",
      "train minibatch loop:   0%|          | 0/2833 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken: 5008.703083515167\n",
      "epoch: 4, training loss: 7.498419, training acc: 0.962283, training depends: 0.928191, valid loss: 11.665039, valid acc: 0.938365, valid depends: 0.914650\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train minibatch loop: 100%|██████████| 2833/2833 [1:20:14<00:00,  1.69s/it, accuracy=0.938, accuracy_depends=0.823, cost=17.7]\n",
      "test minibatch loop: 100%|██████████| 315/315 [03:15<00:00,  1.63it/s, accuracy=0.967, accuracy_depends=0.844, cost=12.6]\n",
      "train minibatch loop:   0%|          | 0/2833 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken: 5010.282833337784\n",
      "epoch: 5, training loss: 10.502579, training acc: 0.964749, training depends: 0.887862, valid loss: 17.299690, valid acc: 0.936364, valid depends: 0.823247\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train minibatch loop: 100%|██████████| 2833/2833 [1:20:15<00:00,  1.69s/it, accuracy=0.961, accuracy_depends=0.958, cost=6.84]\n",
      "test minibatch loop: 100%|██████████| 315/315 [03:15<00:00,  1.63it/s, accuracy=0.978, accuracy_depends=0.948, cost=5.51]\n",
      "train minibatch loop:   0%|          | 0/2833 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken: 5010.7648820877075\n",
      "epoch: 6, training loss: 8.172327, training acc: 0.972956, training depends: 0.908020, valid loss: 10.859837, valid acc: 0.947560, valid depends: 0.921681\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train minibatch loop: 100%|██████████| 2833/2833 [1:20:14<00:00,  1.69s/it, accuracy=0.982, accuracy_depends=0.956, cost=4.74] \n",
      "test minibatch loop: 100%|██████████| 315/315 [03:15<00:00,  1.64it/s, accuracy=0.985, accuracy_depends=0.974, cost=2.53]\n",
      "train minibatch loop:   0%|          | 0/2833 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken: 5010.066545963287\n",
      "epoch: 7, training loss: 5.122587, training acc: 0.979184, training depends: 0.947194, valid loss: 10.091347, valid acc: 0.951014, valid depends: 0.936373\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train minibatch loop: 100%|██████████| 2833/2833 [1:20:16<00:00,  1.69s/it, accuracy=0.966, accuracy_depends=0.932, cost=7.67] \n",
      "test minibatch loop: 100%|██████████| 315/315 [03:15<00:00,  1.64it/s, accuracy=0.974, accuracy_depends=0.919, cost=7.52]\n",
      "train minibatch loop:   0%|          | 0/2833 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken: 5011.766835451126\n",
      "epoch: 8, training loss: 5.387102, training acc: 0.979654, training depends: 0.941862, valid loss: 10.987624, valid acc: 0.946941, valid depends: 0.924877\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train minibatch loop: 100%|██████████| 2833/2833 [1:20:17<00:00,  1.69s/it, accuracy=0.971, accuracy_depends=0.956, cost=5.2] \n",
      "test minibatch loop: 100%|██████████| 315/315 [03:15<00:00,  1.62it/s, accuracy=0.993, accuracy_depends=0.97, cost=2.84] \n",
      "train minibatch loop:   0%|          | 0/2833 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken: 5013.079018354416\n",
      "epoch: 9, training loss: 9.745852, training acc: 0.976012, training depends: 0.874312, valid loss: 11.059560, valid acc: 0.950731, valid depends: 0.925793\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train minibatch loop: 100%|██████████| 2833/2833 [1:20:16<00:00,  1.70s/it, accuracy=0.964, accuracy_depends=0.94, cost=5.8]   \n",
      "test minibatch loop: 100%|██████████| 315/315 [03:15<00:00,  1.64it/s, accuracy=0.981, accuracy_depends=0.97, cost=3.35] \n",
      "train minibatch loop:   0%|          | 0/2833 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken: 5012.365065097809\n",
      "epoch: 10, training loss: 8.140059, training acc: 0.971539, training depends: 0.907471, valid loss: 10.344279, valid acc: 0.951060, valid depends: 0.935012\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train minibatch loop: 100%|██████████| 2833/2833 [1:20:15<00:00,  1.68s/it, accuracy=0.99, accuracy_depends=0.969, cost=3.05]  \n",
      "test minibatch loop: 100%|██████████| 315/315 [03:15<00:00,  1.63it/s, accuracy=0.981, accuracy_depends=0.959, cost=4.11]\n",
      "train minibatch loop:   0%|          | 0/2833 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken: 5011.202510595322\n",
      "epoch: 11, training loss: 3.299452, training acc: 0.985352, training depends: 0.966909, valid loss: 9.951744, valid acc: 0.954282, valid depends: 0.944745\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train minibatch loop: 100%|██████████| 2833/2833 [1:20:16<00:00,  1.70s/it, accuracy=0.99, accuracy_depends=0.969, cost=3.83]  \n",
      "test minibatch loop: 100%|██████████| 315/315 [03:15<00:00,  1.63it/s, accuracy=0.981, accuracy_depends=0.978, cost=2.13]\n",
      "train minibatch loop:   0%|          | 0/2833 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken: 5011.455784082413\n",
      "epoch: 12, training loss: 2.711230, training acc: 0.987114, training depends: 0.974351, valid loss: 9.891155, valid acc: 0.954302, valid depends: 0.948340\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train minibatch loop: 100%|██████████| 2833/2833 [1:20:16<00:00,  1.69s/it, accuracy=0.99, accuracy_depends=0.977, cost=2.45]  \n",
      "test minibatch loop: 100%|██████████| 315/315 [03:15<00:00,  1.64it/s, accuracy=0.993, accuracy_depends=0.974, cost=1.97]\n",
      "train minibatch loop:   0%|          | 0/2833 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken: 5012.48108124733\n",
      "epoch: 13, training loss: 2.359227, training acc: 0.988185, training depends: 0.978197, valid loss: 9.463627, valid acc: 0.955425, valid depends: 0.952417\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train minibatch loop: 100%|██████████| 2833/2833 [1:20:18<00:00,  1.68s/it, accuracy=0.964, accuracy_depends=0.987, cost=4.21] \n",
      "test minibatch loop: 100%|██████████| 315/315 [03:15<00:00,  1.63it/s, accuracy=0.985, accuracy_depends=0.974, cost=2.12]\n",
      "train minibatch loop:   0%|          | 0/2833 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken: 5013.777709722519\n",
      "epoch: 14, training loss: 2.100721, training acc: 0.989465, training depends: 0.980502, valid loss: 9.556043, valid acc: 0.956996, valid depends: 0.954261\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train minibatch loop: 100%|██████████| 2833/2833 [1:20:18<00:00,  1.68s/it, accuracy=0.987, accuracy_depends=0.984, cost=1.9]  \n",
      "test minibatch loop: 100%|██████████| 315/315 [03:15<00:00,  1.64it/s, accuracy=0.981, accuracy_depends=0.974, cost=4.66]\n",
      "train minibatch loop:   0%|          | 0/2833 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken: 5014.499285459518\n",
      "epoch: 15, training loss: 1.833721, training acc: 0.990503, training depends: 0.983315, valid loss: 9.180412, valid acc: 0.959398, valid depends: 0.957512\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train minibatch loop:   0%|          | 5/2833 [00:08<1:20:31,  1.71s/it, accuracy=0.997, accuracy_depends=0.988, cost=1.06]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-493f7b4fc43e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchar_ids\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_char\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m                 \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdepends\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_depends\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m             },\n\u001b[1;32m     22\u001b[0m         )\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1332\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "for e in range(15):\n",
    "    lasttime = time.time()\n",
    "    train_acc, train_loss, test_acc, test_loss, train_acc_depends, test_acc_depends = 0, 0, 0, 0, 0, 0\n",
    "    pbar = tqdm(\n",
    "        range(0, len(train_X), batch_size), desc = 'train minibatch loop'\n",
    "    )\n",
    "    for i in pbar:\n",
    "        batch_x = train_X[i : min(i + batch_size, train_X.shape[0])]\n",
    "        batch_char = train_char[i : min(i + batch_size, train_X.shape[0])]\n",
    "        batch_y = train_Y[i : min(i + batch_size, train_X.shape[0])]\n",
    "        batch_depends = train_depends[i : min(i + batch_size, train_X.shape[0])]\n",
    "        acc_depends, acc, cost, _ = sess.run(\n",
    "            [model.accuracy_depends, model.accuracy, model.cost, model.optimizer],\n",
    "            feed_dict = {\n",
    "                model.word_ids: batch_x,\n",
    "                model.char_ids: batch_char,\n",
    "                model.labels: batch_y,\n",
    "                model.depends: batch_depends\n",
    "            },\n",
    "        )\n",
    "        assert not np.isnan(cost)\n",
    "        train_loss += cost\n",
    "        train_acc += acc\n",
    "        train_acc_depends += acc_depends\n",
    "        pbar.set_postfix(cost = cost, accuracy = acc, accuracy_depends = acc_depends)\n",
    "    pbar = tqdm(\n",
    "        range(0, len(test_X), batch_size), desc = 'test minibatch loop'\n",
    "    )\n",
    "    for i in pbar:\n",
    "        batch_x = test_X[i : min(i + batch_size, test_X.shape[0])]\n",
    "        batch_char = test_char[i : min(i + batch_size, test_X.shape[0])]\n",
    "        batch_y = test_Y[i : min(i + batch_size, test_X.shape[0])]\n",
    "        batch_depends = test_depends[i : min(i + batch_size, test_X.shape[0])]\n",
    "        acc_depends, acc, cost = sess.run(\n",
    "            [model.accuracy_depends, model.accuracy, model.cost],\n",
    "            feed_dict = {\n",
    "                model.word_ids: batch_x,\n",
    "                model.char_ids: batch_char,\n",
    "                model.labels: batch_y,\n",
    "                model.depends: batch_depends\n",
    "            },\n",
    "        )\n",
    "        assert not np.isnan(cost)\n",
    "        test_loss += cost\n",
    "        test_acc += acc\n",
    "        test_acc_depends += acc_depends\n",
    "        pbar.set_postfix(cost = cost, accuracy = acc, accuracy_depends = acc_depends)\n",
    "    \n",
    "    train_loss /= len(train_X) / batch_size\n",
    "    train_acc /= len(train_X) / batch_size\n",
    "    train_acc_depends /= len(train_X) / batch_size\n",
    "    test_loss /= len(test_X) / batch_size\n",
    "    test_acc /= len(test_X) / batch_size\n",
    "    test_acc_depends /= len(test_X) / batch_size\n",
    "\n",
    "    print('time taken:', time.time() - lasttime)\n",
    "    print(\n",
    "        'epoch: %d, training loss: %f, training acc: %f, training depends: %f, valid loss: %f, valid acc: %f, valid depends: %f\\n'\n",
    "        % (e, train_loss, train_acc, train_acc_depends, test_loss, test_acc, test_acc_depends)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred2label(pred):\n",
    "    out = []\n",
    "    for pred_i in pred:\n",
    "        out_i = []\n",
    "        for p in pred_i:\n",
    "            out_i.append(idx2tag[p])\n",
    "        out.append(out_i)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq, deps = sess.run([model.tags_seq, model.tags_seq_depends],\n",
    "            feed_dict = {\n",
    "                model.word_ids: batch_x,\n",
    "                model.char_ids: batch_char,\n",
    "            },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "validation minibatch loop:   0%|          | 0/315 [00:00<?, ?it/s]\u001b[A\n",
      "validation minibatch loop:   0%|          | 1/315 [00:00<03:12,  1.63it/s]\u001b[A\n",
      "validation minibatch loop:   1%|          | 2/315 [00:01<03:10,  1.65it/s]\u001b[A\n",
      "validation minibatch loop:   1%|          | 3/315 [00:01<03:09,  1.64it/s]\u001b[A\n",
      "validation minibatch loop:   1%|▏         | 4/315 [00:02<03:08,  1.65it/s]\u001b[A\n",
      "validation minibatch loop:   2%|▏         | 5/315 [00:03<03:09,  1.64it/s]\u001b[A\n",
      "validation minibatch loop:   2%|▏         | 6/315 [00:03<03:10,  1.62it/s]\u001b[A\n",
      "validation minibatch loop:   2%|▏         | 7/315 [00:04<03:08,  1.64it/s]\u001b[A\n",
      "validation minibatch loop:   3%|▎         | 8/315 [00:04<03:06,  1.64it/s]\u001b[A\n",
      "validation minibatch loop:   3%|▎         | 9/315 [00:05<03:05,  1.65it/s]\u001b[A\n",
      "validation minibatch loop:   3%|▎         | 10/315 [00:06<03:03,  1.66it/s]\u001b[A\n",
      "validation minibatch loop:   3%|▎         | 11/315 [00:06<03:03,  1.66it/s]\u001b[A\n",
      "validation minibatch loop:   4%|▍         | 12/315 [00:07<03:01,  1.67it/s]\u001b[A\n",
      "validation minibatch loop:   4%|▍         | 13/315 [00:07<03:01,  1.67it/s]\u001b[A\n",
      "validation minibatch loop:   4%|▍         | 14/315 [00:08<03:00,  1.67it/s]\u001b[A\n",
      "validation minibatch loop:   5%|▍         | 15/315 [00:09<03:00,  1.66it/s]\u001b[A\n",
      "validation minibatch loop:   5%|▌         | 16/315 [00:09<02:59,  1.67it/s]\u001b[A\n",
      "validation minibatch loop:   5%|▌         | 17/315 [00:10<03:00,  1.65it/s]\u001b[A\n",
      "validation minibatch loop:   6%|▌         | 18/315 [00:10<03:00,  1.65it/s]\u001b[A\n",
      "validation minibatch loop:   6%|▌         | 19/315 [00:11<02:58,  1.66it/s]\u001b[A\n",
      "validation minibatch loop:   6%|▋         | 20/315 [00:12<02:57,  1.66it/s]\u001b[A\n",
      "validation minibatch loop:   7%|▋         | 21/315 [00:12<02:57,  1.66it/s]\u001b[A\n",
      "validation minibatch loop:   7%|▋         | 22/315 [00:13<02:57,  1.65it/s]\u001b[A\n",
      "validation minibatch loop:   7%|▋         | 23/315 [00:13<03:00,  1.61it/s]\u001b[A\n",
      "validation minibatch loop:   8%|▊         | 24/315 [00:14<02:58,  1.63it/s]\u001b[A\n",
      "validation minibatch loop:   8%|▊         | 25/315 [00:15<02:58,  1.63it/s]\u001b[A\n",
      "validation minibatch loop:   8%|▊         | 26/315 [00:15<02:56,  1.63it/s]\u001b[A\n",
      "validation minibatch loop:   9%|▊         | 27/315 [00:16<02:55,  1.64it/s]\u001b[A\n",
      "validation minibatch loop:   9%|▉         | 28/315 [00:16<02:54,  1.65it/s]\u001b[A\n",
      "validation minibatch loop:   9%|▉         | 29/315 [00:17<02:52,  1.65it/s]\u001b[A\n",
      "validation minibatch loop:  10%|▉         | 30/315 [00:18<02:51,  1.66it/s]\u001b[A\n",
      "validation minibatch loop:  10%|▉         | 31/315 [00:18<02:51,  1.66it/s]\u001b[A\n",
      "validation minibatch loop:  10%|█         | 32/315 [00:19<02:50,  1.66it/s]\u001b[A\n",
      "validation minibatch loop:  10%|█         | 33/315 [00:19<02:50,  1.65it/s]\u001b[A\n",
      "validation minibatch loop:  11%|█         | 34/315 [00:20<02:50,  1.65it/s]\u001b[A\n",
      "validation minibatch loop:  11%|█         | 35/315 [00:21<02:49,  1.66it/s]\u001b[A\n",
      "validation minibatch loop:  11%|█▏        | 36/315 [00:21<02:48,  1.65it/s]\u001b[A\n",
      "validation minibatch loop:  12%|█▏        | 37/315 [00:22<02:50,  1.63it/s]\u001b[A\n",
      "validation minibatch loop:  12%|█▏        | 38/315 [00:23<02:49,  1.63it/s]\u001b[A\n",
      "validation minibatch loop:  12%|█▏        | 39/315 [00:23<02:48,  1.64it/s]\u001b[A\n",
      "validation minibatch loop:  13%|█▎        | 40/315 [00:24<02:46,  1.66it/s]\u001b[A\n",
      "validation minibatch loop:  13%|█▎        | 41/315 [00:24<02:44,  1.66it/s]\u001b[A\n",
      "validation minibatch loop:  13%|█▎        | 42/315 [00:25<02:43,  1.67it/s]\u001b[A\n",
      "validation minibatch loop:  14%|█▎        | 43/315 [00:26<02:45,  1.65it/s]\u001b[A\n",
      "validation minibatch loop:  14%|█▍        | 44/315 [00:26<02:44,  1.65it/s]\u001b[A\n",
      "validation minibatch loop:  14%|█▍        | 45/315 [00:27<02:43,  1.65it/s]\u001b[A\n",
      "validation minibatch loop:  15%|█▍        | 46/315 [00:27<02:43,  1.65it/s]\u001b[A\n",
      "validation minibatch loop:  15%|█▍        | 47/315 [00:28<02:41,  1.66it/s]\u001b[A\n",
      "validation minibatch loop:  15%|█▌        | 48/315 [00:29<02:40,  1.67it/s]\u001b[A\n",
      "validation minibatch loop:  16%|█▌        | 49/315 [00:29<02:40,  1.65it/s]\u001b[A\n",
      "validation minibatch loop:  16%|█▌        | 50/315 [00:30<02:39,  1.66it/s]\u001b[A\n",
      "validation minibatch loop:  16%|█▌        | 51/315 [00:30<02:39,  1.65it/s]\u001b[A\n",
      "validation minibatch loop:  17%|█▋        | 52/315 [00:31<02:38,  1.66it/s]\u001b[A\n",
      "validation minibatch loop:  17%|█▋        | 53/315 [00:32<02:36,  1.67it/s]\u001b[A\n",
      "validation minibatch loop:  17%|█▋        | 54/315 [00:32<02:37,  1.66it/s]\u001b[A\n",
      "validation minibatch loop:  17%|█▋        | 55/315 [00:33<02:36,  1.66it/s]\u001b[A\n",
      "validation minibatch loop:  18%|█▊        | 56/315 [00:33<02:37,  1.64it/s]\u001b[A\n",
      "validation minibatch loop:  18%|█▊        | 57/315 [00:34<02:36,  1.65it/s]\u001b[A\n",
      "validation minibatch loop:  18%|█▊        | 58/315 [00:35<02:35,  1.66it/s]\u001b[A\n",
      "validation minibatch loop:  19%|█▊        | 59/315 [00:35<02:34,  1.65it/s]\u001b[A\n",
      "validation minibatch loop:  19%|█▉        | 60/315 [00:36<02:34,  1.65it/s]\u001b[A\n",
      "validation minibatch loop:  19%|█▉        | 61/315 [00:36<02:34,  1.64it/s]\u001b[A\n",
      "validation minibatch loop:  20%|█▉        | 62/315 [00:37<02:32,  1.66it/s]\u001b[A\n",
      "validation minibatch loop:  20%|██        | 63/315 [00:38<02:32,  1.66it/s]\u001b[A\n",
      "validation minibatch loop:  20%|██        | 64/315 [00:38<02:32,  1.64it/s]\u001b[A\n",
      "validation minibatch loop:  21%|██        | 65/315 [00:39<02:30,  1.66it/s]\u001b[A\n",
      "validation minibatch loop:  21%|██        | 66/315 [00:39<02:28,  1.67it/s]\u001b[A\n",
      "validation minibatch loop:  21%|██▏       | 67/315 [00:40<02:27,  1.68it/s]\u001b[A\n",
      "validation minibatch loop:  22%|██▏       | 68/315 [00:41<02:27,  1.67it/s]\u001b[A\n",
      "validation minibatch loop:  22%|██▏       | 69/315 [00:41<02:28,  1.65it/s]\u001b[A\n",
      "validation minibatch loop:  22%|██▏       | 70/315 [00:42<02:28,  1.65it/s]\u001b[A\n",
      "validation minibatch loop:  23%|██▎       | 71/315 [00:43<02:30,  1.62it/s]\u001b[A\n",
      "validation minibatch loop:  23%|██▎       | 72/315 [00:43<02:29,  1.62it/s]\u001b[A\n",
      "validation minibatch loop:  23%|██▎       | 73/315 [00:44<02:27,  1.64it/s]\u001b[A\n",
      "validation minibatch loop:  23%|██▎       | 74/315 [00:44<02:28,  1.63it/s]\u001b[A\n",
      "validation minibatch loop:  24%|██▍       | 75/315 [00:45<02:26,  1.63it/s]\u001b[A\n",
      "validation minibatch loop:  24%|██▍       | 76/315 [00:46<02:24,  1.65it/s]\u001b[A\n",
      "validation minibatch loop:  24%|██▍       | 77/315 [00:46<02:23,  1.66it/s]\u001b[A\n",
      "validation minibatch loop:  25%|██▍       | 78/315 [00:47<02:22,  1.67it/s]\u001b[A\n",
      "validation minibatch loop:  25%|██▌       | 79/315 [00:47<02:24,  1.64it/s]\u001b[A\n",
      "validation minibatch loop:  25%|██▌       | 80/315 [00:48<02:22,  1.65it/s]\u001b[A\n",
      "validation minibatch loop:  26%|██▌       | 81/315 [00:49<02:21,  1.65it/s]\u001b[A\n",
      "validation minibatch loop:  26%|██▌       | 82/315 [00:49<02:22,  1.64it/s]\u001b[A\n",
      "validation minibatch loop:  26%|██▋       | 83/315 [00:50<02:21,  1.64it/s]\u001b[A\n",
      "validation minibatch loop:  27%|██▋       | 84/315 [00:50<02:20,  1.64it/s]\u001b[A\n",
      "validation minibatch loop:  27%|██▋       | 85/315 [00:51<02:20,  1.64it/s]\u001b[A\n",
      "validation minibatch loop:  27%|██▋       | 86/315 [00:52<02:18,  1.65it/s]\u001b[A\n",
      "validation minibatch loop:  28%|██▊       | 87/315 [00:52<02:17,  1.66it/s]\u001b[A\n",
      "validation minibatch loop:  28%|██▊       | 88/315 [00:53<02:17,  1.65it/s]\u001b[A\n",
      "validation minibatch loop:  28%|██▊       | 89/315 [00:53<02:17,  1.64it/s]\u001b[A\n",
      "validation minibatch loop:  29%|██▊       | 90/315 [00:54<02:16,  1.65it/s]\u001b[A\n",
      "validation minibatch loop:  29%|██▉       | 91/315 [00:55<02:15,  1.65it/s]\u001b[A\n",
      "validation minibatch loop:  29%|██▉       | 92/315 [00:55<02:16,  1.64it/s]\u001b[A\n",
      "validation minibatch loop:  30%|██▉       | 93/315 [00:56<02:14,  1.66it/s]\u001b[A\n",
      "validation minibatch loop:  30%|██▉       | 94/315 [00:56<02:13,  1.66it/s]\u001b[A\n",
      "validation minibatch loop:  30%|███       | 95/315 [00:57<02:12,  1.66it/s]\u001b[A\n",
      "validation minibatch loop:  30%|███       | 96/315 [00:58<02:11,  1.66it/s]\u001b[A\n",
      "validation minibatch loop:  31%|███       | 97/315 [00:58<02:12,  1.65it/s]\u001b[A\n",
      "validation minibatch loop:  31%|███       | 98/315 [00:59<02:11,  1.64it/s]\u001b[A\n",
      "validation minibatch loop:  31%|███▏      | 99/315 [00:59<02:11,  1.64it/s]\u001b[A\n",
      "validation minibatch loop:  32%|███▏      | 100/315 [01:00<02:10,  1.65it/s]\u001b[A\n",
      "validation minibatch loop:  32%|███▏      | 101/315 [01:01<02:11,  1.63it/s]\u001b[A\n",
      "validation minibatch loop:  32%|███▏      | 102/315 [01:01<02:09,  1.64it/s]\u001b[A\n",
      "validation minibatch loop:  33%|███▎      | 103/315 [01:02<02:08,  1.64it/s]\u001b[A\n",
      "validation minibatch loop:  33%|███▎      | 104/315 [01:03<02:07,  1.65it/s]\u001b[A\n",
      "validation minibatch loop:  33%|███▎      | 105/315 [01:03<02:06,  1.66it/s]\u001b[A\n",
      "validation minibatch loop:  34%|███▎      | 106/315 [01:04<02:05,  1.67it/s]\u001b[A\n",
      "validation minibatch loop:  34%|███▍      | 107/315 [01:04<02:07,  1.63it/s]\u001b[A\n",
      "validation minibatch loop:  34%|███▍      | 108/315 [01:05<02:05,  1.65it/s]\u001b[A\n",
      "validation minibatch loop:  35%|███▍      | 109/315 [01:06<02:05,  1.65it/s]\u001b[A\n",
      "validation minibatch loop:  35%|███▍      | 110/315 [01:06<02:03,  1.65it/s]\u001b[A\n",
      "validation minibatch loop:  35%|███▌      | 111/315 [01:07<02:03,  1.65it/s]\u001b[A\n",
      "validation minibatch loop:  36%|███▌      | 112/315 [01:07<02:03,  1.64it/s]\u001b[A\n",
      "validation minibatch loop:  36%|███▌      | 113/315 [01:08<02:02,  1.66it/s]\u001b[A\n",
      "validation minibatch loop:  36%|███▌      | 114/315 [01:09<02:05,  1.60it/s]\u001b[A\n",
      "validation minibatch loop:  37%|███▋      | 115/315 [01:09<02:03,  1.62it/s]\u001b[A\n",
      "validation minibatch loop:  37%|███▋      | 116/315 [01:10<02:01,  1.64it/s]\u001b[A\n",
      "validation minibatch loop:  37%|███▋      | 117/315 [01:10<02:00,  1.64it/s]\u001b[A\n",
      "validation minibatch loop:  37%|███▋      | 118/315 [01:11<01:58,  1.66it/s]\u001b[A\n",
      "validation minibatch loop:  38%|███▊      | 119/315 [01:12<01:59,  1.64it/s]\u001b[A\n",
      "validation minibatch loop:  38%|███▊      | 120/315 [01:12<01:59,  1.64it/s]\u001b[A\n",
      "validation minibatch loop:  38%|███▊      | 121/315 [01:13<01:58,  1.64it/s]\u001b[A\n",
      "validation minibatch loop:  39%|███▊      | 122/315 [01:13<01:58,  1.63it/s]\u001b[A\n",
      "validation minibatch loop:  39%|███▉      | 123/315 [01:14<01:56,  1.64it/s]\u001b[A\n",
      "validation minibatch loop:  39%|███▉      | 124/315 [01:15<01:55,  1.65it/s]\u001b[A\n",
      "validation minibatch loop:  40%|███▉      | 125/315 [01:15<01:56,  1.63it/s]\u001b[A\n",
      "validation minibatch loop:  40%|████      | 126/315 [01:16<01:55,  1.64it/s]\u001b[A\n",
      "validation minibatch loop:  40%|████      | 127/315 [01:17<01:53,  1.65it/s]\u001b[A\n",
      "validation minibatch loop:  41%|████      | 128/315 [01:17<01:52,  1.66it/s]\u001b[A\n",
      "validation minibatch loop:  41%|████      | 129/315 [01:18<01:52,  1.66it/s]\u001b[A\n",
      "validation minibatch loop:  41%|████▏     | 130/315 [01:18<01:50,  1.67it/s]\u001b[A\n",
      "validation minibatch loop:  42%|████▏     | 131/315 [01:19<01:49,  1.67it/s]\u001b[A\n",
      "validation minibatch loop:  42%|████▏     | 132/315 [01:20<01:49,  1.68it/s]\u001b[A\n",
      "validation minibatch loop:  42%|████▏     | 133/315 [01:20<01:48,  1.67it/s]\u001b[A\n",
      "validation minibatch loop:  43%|████▎     | 134/315 [01:21<01:47,  1.68it/s]\u001b[A\n",
      "validation minibatch loop:  43%|████▎     | 135/315 [01:21<01:47,  1.67it/s]\u001b[A\n",
      "validation minibatch loop:  43%|████▎     | 136/315 [01:22<01:46,  1.68it/s]\u001b[A\n",
      "validation minibatch loop:  43%|████▎     | 137/315 [01:23<01:47,  1.66it/s]\u001b[A\n",
      "validation minibatch loop:  44%|████▍     | 138/315 [01:23<01:46,  1.66it/s]\u001b[A\n",
      "validation minibatch loop:  44%|████▍     | 139/315 [01:24<01:46,  1.66it/s]\u001b[A\n",
      "validation minibatch loop:  44%|████▍     | 140/315 [01:24<01:46,  1.65it/s]\u001b[A\n",
      "validation minibatch loop:  45%|████▍     | 141/315 [01:25<01:44,  1.66it/s]\u001b[A\n",
      "validation minibatch loop:  45%|████▌     | 142/315 [01:26<01:45,  1.63it/s]\u001b[A\n",
      "validation minibatch loop:  45%|████▌     | 143/315 [01:26<01:45,  1.64it/s]\u001b[A\n",
      "validation minibatch loop:  46%|████▌     | 144/315 [01:27<01:43,  1.65it/s]\u001b[A\n",
      "validation minibatch loop:  46%|████▌     | 145/315 [01:27<01:43,  1.65it/s]\u001b[A\n",
      "validation minibatch loop:  46%|████▋     | 146/315 [01:28<01:42,  1.65it/s]\u001b[A\n",
      "validation minibatch loop:  47%|████▋     | 147/315 [01:29<01:41,  1.66it/s]\u001b[A\n",
      "validation minibatch loop:  47%|████▋     | 148/315 [01:29<01:40,  1.66it/s]\u001b[A\n",
      "validation minibatch loop:  47%|████▋     | 149/315 [01:30<01:39,  1.66it/s]\u001b[A\n",
      "validation minibatch loop:  48%|████▊     | 150/315 [01:30<01:40,  1.65it/s]\u001b[A\n",
      "validation minibatch loop:  48%|████▊     | 151/315 [01:31<01:41,  1.61it/s]\u001b[A\n",
      "validation minibatch loop:  48%|████▊     | 152/315 [01:32<01:39,  1.64it/s]\u001b[A\n",
      "validation minibatch loop:  49%|████▊     | 153/315 [01:32<01:38,  1.65it/s]\u001b[A\n",
      "validation minibatch loop:  49%|████▉     | 154/315 [01:33<01:37,  1.66it/s]\u001b[A\n",
      "validation minibatch loop:  49%|████▉     | 155/315 [01:33<01:36,  1.66it/s]\u001b[A\n",
      "validation minibatch loop:  50%|████▉     | 156/315 [01:34<01:36,  1.65it/s]\u001b[A\n",
      "validation minibatch loop:  50%|████▉     | 157/315 [01:35<01:35,  1.65it/s]\u001b[A\n",
      "validation minibatch loop:  50%|█████     | 158/315 [01:35<01:35,  1.65it/s]\u001b[A\n",
      "validation minibatch loop:  50%|█████     | 159/315 [01:36<01:34,  1.64it/s]\u001b[A\n",
      "validation minibatch loop:  51%|█████     | 160/315 [01:36<01:33,  1.65it/s]\u001b[A\n",
      "validation minibatch loop:  51%|█████     | 161/315 [01:37<01:32,  1.66it/s]\u001b[A\n",
      "validation minibatch loop:  51%|█████▏    | 162/315 [01:38<01:31,  1.66it/s]\u001b[A\n",
      "validation minibatch loop:  52%|█████▏    | 163/315 [01:38<01:32,  1.65it/s]\u001b[A\n",
      "validation minibatch loop:  52%|█████▏    | 164/315 [01:39<01:31,  1.65it/s]\u001b[A\n",
      "validation minibatch loop:  52%|█████▏    | 165/315 [01:39<01:30,  1.65it/s]\u001b[A\n",
      "validation minibatch loop:  53%|█████▎    | 166/315 [01:40<01:31,  1.63it/s]\u001b[A\n",
      "validation minibatch loop:  53%|█████▎    | 167/315 [01:41<01:30,  1.64it/s]\u001b[A\n",
      "validation minibatch loop:  53%|█████▎    | 168/315 [01:41<01:29,  1.64it/s]\u001b[A\n",
      "validation minibatch loop:  54%|█████▎    | 169/315 [01:42<01:29,  1.63it/s]\u001b[A\n",
      "validation minibatch loop:  54%|█████▍    | 170/315 [01:43<01:28,  1.63it/s]\u001b[A\n",
      "validation minibatch loop:  54%|█████▍    | 171/315 [01:43<01:27,  1.65it/s]\u001b[A\n",
      "validation minibatch loop:  55%|█████▍    | 172/315 [01:44<01:26,  1.66it/s]\u001b[A\n",
      "validation minibatch loop:  55%|█████▍    | 173/315 [01:44<01:25,  1.66it/s]\u001b[A\n",
      "validation minibatch loop:  55%|█████▌    | 174/315 [01:45<01:25,  1.65it/s]\u001b[A\n",
      "validation minibatch loop:  56%|█████▌    | 175/315 [01:46<01:24,  1.66it/s]\u001b[A\n",
      "validation minibatch loop:  56%|█████▌    | 176/315 [01:46<01:24,  1.65it/s]\u001b[A\n",
      "validation minibatch loop:  56%|█████▌    | 177/315 [01:47<01:23,  1.66it/s]\u001b[A\n",
      "validation minibatch loop:  57%|█████▋    | 178/315 [01:47<01:22,  1.65it/s]\u001b[A\n",
      "validation minibatch loop:  57%|█████▋    | 179/315 [01:48<01:22,  1.66it/s]\u001b[A\n",
      "validation minibatch loop:  57%|█████▋    | 180/315 [01:49<01:21,  1.66it/s]\u001b[A\n",
      "validation minibatch loop:  57%|█████▋    | 181/315 [01:49<01:21,  1.65it/s]\u001b[A\n",
      "validation minibatch loop:  58%|█████▊    | 182/315 [01:50<01:20,  1.65it/s]\u001b[A\n",
      "validation minibatch loop:  58%|█████▊    | 183/315 [01:50<01:20,  1.65it/s]\u001b[A\n",
      "validation minibatch loop:  58%|█████▊    | 184/315 [01:51<01:20,  1.63it/s]\u001b[A\n",
      "validation minibatch loop:  59%|█████▊    | 185/315 [01:52<01:19,  1.64it/s]\u001b[A\n",
      "validation minibatch loop:  59%|█████▉    | 186/315 [01:52<01:19,  1.62it/s]\u001b[A\n",
      "validation minibatch loop:  59%|█████▉    | 187/315 [01:53<01:20,  1.60it/s]\u001b[A\n",
      "validation minibatch loop:  60%|█████▉    | 188/315 [01:54<01:20,  1.59it/s]\u001b[A\n",
      "validation minibatch loop:  60%|██████    | 189/315 [01:54<01:17,  1.62it/s]\u001b[A\n",
      "validation minibatch loop:  60%|██████    | 190/315 [01:55<01:17,  1.62it/s]\u001b[A\n",
      "validation minibatch loop:  61%|██████    | 191/315 [01:55<01:17,  1.61it/s]\u001b[A\n",
      "validation minibatch loop:  61%|██████    | 192/315 [01:56<01:16,  1.62it/s]\u001b[A\n",
      "validation minibatch loop:  61%|██████▏   | 193/315 [01:57<01:14,  1.63it/s]\u001b[A\n",
      "validation minibatch loop:  62%|██████▏   | 194/315 [01:57<01:15,  1.61it/s]\u001b[A\n",
      "validation minibatch loop:  62%|██████▏   | 195/315 [01:58<01:14,  1.62it/s]\u001b[A\n",
      "validation minibatch loop:  62%|██████▏   | 196/315 [01:58<01:14,  1.60it/s]\u001b[A\n",
      "validation minibatch loop:  63%|██████▎   | 197/315 [01:59<01:14,  1.59it/s]\u001b[A\n",
      "validation minibatch loop:  63%|██████▎   | 198/315 [02:00<01:12,  1.62it/s]\u001b[A\n",
      "validation minibatch loop:  63%|██████▎   | 199/315 [02:00<01:11,  1.63it/s]\u001b[A\n",
      "validation minibatch loop:  63%|██████▎   | 200/315 [02:01<01:09,  1.64it/s]\u001b[A\n",
      "validation minibatch loop:  64%|██████▍   | 201/315 [02:02<01:09,  1.65it/s]\u001b[A\n",
      "validation minibatch loop:  64%|██████▍   | 202/315 [02:02<01:08,  1.65it/s]\u001b[A\n",
      "validation minibatch loop:  64%|██████▍   | 203/315 [02:03<01:07,  1.65it/s]\u001b[A\n",
      "validation minibatch loop:  65%|██████▍   | 204/315 [02:03<01:06,  1.67it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "validation minibatch loop:  65%|██████▌   | 205/315 [02:04<01:07,  1.62it/s]\u001b[A\n",
      "validation minibatch loop:  65%|██████▌   | 206/315 [02:05<01:06,  1.64it/s]\u001b[A\n",
      "validation minibatch loop:  66%|██████▌   | 207/315 [02:05<01:07,  1.61it/s]\u001b[A\n",
      "validation minibatch loop:  66%|██████▌   | 208/315 [02:06<01:05,  1.62it/s]\u001b[A\n",
      "validation minibatch loop:  66%|██████▋   | 209/315 [02:06<01:04,  1.64it/s]\u001b[A\n",
      "validation minibatch loop:  67%|██████▋   | 210/315 [02:07<01:03,  1.65it/s]\u001b[A\n",
      "validation minibatch loop:  67%|██████▋   | 211/315 [02:08<01:02,  1.66it/s]\u001b[A\n",
      "validation minibatch loop:  67%|██████▋   | 212/315 [02:08<01:01,  1.66it/s]\u001b[A\n",
      "validation minibatch loop:  68%|██████▊   | 213/315 [02:09<01:02,  1.64it/s]\u001b[A\n",
      "validation minibatch loop:  68%|██████▊   | 214/315 [02:09<01:01,  1.65it/s]\u001b[A\n",
      "validation minibatch loop:  68%|██████▊   | 215/315 [02:10<01:00,  1.65it/s]\u001b[A\n",
      "validation minibatch loop:  69%|██████▊   | 216/315 [02:11<00:59,  1.66it/s]\u001b[A\n",
      "validation minibatch loop:  69%|██████▉   | 217/315 [02:11<00:59,  1.65it/s]\u001b[A\n",
      "validation minibatch loop:  69%|██████▉   | 218/315 [02:12<00:58,  1.65it/s]\u001b[A\n",
      "validation minibatch loop:  70%|██████▉   | 219/315 [02:12<00:57,  1.66it/s]\u001b[A\n",
      "validation minibatch loop:  70%|██████▉   | 220/315 [02:13<00:57,  1.65it/s]\u001b[A\n",
      "validation minibatch loop:  70%|███████   | 221/315 [02:14<00:56,  1.66it/s]\u001b[A\n",
      "validation minibatch loop:  70%|███████   | 222/315 [02:14<00:56,  1.65it/s]\u001b[A\n",
      "validation minibatch loop:  71%|███████   | 223/315 [02:15<00:55,  1.65it/s]\u001b[A\n",
      "validation minibatch loop:  71%|███████   | 224/315 [02:15<00:55,  1.65it/s]\u001b[A\n",
      "validation minibatch loop:  71%|███████▏  | 225/315 [02:16<00:54,  1.66it/s]\u001b[A\n",
      "validation minibatch loop:  72%|███████▏  | 226/315 [02:17<00:53,  1.65it/s]\u001b[A\n",
      "validation minibatch loop:  72%|███████▏  | 227/315 [02:17<00:53,  1.66it/s]\u001b[A\n",
      "validation minibatch loop:  72%|███████▏  | 228/315 [02:18<00:52,  1.66it/s]\u001b[A\n",
      "validation minibatch loop:  73%|███████▎  | 229/315 [02:18<00:51,  1.67it/s]\u001b[A\n",
      "validation minibatch loop:  73%|███████▎  | 230/315 [02:19<00:50,  1.67it/s]\u001b[A\n",
      "validation minibatch loop:  73%|███████▎  | 231/315 [02:20<00:50,  1.66it/s]\u001b[A\n",
      "validation minibatch loop:  74%|███████▎  | 232/315 [02:20<00:49,  1.67it/s]\u001b[A\n",
      "validation minibatch loop:  74%|███████▍  | 233/315 [02:21<00:49,  1.66it/s]\u001b[A\n",
      "validation minibatch loop:  74%|███████▍  | 234/315 [02:21<00:48,  1.67it/s]\u001b[A\n",
      "validation minibatch loop:  75%|███████▍  | 235/315 [02:22<00:48,  1.67it/s]\u001b[A\n",
      "validation minibatch loop:  75%|███████▍  | 236/315 [02:23<00:47,  1.66it/s]\u001b[A\n",
      "validation minibatch loop:  75%|███████▌  | 237/315 [02:23<00:46,  1.67it/s]\u001b[A\n",
      "validation minibatch loop:  76%|███████▌  | 238/315 [02:24<00:46,  1.67it/s]\u001b[A\n",
      "validation minibatch loop:  76%|███████▌  | 239/315 [02:24<00:45,  1.67it/s]\u001b[A\n",
      "validation minibatch loop:  76%|███████▌  | 240/315 [02:25<00:46,  1.63it/s]\u001b[A\n",
      "validation minibatch loop:  77%|███████▋  | 241/315 [02:26<00:44,  1.65it/s]\u001b[A\n",
      "validation minibatch loop:  77%|███████▋  | 242/315 [02:26<00:44,  1.65it/s]\u001b[A\n",
      "validation minibatch loop:  77%|███████▋  | 243/315 [02:27<00:43,  1.66it/s]\u001b[A\n",
      "validation minibatch loop:  77%|███████▋  | 244/315 [02:28<00:42,  1.66it/s]\u001b[A\n",
      "validation minibatch loop:  78%|███████▊  | 245/315 [02:28<00:42,  1.66it/s]\u001b[A\n",
      "validation minibatch loop:  78%|███████▊  | 246/315 [02:29<00:41,  1.67it/s]\u001b[A\n",
      "validation minibatch loop:  78%|███████▊  | 247/315 [02:29<00:40,  1.67it/s]\u001b[A\n",
      "validation minibatch loop:  79%|███████▊  | 248/315 [02:30<00:40,  1.67it/s]\u001b[A\n",
      "validation minibatch loop:  79%|███████▉  | 249/315 [02:31<00:39,  1.67it/s]\u001b[A\n",
      "validation minibatch loop:  79%|███████▉  | 250/315 [02:31<00:38,  1.67it/s]\u001b[A\n",
      "validation minibatch loop:  80%|███████▉  | 251/315 [02:32<00:38,  1.67it/s]\u001b[A\n",
      "validation minibatch loop:  80%|████████  | 252/315 [02:32<00:37,  1.67it/s]\u001b[A\n",
      "validation minibatch loop:  80%|████████  | 253/315 [02:33<00:37,  1.67it/s]\u001b[A\n",
      "validation minibatch loop:  81%|████████  | 254/315 [02:34<00:36,  1.67it/s]\u001b[A\n",
      "validation minibatch loop:  81%|████████  | 255/315 [02:34<00:36,  1.66it/s]\u001b[A\n",
      "validation minibatch loop:  81%|████████▏ | 256/315 [02:35<00:35,  1.66it/s]\u001b[A\n",
      "validation minibatch loop:  82%|████████▏ | 257/315 [02:35<00:35,  1.65it/s]\u001b[A\n",
      "validation minibatch loop:  82%|████████▏ | 258/315 [02:36<00:34,  1.64it/s]\u001b[A\n",
      "validation minibatch loop:  82%|████████▏ | 259/315 [02:37<00:33,  1.65it/s]\u001b[A\n",
      "validation minibatch loop:  83%|████████▎ | 260/315 [02:37<00:33,  1.64it/s]\u001b[A\n",
      "validation minibatch loop:  83%|████████▎ | 261/315 [02:38<00:32,  1.64it/s]\u001b[A\n",
      "validation minibatch loop:  83%|████████▎ | 262/315 [02:38<00:32,  1.64it/s]\u001b[A\n",
      "validation minibatch loop:  83%|████████▎ | 263/315 [02:39<00:31,  1.64it/s]\u001b[A\n",
      "validation minibatch loop:  84%|████████▍ | 264/315 [02:40<00:30,  1.66it/s]\u001b[A\n",
      "validation minibatch loop:  84%|████████▍ | 265/315 [02:40<00:30,  1.65it/s]\u001b[A\n",
      "validation minibatch loop:  84%|████████▍ | 266/315 [02:41<00:30,  1.63it/s]\u001b[A\n",
      "validation minibatch loop:  85%|████████▍ | 267/315 [02:41<00:29,  1.64it/s]\u001b[A\n",
      "validation minibatch loop:  85%|████████▌ | 268/315 [02:42<00:28,  1.65it/s]\u001b[A\n",
      "validation minibatch loop:  85%|████████▌ | 269/315 [02:43<00:28,  1.64it/s]\u001b[A\n",
      "validation minibatch loop:  86%|████████▌ | 270/315 [02:43<00:27,  1.64it/s]\u001b[A\n",
      "validation minibatch loop:  86%|████████▌ | 271/315 [02:44<00:26,  1.66it/s]\u001b[A\n",
      "validation minibatch loop:  86%|████████▋ | 272/315 [02:44<00:25,  1.66it/s]\u001b[A\n",
      "validation minibatch loop:  87%|████████▋ | 273/315 [02:45<00:25,  1.62it/s]\u001b[A\n",
      "validation minibatch loop:  87%|████████▋ | 274/315 [02:46<00:25,  1.61it/s]\u001b[A\n",
      "validation minibatch loop:  87%|████████▋ | 275/315 [02:46<00:24,  1.62it/s]\u001b[A\n",
      "validation minibatch loop:  88%|████████▊ | 276/315 [02:47<00:23,  1.63it/s]\u001b[A\n",
      "validation minibatch loop:  88%|████████▊ | 277/315 [02:48<00:23,  1.63it/s]\u001b[A\n",
      "validation minibatch loop:  88%|████████▊ | 278/315 [02:48<00:22,  1.63it/s]\u001b[A\n",
      "validation minibatch loop:  89%|████████▊ | 279/315 [02:49<00:21,  1.64it/s]\u001b[A\n",
      "validation minibatch loop:  89%|████████▉ | 280/315 [02:49<00:21,  1.65it/s]\u001b[A\n",
      "validation minibatch loop:  89%|████████▉ | 281/315 [02:50<00:20,  1.66it/s]\u001b[A\n",
      "validation minibatch loop:  90%|████████▉ | 282/315 [02:51<00:19,  1.66it/s]\u001b[A\n",
      "validation minibatch loop:  90%|████████▉ | 283/315 [02:51<00:19,  1.66it/s]\u001b[A\n",
      "validation minibatch loop:  90%|█████████ | 284/315 [02:52<00:18,  1.65it/s]\u001b[A\n",
      "validation minibatch loop:  90%|█████████ | 285/315 [02:52<00:18,  1.64it/s]\u001b[A\n",
      "validation minibatch loop:  91%|█████████ | 286/315 [02:53<00:17,  1.65it/s]\u001b[A\n",
      "validation minibatch loop:  91%|█████████ | 287/315 [02:54<00:17,  1.61it/s]\u001b[A\n",
      "validation minibatch loop:  91%|█████████▏| 288/315 [02:54<00:16,  1.63it/s]\u001b[A\n",
      "validation minibatch loop:  92%|█████████▏| 289/315 [02:55<00:15,  1.64it/s]\u001b[A\n",
      "validation minibatch loop:  92%|█████████▏| 290/315 [02:56<00:15,  1.60it/s]\u001b[A\n",
      "validation minibatch loop:  92%|█████████▏| 291/315 [02:56<00:14,  1.62it/s]\u001b[A\n",
      "validation minibatch loop:  93%|█████████▎| 292/315 [02:57<00:14,  1.60it/s]\u001b[A\n",
      "validation minibatch loop:  93%|█████████▎| 293/315 [02:57<00:13,  1.62it/s]\u001b[A\n",
      "validation minibatch loop:  93%|█████████▎| 294/315 [02:58<00:12,  1.64it/s]\u001b[A\n",
      "validation minibatch loop:  94%|█████████▎| 295/315 [02:59<00:12,  1.65it/s]\u001b[A\n",
      "validation minibatch loop:  94%|█████████▍| 296/315 [02:59<00:11,  1.64it/s]\u001b[A\n",
      "validation minibatch loop:  94%|█████████▍| 297/315 [03:00<00:10,  1.65it/s]\u001b[A\n",
      "validation minibatch loop:  95%|█████████▍| 298/315 [03:00<00:10,  1.66it/s]\u001b[A\n",
      "validation minibatch loop:  95%|█████████▍| 299/315 [03:01<00:09,  1.63it/s]\u001b[A\n",
      "validation minibatch loop:  95%|█████████▌| 300/315 [03:02<00:09,  1.64it/s]\u001b[A\n",
      "validation minibatch loop:  96%|█████████▌| 301/315 [03:02<00:08,  1.64it/s]\u001b[A\n",
      "validation minibatch loop:  96%|█████████▌| 302/315 [03:03<00:07,  1.65it/s]\u001b[A\n",
      "validation minibatch loop:  96%|█████████▌| 303/315 [03:03<00:07,  1.63it/s]\u001b[A\n",
      "validation minibatch loop:  97%|█████████▋| 304/315 [03:04<00:06,  1.64it/s]\u001b[A\n",
      "validation minibatch loop:  97%|█████████▋| 305/315 [03:05<00:06,  1.64it/s]\u001b[A\n",
      "validation minibatch loop:  97%|█████████▋| 306/315 [03:05<00:05,  1.64it/s]\u001b[A\n",
      "validation minibatch loop:  97%|█████████▋| 307/315 [03:06<00:04,  1.64it/s]\u001b[A\n",
      "validation minibatch loop:  98%|█████████▊| 308/315 [03:07<00:04,  1.61it/s]\u001b[A\n",
      "validation minibatch loop:  98%|█████████▊| 309/315 [03:07<00:03,  1.61it/s]\u001b[A\n",
      "validation minibatch loop:  98%|█████████▊| 310/315 [03:08<00:03,  1.63it/s]\u001b[A\n",
      "validation minibatch loop:  99%|█████████▊| 311/315 [03:08<00:02,  1.63it/s]\u001b[A\n",
      "validation minibatch loop:  99%|█████████▉| 312/315 [03:09<00:01,  1.61it/s]\u001b[A\n",
      "validation minibatch loop:  99%|█████████▉| 313/315 [03:10<00:01,  1.61it/s]\u001b[A\n",
      "validation minibatch loop: 100%|█████████▉| 314/315 [03:10<00:00,  1.61it/s]\u001b[A\n",
      "validation minibatch loop: 100%|██████████| 315/315 [03:11<00:00,  1.67it/s]\u001b[A\n",
      "\u001b[A"
     ]
    }
   ],
   "source": [
    "real_Y, predict_Y, real_depends, predict_depends = [], [], [], []\n",
    "\n",
    "pbar = tqdm(\n",
    "    range(0, len(test_X), batch_size), desc = 'validation minibatch loop'\n",
    ")\n",
    "for i in pbar:\n",
    "    batch_x = test_X[i : min(i + batch_size, test_X.shape[0])]\n",
    "    batch_char = test_char[i : min(i + batch_size, test_X.shape[0])]\n",
    "    batch_y = test_Y[i : min(i + batch_size, test_X.shape[0])]\n",
    "    batch_depends = test_depends[i : min(i + batch_size, test_X.shape[0])]\n",
    "    seq, deps = sess.run([model.tags_seq, model.tags_seq_depends],\n",
    "            feed_dict = {\n",
    "                model.word_ids: batch_x,\n",
    "                model.char_ids: batch_char,\n",
    "            },\n",
    "    )\n",
    "    predicted = pred2label(seq)\n",
    "    real = pred2label(batch_y)\n",
    "    predict_Y.extend(predicted)\n",
    "    real_Y.extend(real)\n",
    "    \n",
    "    real_depends.extend(batch_depends.tolist())\n",
    "    predict_depends.extend(deps.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "          PAD     1.0000    1.0000    1.0000    843055\n",
      "          acl     0.9406    0.9296    0.9351      2983\n",
      "        advcl     0.8924    0.8613    0.8766      1175\n",
      "       advmod     0.9549    0.9482    0.9515      4712\n",
      "         amod     0.9296    0.9100    0.9197      4135\n",
      "        appos     0.9312    0.9570    0.9439      2488\n",
      "          aux     1.0000    1.0000    1.0000         5\n",
      "         case     0.9809    0.9823    0.9816     10557\n",
      "           cc     0.9676    0.9795    0.9735      3170\n",
      "        ccomp     0.8598    0.8045    0.8312       404\n",
      "     compound     0.9201    0.9464    0.9331      6605\n",
      "compound:plur     0.9597    0.9630    0.9613       594\n",
      "         conj     0.9600    0.9572    0.9586      4158\n",
      "          cop     0.9670    0.9720    0.9695       966\n",
      "        csubj     0.8929    0.8333    0.8621        30\n",
      "   csubj:pass     0.8000    0.6667    0.7273        12\n",
      "          dep     0.8189    0.9259    0.8691       459\n",
      "          det     0.9558    0.9369    0.9463      4041\n",
      "        fixed     0.9337    0.8953    0.9141       535\n",
      "         flat     0.9724    0.9714    0.9719     10479\n",
      "         iobj     0.9286    0.7222    0.8125        18\n",
      "         mark     0.9210    0.9491    0.9349      1376\n",
      "         nmod     0.9355    0.9324    0.9340      3921\n",
      "        nsubj     0.9430    0.9538    0.9484      6345\n",
      "   nsubj:pass     0.9458    0.9053    0.9251      1985\n",
      "       nummod     0.9762    0.9787    0.9775      3854\n",
      "          obj     0.9495    0.9465    0.9480      5162\n",
      "          obl     0.9458    0.9543    0.9500      5599\n",
      "    parataxis     0.9268    0.8283    0.8748       367\n",
      "        punct     0.9978    0.9968    0.9973     16549\n",
      "         root     0.9743    0.9643    0.9693      5037\n",
      "        xcomp     0.8878    0.9039    0.8958      1217\n",
      "\n",
      "  avg / total     0.9953    0.9953    0.9953    951993\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(np.array(real_Y).ravel(), np.array(predict_Y).ravel(), digits = 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     1.0000    1.0000    1.0000    843055\n",
      "          1     0.9718    0.9633    0.9675      5037\n",
      "          2     0.9604    0.9459    0.9531      4285\n",
      "          3     0.9474    0.9557    0.9515      4971\n",
      "          4     0.9575    0.9647    0.9611      6594\n",
      "          5     0.9534    0.9665    0.9599      5880\n",
      "          6     0.9648    0.9632    0.9640      6037\n",
      "          7     0.9512    0.9654    0.9582      5548\n",
      "          8     0.9611    0.9623    0.9617      5542\n",
      "          9     0.9729    0.9498    0.9612      4877\n",
      "         10     0.9614    0.9621    0.9617      4559\n",
      "         11     0.9495    0.9588    0.9541      4316\n",
      "         12     0.9547    0.9573    0.9560      3698\n",
      "         13     0.9664    0.9506    0.9584      3600\n",
      "         14     0.9652    0.9590    0.9621      3294\n",
      "         15     0.9619    0.9541    0.9580      3179\n",
      "         16     0.9604    0.9573    0.9589      3117\n",
      "         17     0.9634    0.9587    0.9610      2831\n",
      "         18     0.9406    0.9594    0.9499      2392\n",
      "         19     0.9657    0.9582    0.9619      2176\n",
      "         20     0.9656    0.9615    0.9635      2102\n",
      "         21     0.9523    0.9577    0.9550      1960\n",
      "         22     0.9519    0.9586    0.9552      1859\n",
      "         23     0.9605    0.9555    0.9580      1732\n",
      "         24     0.9649    0.9474    0.9561      1540\n",
      "         25     0.9399    0.9503    0.9451      1349\n",
      "         26     0.9680    0.9333    0.9503      1199\n",
      "         27     0.9246    0.9604    0.9422      1111\n",
      "         28     0.9491    0.9561    0.9526       956\n",
      "         29     0.9578    0.9646    0.9612       989\n",
      "         30     0.9365    0.9513    0.9438      1007\n",
      "         31     0.9483    0.9592    0.9537       784\n",
      "         32     0.9352    0.9545    0.9448       726\n",
      "         33     0.9468    0.9290    0.9378       690\n",
      "         34     0.9575    0.9464    0.9519       690\n",
      "         35     0.9480    0.9231    0.9354       533\n",
      "         36     0.9532    0.9432    0.9481       475\n",
      "         37     0.9511    0.9340    0.9425       500\n",
      "         38     0.9455    0.9139    0.9294       418\n",
      "         39     0.9326    0.9708    0.9513       342\n",
      "         40     0.9361    0.9338    0.9350       408\n",
      "         41     0.9260    0.9602    0.9428       352\n",
      "         42     0.9649    0.9615    0.9632       286\n",
      "         43     0.9418    0.9487    0.9453       273\n",
      "         44     0.9125    0.9389    0.9255       311\n",
      "         45     0.9406    0.9556    0.9480       315\n",
      "         46     0.9703    0.9655    0.9679       203\n",
      "         47     0.9662    0.9542    0.9602       240\n",
      "         48     0.9065    0.9065    0.9065       214\n",
      "         49     0.9455    0.9720    0.9585       214\n",
      "         50     0.9315    0.9189    0.9252       148\n",
      "         51     0.9356    0.9265    0.9310       204\n",
      "         52     0.9257    0.9580    0.9416       143\n",
      "         53     0.9496    0.9231    0.9362       143\n",
      "         54     0.9381    0.9430    0.9406       193\n",
      "         55     0.9837    0.9237    0.9528       131\n",
      "         56     0.8532    0.9688    0.9073        96\n",
      "         57     0.9604    0.9510    0.9557       102\n",
      "         58     0.9633    0.9459    0.9545       111\n",
      "         59     0.9870    0.8837    0.9325        86\n",
      "         60     1.0000    0.9559    0.9774        68\n",
      "         61     0.9429    0.9519    0.9474       104\n",
      "         62     0.9726    0.8875    0.9281        80\n",
      "         63     0.9459    0.9589    0.9524        73\n",
      "         64     0.9385    0.9531    0.9457        64\n",
      "         65     1.0000    0.8833    0.9381        60\n",
      "         66     0.8676    0.9516    0.9077        62\n",
      "         67     0.9020    0.8519    0.8762        54\n",
      "         68     0.9683    0.9242    0.9457        66\n",
      "         69     0.9474    0.9351    0.9412        77\n",
      "         70     0.8406    0.8923    0.8657        65\n",
      "         71     0.9474    0.9818    0.9643        55\n",
      "         72     0.9722    0.9459    0.9589        37\n",
      "         73     0.9796    0.9600    0.9697        50\n",
      "         74     0.9630    0.9630    0.9630        27\n",
      "         75     0.9750    1.0000    0.9873        39\n",
      "         76     0.9655    1.0000    0.9825        28\n",
      "         77     0.9655    0.9333    0.9492        30\n",
      "         78     1.0000    1.0000    1.0000        24\n",
      "         79     0.9677    1.0000    0.9836        30\n",
      "         80     0.9608    0.9074    0.9333        54\n",
      "         81     0.9167    1.0000    0.9565        11\n",
      "         82     0.9074    0.9423    0.9245        52\n",
      "         83     0.9259    1.0000    0.9615        25\n",
      "         84     0.9677    1.0000    0.9836        30\n",
      "         85     1.0000    1.0000    1.0000        14\n",
      "         86     1.0000    0.9412    0.9697        34\n",
      "         87     1.0000    1.0000    1.0000        22\n",
      "         88     1.0000    1.0000    1.0000         8\n",
      "         89     1.0000    1.0000    1.0000        14\n",
      "         90     1.0000    1.0000    1.0000        18\n",
      "         91     0.9677    0.8824    0.9231        34\n",
      "         92     0.8182    1.0000    0.9000         9\n",
      "         93     0.9444    0.9444    0.9444        18\n",
      "         94     1.0000    0.9444    0.9714        18\n",
      "         95     0.9259    0.9615    0.9434        26\n",
      "         96     1.0000    1.0000    1.0000         8\n",
      "         97     1.0000    1.0000    1.0000         2\n",
      "         98     1.0000    1.0000    1.0000        16\n",
      "         99     0.9697    0.8649    0.9143        37\n",
      "        100     1.0000    1.0000    1.0000         2\n",
      "        101     1.0000    1.0000    1.0000        44\n",
      "        102     1.0000    1.0000    1.0000        15\n",
      "        103     0.8889    1.0000    0.9412         8\n",
      "        104     0.8269    0.9773    0.8958        44\n",
      "        105     1.0000    1.0000    1.0000         6\n",
      "        106     1.0000    1.0000    1.0000         7\n",
      "        107     1.0000    1.0000    1.0000        10\n",
      "        108     0.9412    1.0000    0.9697        32\n",
      "        109     1.0000    1.0000    1.0000        13\n",
      "        110     1.0000    1.0000    1.0000         9\n",
      "        111     1.0000    1.0000    1.0000         1\n",
      "        112     1.0000    0.7826    0.8780        23\n",
      "        113     1.0000    1.0000    1.0000        16\n",
      "        114     0.8333    1.0000    0.9091         5\n",
      "        115     1.0000    1.0000    1.0000         1\n",
      "        116     0.9130    0.9545    0.9333        22\n",
      "        117     1.0000    1.0000    1.0000         5\n",
      "        118     0.0000    0.0000    0.0000         0\n",
      "        119     1.0000    1.0000    1.0000         3\n",
      "        120     1.0000    1.0000    1.0000        15\n",
      "        122     1.0000    1.0000    1.0000         8\n",
      "        123     1.0000    1.0000    1.0000         4\n",
      "        125     1.0000    1.0000    1.0000        10\n",
      "        126     1.0000    1.0000    1.0000         2\n",
      "        129     1.0000    1.0000    1.0000         8\n",
      "        133     1.0000    1.0000    1.0000         4\n",
      "        135     1.0000    1.0000    1.0000         3\n",
      "        136     1.0000    1.0000    1.0000         2\n",
      "        139     1.0000    1.0000    1.0000         1\n",
      "        142     1.0000    1.0000    1.0000         2\n",
      "        146     1.0000    1.0000    1.0000         1\n",
      "        151     1.0000    1.0000    1.0000         1\n",
      "\n",
      "avg / total     0.9951    0.9951    0.9951    951993\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(np.array(real_depends).ravel(), \n",
    "                            np.array(predict_depends).ravel(), digits = 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tolong', 'tangkap', 'gambar', 'kami']"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string = 'tolong tangkap gambar kami'\n",
    "\n",
    "def char_str_idx(corpus, dic, UNK = 0):\n",
    "    maxlen = max([len(i) for i in corpus])\n",
    "    X = np.zeros((len(corpus), maxlen))\n",
    "    for i in range(len(corpus)):\n",
    "        for no, k in enumerate(corpus[i][:maxlen]):\n",
    "            val = dic[k] if k in dic else UNK\n",
    "            X[i, no] = val\n",
    "    return X\n",
    "\n",
    "def generate_char_seq(batch, UNK = 2):\n",
    "    maxlen_c = max([len(k) for k in batch])\n",
    "    x = [[len(i) for i in k] for k in batch]\n",
    "    maxlen = max([j for i in x for j in i])\n",
    "    temp = np.zeros((len(batch),maxlen_c,maxlen),dtype=np.int32)\n",
    "    for i in range(len(batch)):\n",
    "        for k in range(len(batch[i])):\n",
    "            for no, c in enumerate(batch[i][k][::-1]):\n",
    "                temp[i,k,-1-no] = char2idx.get(c, UNK)\n",
    "    return temp\n",
    "\n",
    "sequence = process_string(string)\n",
    "sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_seq = char_str_idx([sequence], word2idx, 2)\n",
    "X_char_seq = generate_char_seq([sequence])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 4, 7)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_char_seq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq, deps = sess.run([model.tags_seq, model.tags_seq_depends],\n",
    "        feed_dict={model.word_ids:X_seq,\n",
    "                  model.char_ids:X_char_seq})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 2, 3], dtype=int32)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deps[0] - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['advmod', 'obj', 'compound', 'det']"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[idx2tag[i] for i in seq[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Placeholder',\n",
       " 'Placeholder_1',\n",
       " 'Placeholder_2',\n",
       " 'Placeholder_3',\n",
       " 'Variable',\n",
       " 'Variable_1',\n",
       " 'bidirectional_rnn_char_0/fw/lstm_cell/kernel',\n",
       " 'bidirectional_rnn_char_0/fw/lstm_cell/bias',\n",
       " 'bidirectional_rnn_char_0/bw/lstm_cell/kernel',\n",
       " 'bidirectional_rnn_char_0/bw/lstm_cell/bias',\n",
       " 'bidirectional_rnn_char_1/fw/lstm_cell/kernel',\n",
       " 'bidirectional_rnn_char_1/fw/lstm_cell/bias',\n",
       " 'bidirectional_rnn_char_1/bw/lstm_cell/kernel',\n",
       " 'bidirectional_rnn_char_1/bw/lstm_cell/bias',\n",
       " 'memory_layer/kernel',\n",
       " 'memory_layer_1/kernel',\n",
       " 'bidirectional_rnn_word_0/fw/attention_wrapper/lstm_cell/kernel',\n",
       " 'bidirectional_rnn_word_0/fw/attention_wrapper/lstm_cell/bias',\n",
       " 'bidirectional_rnn_word_0/fw/attention_wrapper/bahdanau_attention/query_layer/kernel',\n",
       " 'bidirectional_rnn_word_0/fw/attention_wrapper/bahdanau_attention/attention_v',\n",
       " 'bidirectional_rnn_word_0/fw/attention_wrapper/attention_layer/kernel',\n",
       " 'bidirectional_rnn_word_0/bw/attention_wrapper/lstm_cell/kernel',\n",
       " 'bidirectional_rnn_word_0/bw/attention_wrapper/lstm_cell/bias',\n",
       " 'bidirectional_rnn_word_0/bw/attention_wrapper/bahdanau_attention/query_layer/kernel',\n",
       " 'bidirectional_rnn_word_0/bw/attention_wrapper/bahdanau_attention/attention_v',\n",
       " 'bidirectional_rnn_word_0/bw/attention_wrapper/attention_layer/kernel',\n",
       " 'memory_layer_2/kernel',\n",
       " 'memory_layer_3/kernel',\n",
       " 'bidirectional_rnn_word_1/fw/attention_wrapper/lstm_cell/kernel',\n",
       " 'bidirectional_rnn_word_1/fw/attention_wrapper/lstm_cell/bias',\n",
       " 'bidirectional_rnn_word_1/fw/attention_wrapper/bahdanau_attention/query_layer/kernel',\n",
       " 'bidirectional_rnn_word_1/fw/attention_wrapper/bahdanau_attention/attention_v',\n",
       " 'bidirectional_rnn_word_1/fw/attention_wrapper/attention_layer/kernel',\n",
       " 'bidirectional_rnn_word_1/bw/attention_wrapper/lstm_cell/kernel',\n",
       " 'bidirectional_rnn_word_1/bw/attention_wrapper/lstm_cell/bias',\n",
       " 'bidirectional_rnn_word_1/bw/attention_wrapper/bahdanau_attention/query_layer/kernel',\n",
       " 'bidirectional_rnn_word_1/bw/attention_wrapper/bahdanau_attention/attention_v',\n",
       " 'bidirectional_rnn_word_1/bw/attention_wrapper/attention_layer/kernel',\n",
       " 'dense/kernel',\n",
       " 'dense/bias',\n",
       " 'Variable_2',\n",
       " 'bidirectional_rnn_word_1/fw/lstm_cell/kernel',\n",
       " 'bidirectional_rnn_word_1/fw/lstm_cell/bias',\n",
       " 'bidirectional_rnn_word_1/bw/lstm_cell/kernel',\n",
       " 'bidirectional_rnn_word_1/bw/lstm_cell/bias',\n",
       " 'dense_1/kernel',\n",
       " 'dense_1/bias',\n",
       " 'transitions',\n",
       " 'depends/transitions',\n",
       " 'logits',\n",
       " 'logits_depends']"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saver = tf.train.Saver(tf.trainable_variables())\n",
    "saver.save(sess, 'bahdanau-dependency/model.ckpt')\n",
    "\n",
    "strings = ','.join(\n",
    "    [\n",
    "        n.name\n",
    "        for n in tf.get_default_graph().as_graph_def().node\n",
    "        if ('Variable' in n.op\n",
    "        or 'Placeholder' in n.name\n",
    "        or 'logits' in n.name\n",
    "        or 'logits_depends' in n.name\n",
    "        or 'alphas' in n.name)\n",
    "        and 'Adam' not in n.name\n",
    "        and 'beta' not in n.name\n",
    "        and 'OptimizeLoss' not in n.name\n",
    "        and 'Global_Step' not in n.name\n",
    "        and 'Epoch_Step' not in n.name\n",
    "        and 'learning_rate' not in n.name\n",
    "    ]\n",
    ")\n",
    "strings.split(',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('bahdanau-dependency.json','w') as fopen:\n",
    "    fopen.write(json.dumps({'idx2tag':idx2tag,'idx2word':idx2word,\n",
    "           'word2idx':word2idx,'tag2idx':tag2idx,'char2idx':char2idx}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freeze_graph(model_dir, output_node_names):\n",
    "\n",
    "    if not tf.gfile.Exists(model_dir):\n",
    "        raise AssertionError(\n",
    "            \"Export directory doesn't exists. Please specify an export \"\n",
    "            'directory: %s' % model_dir\n",
    "        )\n",
    "\n",
    "    checkpoint = tf.train.get_checkpoint_state(model_dir)\n",
    "    input_checkpoint = checkpoint.model_checkpoint_path\n",
    "\n",
    "    absolute_model_dir = '/'.join(input_checkpoint.split('/')[:-1])\n",
    "    output_graph = absolute_model_dir + '/frozen_model.pb'\n",
    "    clear_devices = True\n",
    "    with tf.Session(graph = tf.Graph()) as sess:\n",
    "        saver = tf.train.import_meta_graph(\n",
    "            input_checkpoint + '.meta', clear_devices = clear_devices\n",
    "        )\n",
    "        saver.restore(sess, input_checkpoint)\n",
    "        output_graph_def = tf.graph_util.convert_variables_to_constants(\n",
    "            sess,\n",
    "            tf.get_default_graph().as_graph_def(),\n",
    "            output_node_names.split(','),\n",
    "        )\n",
    "        with tf.gfile.GFile(output_graph, 'wb') as f:\n",
    "            f.write(output_graph_def.SerializeToString())\n",
    "        print('%d ops in the final graph.' % len(output_graph_def.node))\n",
    "        \n",
    "def load_graph(frozen_graph_filename):\n",
    "    with tf.gfile.GFile(frozen_graph_filename, 'rb') as f:\n",
    "        graph_def = tf.GraphDef()\n",
    "        graph_def.ParseFromString(f.read())\n",
    "    with tf.Graph().as_default() as graph:\n",
    "        tf.import_graph_def(graph_def)\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from bahdanau-dependency/model.ckpt\n",
      "INFO:tensorflow:Froze 45 variables.\n",
      "INFO:tensorflow:Converted 45 variables to const ops.\n",
      "2531 ops in the final graph.\n"
     ]
    }
   ],
   "source": [
    "freeze_graph('bahdanau-dependency', strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = load_graph('bahdanau-dependency/frozen_model.pb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py:1702: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
      "  warnings.warn('An interactive session is already active. This can '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[14 16 13  3]] [[3 1 3 3]]\n"
     ]
    }
   ],
   "source": [
    "word_ids = g.get_tensor_by_name('import/Placeholder:0')\n",
    "char_ids = g.get_tensor_by_name('import/Placeholder_1:0')\n",
    "tags_seq = g.get_tensor_by_name('import/logits:0')\n",
    "depends_seq = g.get_tensor_by_name('import/logits_depends:0')\n",
    "test_sess = tf.InteractiveSession(graph = g)\n",
    "seq, deps = test_sess.run([tags_seq, depends_seq],\n",
    "            feed_dict = {\n",
    "                word_ids: X_seq,\n",
    "                char_ids: X_char_seq,\n",
    "            })\n",
    "\n",
    "print(seq,deps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
