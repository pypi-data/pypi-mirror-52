{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import collections\n",
    "from sklearn import metrics\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from unidecode import unidecode\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import malaya"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = malaya.preprocessing._SocialTokenizer().tokenize\n",
    "rules_normalizer = malaya.texts._tatabahasa.rules_normalizer\n",
    "\n",
    "def is_number_regex(s):\n",
    "    if re.match(\"^\\d+?\\.\\d+?$\", s) is None:\n",
    "        return s.isdigit()\n",
    "    return True\n",
    "\n",
    "def detect_money(word):\n",
    "    if word[:2] == 'rm' and is_number_regex(word[2:]):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def preprocessing(string):\n",
    "    tokenized = tokenizer(unidecode(string))\n",
    "    tokenized = [malaya.stem.naive(w) for w in tokenized]\n",
    "    tokenized = [w.lower() for w in tokenized if len(w) > 1]\n",
    "    tokenized = [rules_normalizer.get(w, w) for w in tokenized]\n",
    "    tokenized = ['<NUM>' if is_number_regex(w) else w for w in tokenized]\n",
    "    tokenized = ['<MONEY>' if detect_money(w) else w for w in tokenized]\n",
    "    return tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataset(words, n_words):\n",
    "    count = [['GO', 0], ['PAD', 1], ['EOS', 2], ['UNK', 3]]\n",
    "    counter = collections.Counter(words).most_common(n_words)\n",
    "    count.extend(counter)\n",
    "    dictionary = dict()\n",
    "    for word, _ in count:\n",
    "        dictionary[word] = len(dictionary)\n",
    "    data = list()\n",
    "    unk_count = 0\n",
    "    for word in words:\n",
    "        index = dictionary.get(word, 3)\n",
    "        if index == 0:\n",
    "            unk_count += 1\n",
    "        data.append(index)\n",
    "    count[0][1] = unk_count\n",
    "    reversed_dictionary = dict(zip(dictionary.values(), dictionary.keys()))\n",
    "    return data, count, dictionary, reversed_dictionary\n",
    "\n",
    "def str_idx(corpus, dic, maxlen, UNK = 3):\n",
    "    X = np.zeros((len(corpus), maxlen))\n",
    "    for i in range(len(corpus)):\n",
    "        for no, k in enumerate(corpus[i][:maxlen][::-1]):\n",
    "            X[i, -1 - no] = dic.get(k, UNK)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('tokenization.json') as fopen:\n",
    "    dataset = json.load(fopen)\n",
    "texts = dataset['texts']\n",
    "labels = dataset['labels']\n",
    "del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('emotion-dictionary.json') as fopen:\n",
    "    d = json.load(fopen)\n",
    "dictionary = d['dictionary']\n",
    "rev_dictionary = d['reverse_dictionary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def position_encoding(inputs):\n",
    "    T = tf.shape(inputs)[1]\n",
    "    repr_dim = inputs.get_shape()[-1].value\n",
    "    pos = tf.reshape(tf.range(0.0, tf.to_float(T), dtype=tf.float32), [-1, 1])\n",
    "    i = np.arange(0, repr_dim, 2, np.float32)\n",
    "    denom = np.reshape(np.power(10000.0, i / repr_dim), [1, -1])\n",
    "    enc = tf.expand_dims(tf.concat([tf.sin(pos / denom), tf.cos(pos / denom)], 1), 0)\n",
    "    return tf.tile(enc, [tf.shape(inputs)[0], 1, 1])\n",
    "\n",
    "def layer_norm(inputs, epsilon=1e-8):\n",
    "    mean, variance = tf.nn.moments(inputs, [-1], keep_dims=True)\n",
    "    normalized = (inputs - mean) / (tf.sqrt(variance + epsilon))\n",
    "    params_shape = inputs.get_shape()[-1:]\n",
    "    gamma = tf.get_variable('gamma', params_shape, tf.float32, tf.ones_initializer())\n",
    "    beta = tf.get_variable('beta', params_shape, tf.float32, tf.zeros_initializer())\n",
    "    return gamma * normalized + beta\n",
    "\n",
    "def Attention(inputs, num_units, num_heads = 8, activation = None):\n",
    "    inputs = tf.layers.dropout(inputs, 0.3, training=True)\n",
    "    T_q = T_k = tf.shape(inputs)[1]\n",
    "    Q_K_V = tf.layers.dense(inputs, 3*num_units, activation)\n",
    "    Q, K, V = tf.split(Q_K_V, 3, -1)\n",
    "    Q_ = tf.concat(tf.split(Q, num_heads, axis=2), 0)\n",
    "    K_ = tf.concat(tf.split(K, num_heads, axis=2), 0)\n",
    "    V_ = tf.concat(tf.split(V, num_heads, axis=2), 0)\n",
    "    align = tf.matmul(Q_, K_, transpose_b=True)\n",
    "    align *= tf.rsqrt(tf.to_float(K_.get_shape()[-1].value))\n",
    "    paddings = tf.fill(tf.shape(align), float('-inf'))\n",
    "    lower_tri = tf.ones([T_q, T_k])\n",
    "    lower_tri = tf.linalg.LinearOperatorLowerTriangular(lower_tri).to_dense()\n",
    "    masks = tf.tile(tf.expand_dims(lower_tri,0), [tf.shape(align)[0],1,1])\n",
    "    align = tf.where(tf.equal(masks, 0), paddings, align)\n",
    "    align = tf.nn.softmax(align)\n",
    "    alignments = tf.transpose(align, [0, 2, 1]) \n",
    "    x = tf.matmul(align, V_)\n",
    "    x = tf.concat(tf.split(x, num_heads, axis=0), 2)\n",
    "    x += inputs\n",
    "    x = layer_norm(x)\n",
    "    return x, alignments\n",
    "\n",
    "class Model:\n",
    "    def __init__(self, size_layer, embed_size, dict_size, dimension_output, learning_rate = 1e-3):\n",
    "        self.X = tf.placeholder(tf.int32, [None, None])\n",
    "        self.Y = tf.placeholder(tf.int32, [None])\n",
    "        \n",
    "        encoder_embeddings = tf.Variable(tf.random_uniform([dict_size, embed_size], -1, 1))\n",
    "        x = tf.nn.embedding_lookup(encoder_embeddings, self.X)\n",
    "        x += position_encoding(x)\n",
    "        x = tf.layers.dropout(x, 0.3, training=True) \n",
    "        \n",
    "        x, self.alignments = Attention(x, size_layer)\n",
    "        self.logits_seq = tf.layers.dense(x, dimension_output)\n",
    "        self.logits_seq = tf.identity(self.logits_seq, name = 'logits_seq')\n",
    "        self.logits = self.logits_seq[:,-1]\n",
    "        self.logits = tf.identity(self.logits, name = 'logits')\n",
    "\n",
    "        self.cost = tf.reduce_mean(\n",
    "            tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "                logits = self.logits, labels = self.Y\n",
    "            )\n",
    "        )\n",
    "        self.optimizer = tf.train.AdamOptimizer(learning_rate).minimize(\n",
    "            self.cost\n",
    "        )\n",
    "        correct_pred = tf.equal(\n",
    "            tf.argmax(self.logits, 1, output_type = tf.int32), self.Y\n",
    "        )\n",
    "        self.accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "        self.attention = tf.identity(tf.reduce_mean(self.alignments[0], 1), name = 'alphas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'only-attention/model.ckpt'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size_layer = 256\n",
    "dimension_output = 6\n",
    "learning_rate = 1e-4\n",
    "batch_size = 32\n",
    "maxlen = 100\n",
    "\n",
    "tf.reset_default_graph()\n",
    "sess = tf.InteractiveSession()\n",
    "model = Model(\n",
    "    size_layer,\n",
    "    size_layer,\n",
    "    len(dictionary),\n",
    "    dimension_output,\n",
    "    learning_rate,\n",
    ")\n",
    "sess.run(tf.global_variables_initializer())\n",
    "saver = tf.train.Saver(tf.trainable_variables())\n",
    "saver.save(sess, 'only-attention/model.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "strings = ','.join(\n",
    "    [\n",
    "        n.name\n",
    "        for n in tf.get_default_graph().as_graph_def().node\n",
    "        if ('Variable' in n.op\n",
    "        or 'Placeholder' in n.name\n",
    "        or 'logits' in n.name\n",
    "        or 'alphas' in n.name)\n",
    "        and 'Adam' not in n.name\n",
    "        and '_power' not in n.name\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Placeholder',\n",
       " 'Placeholder_1',\n",
       " 'Variable',\n",
       " 'dense/kernel',\n",
       " 'dense/bias',\n",
       " 'gamma',\n",
       " 'beta',\n",
       " 'dense_1/kernel',\n",
       " 'dense_1/bias',\n",
       " 'logits_seq',\n",
       " 'logits',\n",
       " 'alphas']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strings.split(',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, test_X, train_Y, test_Y = train_test_split(\n",
    "    texts, labels, test_size = 0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train minibatch loop: 100%|██████████| 10513/10513 [11:49<00:00, 14.91it/s, accuracy=0.75, cost=0.606] \n",
      "test minibatch loop: 100%|██████████| 2629/2629 [00:22<00:00, 116.65it/s, accuracy=0.875, cost=0.331]\n",
      "train minibatch loop:   0%|          | 2/10513 [00:00<11:45, 14.90it/s, accuracy=0.812, cost=0.499]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, pass acc: 0.000000, current acc: 0.727349\n",
      "time taken: 731.6978554725647\n",
      "epoch: 0, training loss: 0.905357, training acc: 0.647174, valid loss: 0.655899, valid acc: 0.727349\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train minibatch loop: 100%|██████████| 10513/10513 [11:47<00:00, 14.86it/s, accuracy=0.75, cost=0.579] \n",
      "test minibatch loop: 100%|██████████| 2629/2629 [00:22<00:00, 116.97it/s, accuracy=1, cost=0.0813]   \n",
      "train minibatch loop:   0%|          | 2/10513 [00:00<11:45, 14.89it/s, accuracy=0.781, cost=0.542]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1, pass acc: 0.727349, current acc: 0.766111\n",
      "time taken: 729.8395171165466\n",
      "epoch: 1, training loss: 0.598457, training acc: 0.750146, valid loss: 0.555720, valid acc: 0.766111\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train minibatch loop: 100%|██████████| 10513/10513 [11:46<00:00, 14.87it/s, accuracy=0.75, cost=0.55]  \n",
      "test minibatch loop: 100%|██████████| 2629/2629 [00:22<00:00, 117.31it/s, accuracy=0.875, cost=0.137]\n",
      "train minibatch loop:   0%|          | 2/10513 [00:00<11:44, 14.93it/s, accuracy=0.875, cost=0.3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2, pass acc: 0.766111, current acc: 0.786443\n",
      "time taken: 729.3791365623474\n",
      "epoch: 2, training loss: 0.527514, training acc: 0.780100, valid loss: 0.507350, valid acc: 0.786443\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train minibatch loop: 100%|██████████| 10513/10513 [11:46<00:00, 14.87it/s, accuracy=0.821, cost=0.478]\n",
      "test minibatch loop: 100%|██████████| 2629/2629 [00:22<00:00, 117.37it/s, accuracy=0.875, cost=0.106]\n",
      "train minibatch loop:   0%|          | 2/10513 [00:00<11:43, 14.95it/s, accuracy=0.812, cost=0.466]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3, pass acc: 0.786443, current acc: 0.801199\n",
      "time taken: 729.3505957126617\n",
      "epoch: 3, training loss: 0.486415, training acc: 0.797101, valid loss: 0.476010, valid acc: 0.801199\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train minibatch loop: 100%|██████████| 10513/10513 [11:46<00:00, 14.88it/s, accuracy=0.893, cost=0.407]\n",
      "test minibatch loop: 100%|██████████| 2629/2629 [00:22<00:00, 117.61it/s, accuracy=0.875, cost=0.121]\n",
      "train minibatch loop:   0%|          | 2/10513 [00:00<11:45, 14.90it/s, accuracy=0.781, cost=0.456]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4, pass acc: 0.801199, current acc: 0.809795\n",
      "time taken: 729.101904630661\n",
      "epoch: 4, training loss: 0.459273, training acc: 0.808106, valid loss: 0.453751, valid acc: 0.809795\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train minibatch loop: 100%|██████████| 10513/10513 [11:46<00:00, 14.88it/s, accuracy=0.75, cost=0.461] \n",
      "test minibatch loop: 100%|██████████| 2629/2629 [00:22<00:00, 117.67it/s, accuracy=0.875, cost=0.145]\n",
      "train minibatch loop:   0%|          | 2/10513 [00:00<11:42, 14.96it/s, accuracy=0.844, cost=0.368]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 5, pass acc: 0.809795, current acc: 0.813564\n",
      "time taken: 728.9868063926697\n",
      "epoch: 5, training loss: 0.439415, training acc: 0.815298, valid loss: 0.440682, valid acc: 0.813564\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train minibatch loop: 100%|██████████| 10513/10513 [11:46<00:00, 14.87it/s, accuracy=0.821, cost=0.406] \n",
      "test minibatch loop: 100%|██████████| 2629/2629 [00:22<00:00, 117.70it/s, accuracy=0.875, cost=0.111]\n",
      "train minibatch loop:   0%|          | 2/10513 [00:00<11:45, 14.90it/s, accuracy=0.812, cost=0.414]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 6, pass acc: 0.813564, current acc: 0.821162\n",
      "time taken: 729.0955126285553\n",
      "epoch: 6, training loss: 0.426599, training acc: 0.819502, valid loss: 0.423938, valid acc: 0.821162\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train minibatch loop: 100%|██████████| 10513/10513 [11:46<00:00, 14.87it/s, accuracy=0.75, cost=0.427]  \n",
      "test minibatch loop: 100%|██████████| 2629/2629 [00:22<00:00, 117.35it/s, accuracy=0.875, cost=0.102] \n",
      "train minibatch loop:   0%|          | 2/10513 [00:00<11:47, 14.87it/s, accuracy=0.812, cost=0.423]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 7, pass acc: 0.821162, current acc: 0.823112\n",
      "time taken: 729.2301309108734\n",
      "epoch: 7, training loss: 0.414481, training acc: 0.823978, valid loss: 0.410924, valid acc: 0.823112\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train minibatch loop: 100%|██████████| 10513/10513 [11:46<00:00, 14.88it/s, accuracy=0.75, cost=0.387]  \n",
      "test minibatch loop: 100%|██████████| 2629/2629 [00:22<00:00, 117.34it/s, accuracy=0.875, cost=0.0979]\n",
      "train minibatch loop:   0%|          | 2/10513 [00:00<11:46, 14.88it/s, accuracy=0.844, cost=0.422]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 8, pass acc: 0.823112, current acc: 0.825835\n",
      "time taken: 729.1006045341492\n",
      "epoch: 8, training loss: 0.403511, training acc: 0.827747, valid loss: 0.406086, valid acc: 0.825835\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train minibatch loop: 100%|██████████| 10513/10513 [11:46<00:00, 14.88it/s, accuracy=0.857, cost=0.407] \n",
      "test minibatch loop: 100%|██████████| 2629/2629 [00:22<00:00, 117.42it/s, accuracy=1, cost=0.0765]    \n",
      "train minibatch loop:   0%|          | 2/10513 [00:00<11:46, 14.88it/s, accuracy=0.75, cost=0.491]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 9, pass acc: 0.825835, current acc: 0.826441\n",
      "time taken: 729.0860552787781\n",
      "epoch: 9, training loss: 0.394586, training acc: 0.830611, valid loss: 0.398988, valid acc: 0.826441\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train minibatch loop: 100%|██████████| 10513/10513 [11:46<00:00, 14.87it/s, accuracy=0.821, cost=0.464]\n",
      "test minibatch loop: 100%|██████████| 2629/2629 [00:22<00:00, 117.66it/s, accuracy=1, cost=0.101]    \n",
      "train minibatch loop:   0%|          | 2/10513 [00:00<11:48, 14.84it/s, accuracy=0.812, cost=0.437]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 10, pass acc: 0.826441, current acc: 0.829271\n",
      "time taken: 729.1331174373627\n",
      "epoch: 10, training loss: 0.387683, training acc: 0.831868, valid loss: 0.390499, valid acc: 0.829271\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train minibatch loop: 100%|██████████| 10513/10513 [11:46<00:00, 14.87it/s, accuracy=0.821, cost=0.324] \n",
      "test minibatch loop: 100%|██████████| 2629/2629 [00:22<00:00, 117.67it/s, accuracy=0.875, cost=0.109]\n",
      "train minibatch loop:   0%|          | 2/10513 [00:00<11:44, 14.92it/s, accuracy=0.75, cost=0.45]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 11, pass acc: 0.829271, current acc: 0.830056\n",
      "time taken: 729.1033494472504\n",
      "epoch: 11, training loss: 0.380850, training acc: 0.834213, valid loss: 0.387611, valid acc: 0.830056\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train minibatch loop: 100%|██████████| 10513/10513 [11:46<00:00, 14.88it/s, accuracy=0.786, cost=0.335]\n",
      "test minibatch loop: 100%|██████████| 2629/2629 [00:22<00:00, 117.54it/s, accuracy=0.875, cost=0.132]\n",
      "train minibatch loop:   0%|          | 2/10513 [00:00<11:47, 14.86it/s, accuracy=0.812, cost=0.368]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 12, pass acc: 0.830056, current acc: 0.831387\n",
      "time taken: 729.0544452667236\n",
      "epoch: 12, training loss: 0.375699, training acc: 0.835616, valid loss: 0.382575, valid acc: 0.831387\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train minibatch loop: 100%|██████████| 10513/10513 [11:46<00:00, 14.88it/s, accuracy=0.893, cost=0.383] \n",
      "test minibatch loop: 100%|██████████| 2629/2629 [00:22<00:00, 117.54it/s, accuracy=0.875, cost=0.146] \n",
      "train minibatch loop:   0%|          | 2/10513 [00:00<11:47, 14.86it/s, accuracy=0.812, cost=0.347]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken: 729.0663626194\n",
      "epoch: 13, training loss: 0.370870, training acc: 0.837109, valid loss: 0.381337, valid acc: 0.830210\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train minibatch loop: 100%|██████████| 10513/10513 [11:46<00:00, 14.88it/s, accuracy=0.786, cost=0.33]  \n",
      "test minibatch loop: 100%|██████████| 2629/2629 [00:22<00:00, 117.55it/s, accuracy=0.875, cost=0.0937]\n",
      "train minibatch loop:   0%|          | 2/10513 [00:00<11:45, 14.91it/s, accuracy=0.844, cost=0.321]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 14, pass acc: 0.831387, current acc: 0.832184\n",
      "time taken: 729.068371295929\n",
      "epoch: 14, training loss: 0.366446, training acc: 0.838544, valid loss: 0.375796, valid acc: 0.832184\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train minibatch loop: 100%|██████████| 10513/10513 [11:46<00:00, 14.87it/s, accuracy=0.821, cost=0.313] \n",
      "test minibatch loop: 100%|██████████| 2629/2629 [00:22<00:00, 117.09it/s, accuracy=0.875, cost=0.0983]\n",
      "train minibatch loop:   0%|          | 2/10513 [00:00<11:46, 14.87it/s, accuracy=0.812, cost=0.376]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 15, pass acc: 0.832184, current acc: 0.833563\n",
      "time taken: 729.2165334224701\n",
      "epoch: 15, training loss: 0.363456, training acc: 0.838815, valid loss: 0.374733, valid acc: 0.833563\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train minibatch loop: 100%|██████████| 10513/10513 [11:46<00:00, 14.87it/s, accuracy=0.857, cost=0.373] \n",
      "test minibatch loop: 100%|██████████| 2629/2629 [00:22<00:00, 117.50it/s, accuracy=1, cost=0.0925]    \n",
      "train minibatch loop:   0%|          | 2/10513 [00:00<11:45, 14.90it/s, accuracy=0.844, cost=0.331]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken: 729.1978690624237\n",
      "epoch: 16, training loss: 0.359132, training acc: 0.840049, valid loss: 0.373113, valid acc: 0.832707\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train minibatch loop: 100%|██████████| 10513/10513 [11:46<00:00, 14.87it/s, accuracy=0.857, cost=0.371] \n",
      "test minibatch loop: 100%|██████████| 2629/2629 [00:22<00:00, 117.57it/s, accuracy=1, cost=0.09]      \n",
      "train minibatch loop:   0%|          | 2/10513 [00:00<11:45, 14.91it/s, accuracy=0.75, cost=0.428]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken: 729.1302597522736\n",
      "epoch: 17, training loss: 0.355423, training acc: 0.841169, valid loss: 0.368639, valid acc: 0.833278\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train minibatch loop: 100%|██████████| 10513/10513 [11:46<00:00, 14.87it/s, accuracy=0.786, cost=0.452] \n",
      "test minibatch loop: 100%|██████████| 2629/2629 [00:22<00:00, 117.47it/s, accuracy=1, cost=0.0825]    \n",
      "train minibatch loop:   0%|          | 2/10513 [00:00<11:43, 14.94it/s, accuracy=0.812, cost=0.341]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 18, pass acc: 0.833563, current acc: 0.833896\n",
      "time taken: 729.2176496982574\n",
      "epoch: 18, training loss: 0.352978, training acc: 0.841359, valid loss: 0.368497, valid acc: 0.833896\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train minibatch loop: 100%|██████████| 10513/10513 [11:46<00:00, 14.87it/s, accuracy=0.893, cost=0.347] \n",
      "test minibatch loop: 100%|██████████| 2629/2629 [00:22<00:00, 117.60it/s, accuracy=0.875, cost=0.135] \n",
      "train minibatch loop:   0%|          | 2/10513 [00:00<11:45, 14.90it/s, accuracy=0.844, cost=0.273]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 19, pass acc: 0.833896, current acc: 0.835561\n",
      "time taken: 729.1488280296326\n",
      "epoch: 19, training loss: 0.349954, training acc: 0.842385, valid loss: 0.362723, valid acc: 0.835561\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train minibatch loop: 100%|██████████| 10513/10513 [11:46<00:00, 14.87it/s, accuracy=0.857, cost=0.267] \n",
      "test minibatch loop: 100%|██████████| 2629/2629 [00:22<00:00, 117.42it/s, accuracy=0.875, cost=0.0996]\n",
      "train minibatch loop:   0%|          | 2/10513 [00:00<11:45, 14.91it/s, accuracy=0.875, cost=0.272]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken: 729.1898145675659\n",
      "epoch: 20, training loss: 0.347365, training acc: 0.843428, valid loss: 0.362455, valid acc: 0.833979\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train minibatch loop: 100%|██████████| 10513/10513 [11:46<00:00, 14.87it/s, accuracy=0.821, cost=0.29]  \n",
      "test minibatch loop: 100%|██████████| 2629/2629 [00:22<00:00, 117.32it/s, accuracy=1, cost=0.0757]   \n",
      "train minibatch loop:   0%|          | 2/10513 [00:00<11:45, 14.90it/s, accuracy=0.812, cost=0.326]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken: 729.206015586853\n",
      "epoch: 21, training loss: 0.345617, training acc: 0.843520, valid loss: 0.359533, valid acc: 0.834086\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train minibatch loop: 100%|██████████| 10513/10513 [11:46<00:00, 14.87it/s, accuracy=0.857, cost=0.264] \n",
      "test minibatch loop: 100%|██████████| 2629/2629 [00:22<00:00, 117.09it/s, accuracy=0.875, cost=0.105] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken: 729.2785265445709\n",
      "epoch: 22, training loss: 0.342237, training acc: 0.844296, valid loss: 0.359588, valid acc: 0.834181\n",
      "\n",
      "break epoch:23\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "EARLY_STOPPING, CURRENT_CHECKPOINT, CURRENT_ACC, EPOCH = 3, 0, 0, 0\n",
    "\n",
    "while True:\n",
    "    lasttime = time.time()\n",
    "    if CURRENT_CHECKPOINT == EARLY_STOPPING:\n",
    "        print('break epoch:%d\\n' % (EPOCH))\n",
    "        break\n",
    "\n",
    "    train_acc, train_loss, test_acc, test_loss = 0, 0, 0, 0\n",
    "    pbar = tqdm(\n",
    "        range(0, len(train_X), batch_size), desc = 'train minibatch loop'\n",
    "    )\n",
    "    for i in pbar:\n",
    "        batch_x = str_idx(train_X[i : min(i + batch_size, len(train_X))], dictionary, maxlen)\n",
    "        batch_y = train_Y[i : min(i + batch_size, len(train_X))]\n",
    "        batch_x_expand = np.expand_dims(batch_x,axis = 1)\n",
    "        acc, cost, _ = sess.run(\n",
    "            [model.accuracy, model.cost, model.optimizer],\n",
    "            feed_dict = {\n",
    "                model.Y: batch_y,\n",
    "                model.X: batch_x\n",
    "            },\n",
    "        )\n",
    "        assert not np.isnan(cost)\n",
    "        train_loss += cost\n",
    "        train_acc += acc\n",
    "        pbar.set_postfix(cost = cost, accuracy = acc)\n",
    "\n",
    "    pbar = tqdm(range(0, len(test_X), batch_size), desc = 'test minibatch loop')\n",
    "    for i in pbar:\n",
    "        batch_x = str_idx(test_X[i : min(i + batch_size, len(test_X))], dictionary, maxlen)\n",
    "        batch_y = test_Y[i : min(i + batch_size, len(test_X))]\n",
    "        batch_x_expand = np.expand_dims(batch_x,axis = 1)\n",
    "        acc, cost = sess.run(\n",
    "            [model.accuracy, model.cost],\n",
    "            feed_dict = {\n",
    "                model.Y: batch_y,\n",
    "                model.X: batch_x\n",
    "            },\n",
    "        )\n",
    "        test_loss += cost\n",
    "        test_acc += acc\n",
    "        pbar.set_postfix(cost = cost, accuracy = acc)\n",
    "\n",
    "    train_loss /= len(train_X) / batch_size\n",
    "    train_acc /= len(train_X) / batch_size\n",
    "    test_loss /= len(test_X) / batch_size\n",
    "    test_acc /= len(test_X) / batch_size\n",
    "\n",
    "    if test_acc > CURRENT_ACC:\n",
    "        print(\n",
    "            'epoch: %d, pass acc: %f, current acc: %f'\n",
    "            % (EPOCH, CURRENT_ACC, test_acc)\n",
    "        )\n",
    "        CURRENT_ACC = test_acc\n",
    "        CURRENT_CHECKPOINT = 0\n",
    "    else:\n",
    "        CURRENT_CHECKPOINT += 1\n",
    "        \n",
    "    print('time taken:', time.time() - lasttime)\n",
    "    print(\n",
    "        'epoch: %d, training loss: %f, training acc: %f, valid loss: %f, valid acc: %f\\n'\n",
    "        % (EPOCH, train_loss, train_acc, test_loss, test_acc)\n",
    "    )\n",
    "    EPOCH += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'only-attention/model.ckpt'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saver.save(sess, 'only-attention/model.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.67638516, 0.0042767 , 0.00291029, 0.02935026, 0.23952654,\n",
       "        0.04755105]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = preprocessing('kerajaan sebenarnya sangat bencikan rakyatnya, minyak naik dan segalanya')\n",
    "new_vector = str_idx([text], dictionary, len(text))\n",
    "sess.run(tf.nn.softmax(model.logits), feed_dict={model.X:new_vector})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[[6.31391769e-03, 4.56804894e-02, 2.21061986e-03, 4.09578323e-01,\n",
       "          2.85104007e-01, 2.51112700e-01],\n",
       "         [1.02130912e-01, 2.20702365e-02, 2.67399265e-03, 9.51586440e-02,\n",
       "          6.47424817e-01, 1.30541399e-01],\n",
       "         [5.37537411e-02, 1.50353706e-03, 4.99343267e-03, 4.11306053e-01,\n",
       "          5.04247367e-01, 2.41958518e-02],\n",
       "         [9.89125967e-01, 1.14880524e-04, 1.28736847e-05, 1.05202815e-03,\n",
       "          8.38419423e-03, 1.31011382e-03],\n",
       "         [2.22332273e-02, 9.59710800e-04, 9.57809796e-04, 3.40199992e-02,\n",
       "          8.58260930e-01, 8.35683569e-02],\n",
       "         [9.93680239e-01, 2.64354894e-04, 1.86971210e-05, 2.17315566e-04,\n",
       "          4.84278053e-03, 9.76616284e-04],\n",
       "         [5.98695040e-01, 3.87248467e-04, 1.83452750e-04, 4.41529136e-03,\n",
       "          3.80682558e-01, 1.56364534e-02],\n",
       "         [6.08286619e-01, 1.20844168e-03, 1.88731239e-04, 1.08873714e-02,\n",
       "          3.75834495e-01, 3.59435077e-03]]], dtype=float32),\n",
       " array([0.29801446, 0.07011506, 0.14716882, 0.42039987, 0.03442984,\n",
       "        0.01194836, 0.0173601 , 0.0005635 ], dtype=float32)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = preprocessing('kerajaan sebenarnya sangat bencikan rakyatnya, minyak naik dan segalanya')\n",
    "new_vector = str_idx([text], dictionary, len(text))\n",
    "sess.run([tf.nn.softmax(model.logits_seq), model.attention], feed_dict={model.X:new_vector})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "validation minibatch loop: 100%|██████████| 2629/2629 [00:19<00:00, 137.83it/s]\n"
     ]
    }
   ],
   "source": [
    "real_Y, predict_Y = [], []\n",
    "\n",
    "pbar = tqdm(\n",
    "    range(0, len(test_X), batch_size), desc = 'validation minibatch loop'\n",
    ")\n",
    "for i in pbar:\n",
    "    batch_x = str_idx(test_X[i : min(i + batch_size, len(test_X))], dictionary, maxlen)\n",
    "    batch_y = test_Y[i : min(i + batch_size, len(test_X))]\n",
    "    predict_Y += np.argmax(\n",
    "        sess.run(\n",
    "            model.logits, feed_dict = {model.X: batch_x, model.Y: batch_y}\n",
    "        ),\n",
    "        1,\n",
    "    ).tolist()\n",
    "    real_Y += batch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "      anger       0.90      0.90      0.90     14869\n",
      "       fear       0.83      0.85      0.84      7682\n",
      "        joy       0.87      0.90      0.89     16658\n",
      "       love       0.92      0.90      0.91     15767\n",
      "    sadness       0.77      0.74      0.76     19866\n",
      "   surprise       0.64      0.67      0.66      9262\n",
      "\n",
      "avg / total       0.83      0.83      0.83     84104\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    metrics.classification_report(\n",
    "        real_Y, predict_Y, target_names = ['anger', 'fear', 'joy', 'love', 'sadness', 'surprise']\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freeze_graph(model_dir, output_node_names):\n",
    "\n",
    "    if not tf.gfile.Exists(model_dir):\n",
    "        raise AssertionError(\n",
    "            \"Export directory doesn't exists. Please specify an export \"\n",
    "            'directory: %s' % model_dir\n",
    "        )\n",
    "\n",
    "    checkpoint = tf.train.get_checkpoint_state(model_dir)\n",
    "    input_checkpoint = checkpoint.model_checkpoint_path\n",
    "\n",
    "    absolute_model_dir = '/'.join(input_checkpoint.split('/')[:-1])\n",
    "    output_graph = absolute_model_dir + '/frozen_model.pb'\n",
    "    clear_devices = True\n",
    "    with tf.Session(graph = tf.Graph()) as sess:\n",
    "        saver = tf.train.import_meta_graph(\n",
    "            input_checkpoint + '.meta', clear_devices = clear_devices\n",
    "        )\n",
    "        saver.restore(sess, input_checkpoint)\n",
    "        output_graph_def = tf.graph_util.convert_variables_to_constants(\n",
    "            sess,\n",
    "            tf.get_default_graph().as_graph_def(),\n",
    "            output_node_names.split(','),\n",
    "        )\n",
    "        with tf.gfile.GFile(output_graph, 'wb') as f:\n",
    "            f.write(output_graph_def.SerializeToString())\n",
    "        print('%d ops in the final graph.' % len(output_graph_def.node))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from only-attention/model.ckpt\n",
      "INFO:tensorflow:Froze 7 variables.\n",
      "INFO:tensorflow:Converted 7 variables to const ops.\n",
      "248 ops in the final graph.\n"
     ]
    }
   ],
   "source": [
    "freeze_graph('only-attention', strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_graph(frozen_graph_filename):\n",
    "    with tf.gfile.GFile(frozen_graph_filename, 'rb') as f:\n",
    "        graph_def = tf.GraphDef()\n",
    "        graph_def.ParseFromString(f.read())\n",
    "    with tf.Graph().as_default() as graph:\n",
    "        tf.import_graph_def(graph_def)\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = load_graph('only-attention/frozen_model.pb')\n",
    "x = g.get_tensor_by_name('import/Placeholder:0')\n",
    "logits_seq = g.get_tensor_by_name('import/logits_seq:0')\n",
    "logits = g.get_tensor_by_name('import/logits:0')\n",
    "alphas = g.get_tensor_by_name('import/alphas:0')\n",
    "test_sess = tf.InteractiveSession(graph = g)\n",
    "result = test_sess.run([logits, alphas, logits_seq], feed_dict = {x: new_vector})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_string = 'Kerajaan juga perlu prihatin dan peka terhadap nasib para nelayan yang bergantung rezeki sepenuhnya kepada sumber hasil laut. Malah, projek ini memberikan kesan buruk yang berpanjangan kepada alam sekitar selain menjejaskan mata pencarian para nelayan'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = preprocessing(news_string)\n",
    "new_vector = str_idx([text], dictionary, len(text))\n",
    "result = test_sess.run([tf.nn.softmax(logits), alphas, tf.nn.softmax(logits_seq)], feed_dict = {x: new_vector})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (15, 7))\n",
    "labels = [word for word in text]\n",
    "val = [val for val in result[1]]\n",
    "plt.bar(np.arange(len(labels)), val)\n",
    "plt.xticks(np.arange(len(labels)), labels, rotation = 'vertical')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[3.57826166e-02, 3.96472897e-04, 1.59756336e-02, 3.90590310e-01,\n",
       "         5.30455232e-01, 2.67997421e-02],\n",
       "        [1.67966858e-02, 3.78293393e-04, 4.24483232e-03, 6.44199774e-02,\n",
       "         9.06710088e-01, 7.45004369e-03],\n",
       "        [5.94010614e-02, 5.88332885e-04, 4.31317836e-02, 6.44679442e-02,\n",
       "         7.84338474e-01, 4.80723865e-02],\n",
       "        [1.34910932e-02, 3.76882555e-04, 6.32534968e-03, 1.09262384e-01,\n",
       "         8.35589051e-01, 3.49552408e-02],\n",
       "        [3.68006295e-03, 7.40904579e-05, 6.51545066e-04, 1.52156912e-02,\n",
       "         9.74577188e-01, 5.80132660e-03],\n",
       "        [2.91984179e-03, 2.24231728e-04, 6.42385974e-04, 2.08916496e-02,\n",
       "         9.58328426e-01, 1.69934761e-02],\n",
       "        [6.99942047e-03, 1.10864428e-04, 8.09886842e-04, 3.44670154e-02,\n",
       "         9.38600004e-01, 1.90127864e-02],\n",
       "        [3.88900656e-03, 3.65889980e-04, 7.75634311e-04, 8.25500116e-02,\n",
       "         8.83286774e-01, 2.91326102e-02],\n",
       "        [1.56838611e-01, 3.44735174e-03, 7.71176245e-04, 1.49044162e-02,\n",
       "         7.92854249e-01, 3.11841648e-02],\n",
       "        [7.97694400e-02, 3.59780388e-04, 2.06559384e-03, 3.97819057e-02,\n",
       "         7.88583398e-01, 8.94399062e-02],\n",
       "        [2.01159157e-02, 3.00212210e-04, 1.54792878e-03, 5.17607555e-02,\n",
       "         9.06498969e-01, 1.97761804e-02],\n",
       "        [1.61342949e-01, 8.18817760e-04, 1.97659410e-03, 4.70545627e-02,\n",
       "         7.71539390e-01, 1.72676947e-02],\n",
       "        [3.95550877e-01, 7.01612385e-04, 1.71440735e-03, 8.24618042e-02,\n",
       "         4.96505767e-01, 2.30654757e-02],\n",
       "        [6.59562126e-02, 5.92901895e-04, 5.47138974e-04, 2.57268921e-02,\n",
       "         8.97797644e-01, 9.37924255e-03],\n",
       "        [6.14898689e-02, 1.42328336e-03, 1.30498630e-03, 7.28473514e-02,\n",
       "         8.05613637e-01, 5.73209412e-02],\n",
       "        [1.29091680e-01, 1.00555143e-03, 3.04668793e-03, 9.19574127e-02,\n",
       "         7.66300857e-01, 8.59782565e-03],\n",
       "        [2.76080787e-01, 8.12901417e-04, 1.12521020e-03, 1.32751450e-01,\n",
       "         5.74998021e-01, 1.42316967e-02],\n",
       "        [2.41127506e-01, 5.00781462e-04, 1.04051852e-03, 5.79245947e-02,\n",
       "         6.71956360e-01, 2.74501797e-02],\n",
       "        [6.08721301e-02, 3.70998110e-04, 3.56351840e-03, 1.72024578e-01,\n",
       "         7.56210327e-01, 6.95839524e-03],\n",
       "        [8.02287385e-02, 1.58183917e-04, 4.59094997e-03, 1.96125910e-01,\n",
       "         7.06913531e-01, 1.19826933e-02],\n",
       "        [5.22482730e-02, 1.29677850e-04, 1.69340870e-03, 4.31252979e-02,\n",
       "         8.97271931e-01, 5.53134922e-03],\n",
       "        [1.74925979e-02, 6.68068824e-05, 1.16120698e-03, 4.13460769e-02,\n",
       "         9.34080005e-01, 5.85323852e-03],\n",
       "        [1.05377994e-02, 2.53858394e-04, 6.98845019e-04, 3.51850651e-02,\n",
       "         9.51058090e-01, 2.26631016e-03],\n",
       "        [3.99019495e-02, 1.54102920e-04, 3.43286694e-04, 8.64109620e-02,\n",
       "         8.71795833e-01, 1.39383925e-03],\n",
       "        [1.19404405e-01, 3.67183326e-04, 2.05474906e-03, 2.75113940e-01,\n",
       "         5.99576175e-01, 3.48356226e-03],\n",
       "        [1.14880409e-02, 1.77806840e-04, 1.81388401e-03, 9.86482129e-02,\n",
       "         8.83489370e-01, 4.38267039e-03],\n",
       "        [4.60060723e-02, 1.10561866e-03, 3.30377207e-03, 1.25366554e-01,\n",
       "         8.16480994e-01, 7.73703028e-03],\n",
       "        [2.59326249e-02, 1.21635196e-04, 4.27651731e-03, 4.08504933e-01,\n",
       "         5.55695593e-01, 5.46872383e-03],\n",
       "        [9.98863652e-02, 7.74365850e-04, 1.23169855e-03, 2.25521803e-01,\n",
       "         6.67399645e-01, 5.18614193e-03],\n",
       "        [1.73696950e-02, 3.31185234e-04, 3.96557356e-04, 3.02951373e-02,\n",
       "         9.49301600e-01, 2.30589416e-03],\n",
       "        [4.69185226e-02, 9.15267970e-04, 1.80410792e-03, 7.40703940e-02,\n",
       "         8.61446083e-01, 1.48456097e-02],\n",
       "        [4.46852371e-02, 5.11548831e-04, 5.47467847e-04, 3.41617130e-02,\n",
       "         9.15280700e-01, 4.81330836e-03],\n",
       "        [7.94937462e-02, 6.60863647e-04, 1.12262520e-03, 2.12945100e-02,\n",
       "         8.89040470e-01, 8.38785619e-03]]], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
