{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import collections\n",
    "from sklearn import metrics\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from unidecode import unidecode\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import malaya"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = malaya.preprocessing._SocialTokenizer().tokenize\n",
    "rules_normalizer = malaya.texts._tatabahasa.rules_normalizer\n",
    "\n",
    "def is_number_regex(s):\n",
    "    if re.match(\"^\\d+?\\.\\d+?$\", s) is None:\n",
    "        return s.isdigit()\n",
    "    return True\n",
    "\n",
    "def detect_money(word):\n",
    "    if word[:2] == 'rm' and is_number_regex(word[2:]):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def preprocessing(string):\n",
    "    tokenized = tokenizer(unidecode(string))\n",
    "    tokenized = [malaya.stem.naive(w) for w in tokenized]\n",
    "    tokenized = [w.lower() for w in tokenized if len(w) > 1]\n",
    "    tokenized = [rules_normalizer.get(w, w) for w in tokenized]\n",
    "    tokenized = ['<NUM>' if is_number_regex(w) else w for w in tokenized]\n",
    "    tokenized = ['<MONEY>' if detect_money(w) else w for w in tokenized]\n",
    "    return tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataset(words, n_words):\n",
    "    count = [['GO', 0], ['PAD', 1], ['EOS', 2], ['UNK', 3]]\n",
    "    counter = collections.Counter(words).most_common(n_words)\n",
    "    count.extend(counter)\n",
    "    dictionary = dict()\n",
    "    for word, _ in count:\n",
    "        dictionary[word] = len(dictionary)\n",
    "    data = list()\n",
    "    unk_count = 0\n",
    "    for word in words:\n",
    "        index = dictionary.get(word, 3)\n",
    "        if index == 0:\n",
    "            unk_count += 1\n",
    "        data.append(index)\n",
    "    count[0][1] = unk_count\n",
    "    reversed_dictionary = dict(zip(dictionary.values(), dictionary.keys()))\n",
    "    return data, count, dictionary, reversed_dictionary\n",
    "\n",
    "def str_idx(corpus, dic, maxlen, UNK = 3):\n",
    "    X = np.zeros((len(corpus), maxlen))\n",
    "    for i in range(len(corpus)):\n",
    "        for no, k in enumerate(corpus[i][:maxlen][::-1]):\n",
    "            X[i, -1 - no] = dic.get(k, UNK)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('tokenized.json') as fopen:\n",
    "    dataset = json.load(fopen)\n",
    "texts = dataset['x']\n",
    "labels = dataset['y']\n",
    "del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('toxicity-dictionary.json') as fopen:\n",
    "    dataset = json.load(fopen)\n",
    "    \n",
    "dictionary = dataset['dictionary']\n",
    "rev_dictionary = dataset['reverse_dictionary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def position_encoding(inputs):\n",
    "    T = tf.shape(inputs)[1]\n",
    "    repr_dim = inputs.get_shape()[-1].value\n",
    "    pos = tf.reshape(tf.range(0.0, tf.to_float(T), dtype=tf.float32), [-1, 1])\n",
    "    i = np.arange(0, repr_dim, 2, np.float32)\n",
    "    denom = np.reshape(np.power(10000.0, i / repr_dim), [1, -1])\n",
    "    enc = tf.expand_dims(tf.concat([tf.sin(pos / denom), tf.cos(pos / denom)], 1), 0)\n",
    "    return tf.tile(enc, [tf.shape(inputs)[0], 1, 1])\n",
    "\n",
    "def layer_norm(inputs, epsilon=1e-8):\n",
    "    mean, variance = tf.nn.moments(inputs, [-1], keep_dims=True)\n",
    "    normalized = (inputs - mean) / (tf.sqrt(variance + epsilon))\n",
    "    params_shape = inputs.get_shape()[-1:]\n",
    "    gamma = tf.get_variable('gamma', params_shape, tf.float32, tf.ones_initializer())\n",
    "    beta = tf.get_variable('beta', params_shape, tf.float32, tf.zeros_initializer())\n",
    "    return gamma * normalized + beta\n",
    "\n",
    "def Attention(inputs, num_units, num_heads = 8, activation = None):\n",
    "    inputs = tf.layers.dropout(inputs, 0.3, training=True)\n",
    "    T_q = T_k = tf.shape(inputs)[1]\n",
    "    Q_K_V = tf.layers.dense(inputs, 3*num_units, activation)\n",
    "    Q, K, V = tf.split(Q_K_V, 3, -1)\n",
    "    Q_ = tf.concat(tf.split(Q, num_heads, axis=2), 0)\n",
    "    K_ = tf.concat(tf.split(K, num_heads, axis=2), 0)\n",
    "    V_ = tf.concat(tf.split(V, num_heads, axis=2), 0)\n",
    "    align = tf.matmul(Q_, K_, transpose_b=True)\n",
    "    align *= tf.rsqrt(tf.to_float(K_.get_shape()[-1].value))\n",
    "    paddings = tf.fill(tf.shape(align), float('-inf'))\n",
    "    lower_tri = tf.ones([T_q, T_k])\n",
    "    lower_tri = tf.linalg.LinearOperatorLowerTriangular(lower_tri).to_dense()\n",
    "    masks = tf.tile(tf.expand_dims(lower_tri,0), [tf.shape(align)[0],1,1])\n",
    "    align = tf.where(tf.equal(masks, 0), paddings, align)\n",
    "    align = tf.nn.softmax(align)\n",
    "    alignments = tf.transpose(align, [0, 2, 1]) \n",
    "    x = tf.matmul(align, V_)\n",
    "    x = tf.concat(tf.split(x, num_heads, axis=0), 2)\n",
    "    x += inputs\n",
    "    x = layer_norm(x)\n",
    "    return x, alignments\n",
    "\n",
    "class Model:\n",
    "    def __init__(self, size_layer, embed_size, dict_size, dimension_output, learning_rate = 1e-3):\n",
    "        self.X = tf.placeholder(tf.int32, [None, None])\n",
    "        self.Y = tf.placeholder(tf.float32, [None, dimension_output])\n",
    "        \n",
    "        encoder_embeddings = tf.Variable(tf.random_uniform([dict_size, embed_size], -1, 1))\n",
    "        x = tf.nn.embedding_lookup(encoder_embeddings, self.X)\n",
    "        x += position_encoding(x)\n",
    "        x = tf.layers.dropout(x, 0.3, training=True) \n",
    "        \n",
    "        x, self.alignments = Attention(x, size_layer)\n",
    "        self.logits_seq = tf.layers.dense(x, dimension_output)\n",
    "        self.logits_seq = tf.identity(self.logits_seq, name = 'logits_seq')\n",
    "        self.logits = self.logits_seq[:,-1]\n",
    "        self.logits = tf.identity(self.logits, name = 'logits')\n",
    "\n",
    "        self.cost = tf.reduce_mean(\n",
    "            tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "                logits = self.logits, labels = self.Y\n",
    "            )\n",
    "        )\n",
    "        self.optimizer = tf.train.AdamOptimizer(\n",
    "            learning_rate = learning_rate\n",
    "        ).minimize(self.cost)\n",
    "        correct_prediction = tf.equal(tf.round(tf.nn.sigmoid(self.logits)), tf.round(self.Y))\n",
    "        all_labels_true = tf.reduce_min(tf.cast(correct_prediction, tf.float32), 1)\n",
    "        self.accuracy = tf.reduce_mean(all_labels_true)\n",
    "        self.attention = tf.identity(tf.reduce_mean(self.alignments[0], 1), name = 'alphas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'only-attention/model.ckpt'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size_layer = 256\n",
    "num_layers = 2\n",
    "dimension_output = len(labels[0])\n",
    "learning_rate = 1e-4\n",
    "batch_size = 32\n",
    "dropout = 0.8\n",
    "maxlen = 100\n",
    "\n",
    "tf.reset_default_graph()\n",
    "sess = tf.InteractiveSession()\n",
    "model = Model(\n",
    "    size_layer,\n",
    "    size_layer,\n",
    "    len(dictionary),\n",
    "    dimension_output,\n",
    "    learning_rate,\n",
    ")\n",
    "sess.run(tf.global_variables_initializer())\n",
    "saver = tf.train.Saver(tf.trainable_variables())\n",
    "saver.save(sess, 'only-attention/model.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "strings = ','.join(\n",
    "    [\n",
    "        n.name\n",
    "        for n in tf.get_default_graph().as_graph_def().node\n",
    "        if ('Variable' in n.op\n",
    "        or 'Placeholder' in n.name\n",
    "        or 'logits' in n.name\n",
    "        or 'alphas' in n.name)\n",
    "        and 'Adam' not in n.name\n",
    "        and '_power' not in n.name\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Placeholder',\n",
       " 'Placeholder_1',\n",
       " 'Variable',\n",
       " 'dense/kernel',\n",
       " 'dense/bias',\n",
       " 'gamma',\n",
       " 'beta',\n",
       " 'dense_1/kernel',\n",
       " 'dense_1/bias',\n",
       " 'logits_seq',\n",
       " 'logits',\n",
       " 'alphas']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strings.split(',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, test_X, train_Y, test_Y = train_test_split(\n",
    "    texts, labels, test_size = 0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train minibatch loop: 100%|██████████| 4801/4801 [03:51<00:00, 20.95it/s, accuracy=0.913, cost=0.147] \n",
      "test minibatch loop: 100%|██████████| 1201/1201 [00:10<00:00, 114.96it/s, accuracy=1, cost=0.0164]    \n",
      "train minibatch loop:   0%|          | 3/4801 [00:00<03:50, 20.80it/s, accuracy=0.812, cost=0.181] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, pass acc: 0.000000, current acc: 0.898323\n",
      "time taken: 241.76166892051697\n",
      "epoch: 0, training loss: 0.136506, training acc: 0.892439, valid loss: 0.116839, valid acc: 0.898323\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train minibatch loop: 100%|██████████| 4801/4801 [03:51<00:00, 20.78it/s, accuracy=0.913, cost=0.0951]\n",
      "test minibatch loop: 100%|██████████| 1201/1201 [00:10<00:00, 116.02it/s, accuracy=1, cost=0.0113]    \n",
      "train minibatch loop:   0%|          | 3/4801 [00:00<03:50, 20.85it/s, accuracy=0.844, cost=0.136] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1, pass acc: 0.898323, current acc: 0.898948\n",
      "time taken: 241.37779450416565\n",
      "epoch: 1, training loss: 0.103845, training acc: 0.900745, valid loss: 0.102865, valid acc: 0.898948\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train minibatch loop: 100%|██████████| 4801/4801 [03:50<00:00, 20.80it/s, accuracy=0.913, cost=0.0977]\n",
      "test minibatch loop: 100%|██████████| 1201/1201 [00:10<00:00, 115.86it/s, accuracy=1, cost=0.00858]   \n",
      "train minibatch loop:   0%|          | 3/4801 [00:00<03:51, 20.72it/s, accuracy=0.844, cost=0.121] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2, pass acc: 0.898948, current acc: 0.899547\n",
      "time taken: 241.21398639678955\n",
      "epoch: 2, training loss: 0.095066, training acc: 0.901422, valid loss: 0.097260, valid acc: 0.899547\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train minibatch loop: 100%|██████████| 4801/4801 [03:50<00:00, 20.80it/s, accuracy=0.957, cost=0.0653]\n",
      "test minibatch loop: 100%|██████████| 1201/1201 [00:10<00:00, 115.93it/s, accuracy=1, cost=0.0129]    \n",
      "train minibatch loop:   0%|          | 3/4801 [00:00<03:50, 20.82it/s, accuracy=0.812, cost=0.134] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3, pass acc: 0.899547, current acc: 0.899833\n",
      "time taken: 241.1545877456665\n",
      "epoch: 3, training loss: 0.089557, training acc: 0.902200, valid loss: 0.091514, valid acc: 0.899833\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train minibatch loop: 100%|██████████| 4801/4801 [03:50<00:00, 20.81it/s, accuracy=0.957, cost=0.0866]\n",
      "test minibatch loop: 100%|██████████| 1201/1201 [00:10<00:00, 115.74it/s, accuracy=1, cost=0.00427]   \n",
      "train minibatch loop:   0%|          | 3/4801 [00:00<03:50, 20.80it/s, accuracy=0.812, cost=0.121] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4, pass acc: 0.899833, current acc: 0.901213\n",
      "time taken: 241.13759565353394\n",
      "epoch: 4, training loss: 0.085141, training acc: 0.902818, valid loss: 0.087218, valid acc: 0.901213\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train minibatch loop: 100%|██████████| 4801/4801 [03:50<00:00, 20.80it/s, accuracy=0.957, cost=0.0694]\n",
      "test minibatch loop: 100%|██████████| 1201/1201 [00:10<00:00, 116.05it/s, accuracy=1, cost=0.0121]    \n",
      "train minibatch loop:   0%|          | 3/4801 [00:00<03:50, 20.86it/s, accuracy=0.844, cost=0.0863]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 5, pass acc: 0.901213, current acc: 0.901838\n",
      "time taken: 241.12765336036682\n",
      "epoch: 5, training loss: 0.080834, training acc: 0.904100, valid loss: 0.083214, valid acc: 0.901838\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train minibatch loop: 100%|██████████| 4801/4801 [03:50<00:00, 20.82it/s, accuracy=0.957, cost=0.0647]\n",
      "test minibatch loop: 100%|██████████| 1201/1201 [00:10<00:00, 116.37it/s, accuracy=1, cost=0.0132]    \n",
      "train minibatch loop:   0%|          | 3/4801 [00:00<03:49, 20.90it/s, accuracy=0.781, cost=0.0845]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 6, pass acc: 0.901838, current acc: 0.903296\n",
      "time taken: 240.9689075946808\n",
      "epoch: 6, training loss: 0.077272, training acc: 0.904784, valid loss: 0.080238, valid acc: 0.903296\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train minibatch loop: 100%|██████████| 4801/4801 [03:50<00:00, 20.81it/s, accuracy=0.957, cost=0.0635]\n",
      "test minibatch loop: 100%|██████████| 1201/1201 [00:10<00:00, 116.38it/s, accuracy=1, cost=0.00489]   \n",
      "train minibatch loop:   0%|          | 3/4801 [00:00<03:50, 20.82it/s, accuracy=0.812, cost=0.0957]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken: 241.00552201271057\n",
      "epoch: 7, training loss: 0.074848, training acc: 0.905487, valid loss: 0.079158, valid acc: 0.903270\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train minibatch loop: 100%|██████████| 4801/4801 [03:50<00:00, 20.82it/s, accuracy=0.957, cost=0.0493]\n",
      "test minibatch loop: 100%|██████████| 1201/1201 [00:10<00:00, 116.43it/s, accuracy=1, cost=0.00674]   \n",
      "train minibatch loop:   0%|          | 3/4801 [00:00<03:50, 20.81it/s, accuracy=0.812, cost=0.129] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken: 240.9566683769226\n",
      "epoch: 8, training loss: 0.072807, training acc: 0.906307, valid loss: 0.076968, valid acc: 0.903140\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train minibatch loop: 100%|██████████| 4801/4801 [03:50<00:00, 20.82it/s, accuracy=0.957, cost=0.0676]\n",
      "test minibatch loop: 100%|██████████| 1201/1201 [00:10<00:00, 116.35it/s, accuracy=1, cost=0.00612]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken: 240.97234177589417\n",
      "epoch: 9, training loss: 0.071114, training acc: 0.907869, valid loss: 0.075624, valid acc: 0.902671\n",
      "\n",
      "break epoch:10\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "EARLY_STOPPING, CURRENT_CHECKPOINT, CURRENT_ACC, EPOCH = 3, 0, 0, 0\n",
    "\n",
    "while True:\n",
    "    lasttime = time.time()\n",
    "    if CURRENT_CHECKPOINT == EARLY_STOPPING:\n",
    "        print('break epoch:%d\\n' % (EPOCH))\n",
    "        break\n",
    "\n",
    "    train_acc, train_loss, test_acc, test_loss = 0, 0, 0, 0\n",
    "    pbar = tqdm(\n",
    "        range(0, len(train_X), batch_size), desc = 'train minibatch loop'\n",
    "    )\n",
    "    for i in pbar:\n",
    "        batch_x = str_idx(train_X[i : min(i + batch_size, len(train_X))], dictionary, maxlen)\n",
    "        batch_y = train_Y[i : min(i + batch_size, len(train_X))]\n",
    "        batch_x_expand = np.expand_dims(batch_x,axis = 1)\n",
    "        acc, cost, _ = sess.run(\n",
    "            [model.accuracy, model.cost, model.optimizer],\n",
    "            feed_dict = {\n",
    "                model.Y: batch_y,\n",
    "                model.X: batch_x\n",
    "            },\n",
    "        )\n",
    "        assert not np.isnan(cost)\n",
    "        train_loss += cost\n",
    "        train_acc += acc\n",
    "        pbar.set_postfix(cost = cost, accuracy = acc)\n",
    "\n",
    "    pbar = tqdm(range(0, len(test_X), batch_size), desc = 'test minibatch loop')\n",
    "    for i in pbar:\n",
    "        batch_x = str_idx(test_X[i : min(i + batch_size, len(test_X))], dictionary, maxlen)\n",
    "        batch_y = test_Y[i : min(i + batch_size, len(test_X))]\n",
    "        batch_x_expand = np.expand_dims(batch_x,axis = 1)\n",
    "        acc, cost = sess.run(\n",
    "            [model.accuracy, model.cost],\n",
    "            feed_dict = {\n",
    "                model.Y: batch_y,\n",
    "                model.X: batch_x\n",
    "            },\n",
    "        )\n",
    "        test_loss += cost\n",
    "        test_acc += acc\n",
    "        pbar.set_postfix(cost = cost, accuracy = acc)\n",
    "\n",
    "    train_loss /= len(train_X) / batch_size\n",
    "    train_acc /= len(train_X) / batch_size\n",
    "    test_loss /= len(test_X) / batch_size\n",
    "    test_acc /= len(test_X) / batch_size\n",
    "\n",
    "    if test_acc > CURRENT_ACC:\n",
    "        print(\n",
    "            'epoch: %d, pass acc: %f, current acc: %f'\n",
    "            % (EPOCH, CURRENT_ACC, test_acc)\n",
    "        )\n",
    "        CURRENT_ACC = test_acc\n",
    "        CURRENT_CHECKPOINT = 0\n",
    "    else:\n",
    "        CURRENT_CHECKPOINT += 1\n",
    "        \n",
    "    print('time taken:', time.time() - lasttime)\n",
    "    print(\n",
    "        'epoch: %d, training loss: %f, training acc: %f, valid loss: %f, valid acc: %f\\n'\n",
    "        % (EPOCH, train_loss, train_acc, test_loss, test_acc)\n",
    "    )\n",
    "    EPOCH += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'only-attention/model.ckpt'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saver.save(sess, 'only-attention/model.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.3315015 , 0.01869684, 0.01216965, 0.0163636 , 0.13262893,\n",
       "        0.2729065 ]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = preprocessing('kerajaan sebenarnya sangat bencikan rakyatnya, minyak naik dan segalanya, tapi gay bodoh')\n",
    "new_vector = str_idx([text], dictionary, len(text))\n",
    "sess.run(tf.nn.sigmoid(model.logits), feed_dict={model.X:new_vector})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[6.0652354e-04, 2.0123320e-03, 3.6770976e-04, 5.6917855e-04,\n",
       "         5.6679390e-04, 1.6016341e-04],\n",
       "        [2.3726411e-02, 2.2312617e-03, 4.8197052e-03, 3.8309365e-03,\n",
       "         1.2273437e-02, 8.0383808e-04],\n",
       "        [3.0553021e-02, 1.1963643e-03, 6.8286746e-03, 3.5382356e-03,\n",
       "         1.4238680e-02, 3.3079090e-03],\n",
       "        [5.4060578e-01, 2.3816165e-02, 1.3812222e-01, 2.4328912e-02,\n",
       "         2.4560468e-01, 1.7712797e-01],\n",
       "        [2.5152368e-02, 1.3602711e-02, 1.9648230e-02, 3.0212464e-02,\n",
       "         3.0157235e-02, 4.1573965e-03],\n",
       "        [3.1011924e-01, 1.3457464e-02, 5.2210525e-02, 7.1576461e-03,\n",
       "         7.0590921e-02, 3.2955125e-02],\n",
       "        [1.4057975e-01, 9.1796927e-03, 2.1016650e-02, 6.6841869e-03,\n",
       "         6.6434622e-02, 2.4952630e-02],\n",
       "        [8.5335553e-02, 6.3630124e-03, 6.5950956e-03, 9.5213028e-03,\n",
       "         1.0843368e-02, 4.7159046e-03],\n",
       "        [1.4287944e-01, 3.9729971e-02, 1.0572384e-02, 3.2806691e-02,\n",
       "         4.5657966e-02, 1.2052376e-02],\n",
       "        [6.8305159e-01, 4.0031414e-02, 7.7751651e-02, 4.6016548e-02,\n",
       "         2.6727679e-01, 7.8109550e-01],\n",
       "        [6.5138584e-01, 2.6553741e-02, 9.3563750e-02, 1.6967397e-02,\n",
       "         4.2986467e-01, 1.1506282e-01]]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(tf.nn.sigmoid(model.logits_seq), feed_dict={model.X:new_vector})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack = []\n",
    "pbar = range(0, len(test_X), batch_size)\n",
    "for i in pbar:\n",
    "    batch_x = str_idx(test_X[i : min(i + batch_size, len(test_X))], dictionary, maxlen)\n",
    "    batch_y = test_Y[i : min(i + batch_size, len(test_X))]\n",
    "    stack.append(sess.run(tf.nn.sigmoid(model.logits),\n",
    "                         feed_dict = {model.X: batch_x}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "        toxic       0.80      0.53      0.64      3806\n",
      " severe_toxic       0.55      0.17      0.26       417\n",
      "      obscene       0.80      0.55      0.65      2106\n",
      "       threat       0.43      0.02      0.05       122\n",
      "       insult       0.73      0.46      0.56      1989\n",
      "identity_hate       0.54      0.12      0.20       343\n",
      "\n",
      "  avg / total       0.76      0.48      0.58      8783\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(np.array(test_Y),np.around(np.concatenate(stack,axis=0)),\n",
    "                                    target_names=[\"toxic\", \"severe_toxic\", \"obscene\", \n",
    "                                            \"threat\", \"insult\", \"identity_hate\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freeze_graph(model_dir, output_node_names):\n",
    "\n",
    "    if not tf.gfile.Exists(model_dir):\n",
    "        raise AssertionError(\n",
    "            \"Export directory doesn't exists. Please specify an export \"\n",
    "            'directory: %s' % model_dir\n",
    "        )\n",
    "\n",
    "    checkpoint = tf.train.get_checkpoint_state(model_dir)\n",
    "    input_checkpoint = checkpoint.model_checkpoint_path\n",
    "\n",
    "    absolute_model_dir = '/'.join(input_checkpoint.split('/')[:-1])\n",
    "    output_graph = absolute_model_dir + '/frozen_model.pb'\n",
    "    clear_devices = True\n",
    "    with tf.Session(graph = tf.Graph()) as sess:\n",
    "        saver = tf.train.import_meta_graph(\n",
    "            input_checkpoint + '.meta', clear_devices = clear_devices\n",
    "        )\n",
    "        saver.restore(sess, input_checkpoint)\n",
    "        output_graph_def = tf.graph_util.convert_variables_to_constants(\n",
    "            sess,\n",
    "            tf.get_default_graph().as_graph_def(),\n",
    "            output_node_names.split(','),\n",
    "        )\n",
    "        with tf.gfile.GFile(output_graph, 'wb') as f:\n",
    "            f.write(output_graph_def.SerializeToString())\n",
    "        print('%d ops in the final graph.' % len(output_graph_def.node))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from only-attention/model.ckpt\n",
      "INFO:tensorflow:Froze 7 variables.\n",
      "INFO:tensorflow:Converted 7 variables to const ops.\n",
      "248 ops in the final graph.\n"
     ]
    }
   ],
   "source": [
    "freeze_graph('only-attention', strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_graph(frozen_graph_filename):\n",
    "    with tf.gfile.GFile(frozen_graph_filename, 'rb') as f:\n",
    "        graph_def = tf.GraphDef()\n",
    "        graph_def.ParseFromString(f.read())\n",
    "    with tf.Graph().as_default() as graph:\n",
    "        tf.import_graph_def(graph_def)\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = load_graph('only-attention/frozen_model.pb')\n",
    "x = g.get_tensor_by_name('import/Placeholder:0')\n",
    "logits_seq = g.get_tensor_by_name('import/logits_seq:0')\n",
    "logits = g.get_tensor_by_name('import/logits:0')\n",
    "alphas = g.get_tensor_by_name('import/alphas:0')\n",
    "test_sess = tf.InteractiveSession(graph = g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_string = 'Kerajaan juga perlu prihatin dan peka terhadap nasib para nelayan yang bergantung rezeki sepenuhnya kepada sumber hasil laut. Malah, projek ini memberikan kesan buruk yang berpanjangan kepada alam sekitar selain menjejaskan mata pencarian para nelayan'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = preprocessing(news_string)\n",
    "new_vector = str_idx([text], dictionary, len(text))\n",
    "result = test_sess.run([tf.nn.sigmoid(logits), alphas, tf.nn.sigmoid(logits_seq)], feed_dict = {x: new_vector})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (15, 7))\n",
    "labels = [word for word in text]\n",
    "val = [val for val in result[1]]\n",
    "plt.bar(np.arange(len(labels)), val)\n",
    "plt.xticks(np.arange(len(labels)), labels, rotation = 'vertical')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1.56210081e-05, 5.89942683e-05, 4.07346088e-05, 5.22144655e-05,\n",
       "         1.02624954e-05, 4.00837162e-05],\n",
       "        [6.78369761e-05, 1.05222163e-04, 2.23647614e-04, 1.34143829e-05,\n",
       "         8.32171863e-05, 5.55181468e-05],\n",
       "        [2.41727786e-04, 1.97828325e-04, 3.75232834e-04, 1.54550566e-04,\n",
       "         1.38942763e-04, 2.29237936e-04],\n",
       "        [1.64956471e-03, 1.18066825e-03, 1.93875027e-03, 2.83026136e-04,\n",
       "         8.49010539e-04, 1.81022577e-03],\n",
       "        [5.92637062e-03, 5.57923981e-04, 3.90568003e-03, 1.05292427e-04,\n",
       "         2.09255447e-03, 2.13713408e-03],\n",
       "        [1.08235900e-03, 8.31799698e-04, 1.48159685e-03, 1.10484470e-04,\n",
       "         6.29505666e-04, 6.26944238e-04],\n",
       "        [9.88643058e-03, 2.57950998e-03, 3.02876648e-03, 1.34259753e-04,\n",
       "         5.44499699e-03, 1.03080478e-02],\n",
       "        [6.20629918e-03, 1.57323794e-03, 6.81923795e-03, 1.14800455e-03,\n",
       "         3.03406431e-03, 2.31336802e-03],\n",
       "        [6.92411046e-03, 2.50246422e-03, 1.67338492e-03, 6.02958142e-04,\n",
       "         2.53897137e-03, 2.77345441e-03],\n",
       "        [1.06697418e-02, 2.29685055e-03, 3.71825555e-03, 9.73718648e-04,\n",
       "         7.94705283e-03, 4.27839952e-03],\n",
       "        [2.97383894e-03, 1.91570504e-03, 3.32953152e-03, 2.04051335e-04,\n",
       "         1.85954780e-03, 2.05649063e-03],\n",
       "        [1.86453890e-02, 6.86301908e-04, 2.80548166e-03, 1.14253926e-04,\n",
       "         7.96155073e-03, 4.21524188e-03],\n",
       "        [1.22518772e-02, 7.03476777e-04, 1.57548813e-03, 3.56795237e-04,\n",
       "         4.14012698e-03, 5.86590590e-03],\n",
       "        [6.04410982e-03, 2.29049125e-03, 1.68273109e-03, 3.79152771e-04,\n",
       "         3.03114485e-03, 2.05100398e-03],\n",
       "        [1.77476380e-03, 9.52072500e-04, 7.83712487e-04, 1.12409543e-04,\n",
       "         1.18841650e-03, 3.08052171e-04],\n",
       "        [5.34612546e-03, 8.02494178e-04, 1.69710652e-03, 3.08017246e-04,\n",
       "         3.74148221e-04, 5.59177715e-04],\n",
       "        [3.11817741e-03, 6.58518809e-04, 2.44973390e-03, 4.31176668e-05,\n",
       "         7.81678944e-04, 5.91805379e-04],\n",
       "        [8.33695382e-03, 2.62296479e-03, 4.10896726e-03, 1.23504884e-04,\n",
       "         3.00310785e-03, 9.78262979e-04],\n",
       "        [1.92363421e-03, 2.46508629e-04, 1.06334663e-03, 1.08958920e-04,\n",
       "         4.05923667e-04, 3.94009374e-04],\n",
       "        [8.81437492e-03, 1.10202411e-03, 1.66746881e-03, 3.81004153e-04,\n",
       "         3.92812444e-03, 1.46397133e-03],\n",
       "        [1.05077112e-02, 9.60377161e-04, 1.32563140e-03, 7.52539549e-04,\n",
       "         1.84550660e-03, 7.77349400e-04],\n",
       "        [1.12608699e-02, 9.72125679e-04, 4.84530581e-03, 8.68361152e-04,\n",
       "         2.87042279e-03, 4.47260542e-03],\n",
       "        [1.68247893e-02, 7.51634303e-04, 5.21295983e-03, 1.45995742e-04,\n",
       "         2.35998048e-03, 2.21878896e-03],\n",
       "        [1.09338360e-02, 3.61077394e-03, 1.14809945e-02, 9.85462102e-04,\n",
       "         4.60460829e-03, 3.99874896e-03],\n",
       "        [1.62268486e-02, 5.32831589e-04, 2.58872518e-03, 8.16301210e-04,\n",
       "         2.20718514e-03, 9.61189158e-04],\n",
       "        [5.93350688e-03, 2.80001608e-04, 1.34016084e-03, 1.97486268e-04,\n",
       "         7.13743619e-04, 2.47385725e-03],\n",
       "        [4.49258182e-03, 2.70759990e-03, 2.05099536e-03, 1.99650298e-04,\n",
       "         1.31710642e-03, 1.28413748e-03],\n",
       "        [5.30327857e-03, 9.29927046e-04, 6.02955744e-03, 4.00005665e-04,\n",
       "         1.69331231e-03, 1.98340393e-03],\n",
       "        [8.40916764e-03, 8.39518383e-04, 6.33574184e-03, 6.47750348e-05,\n",
       "         2.31710286e-03, 3.32697853e-03],\n",
       "        [2.74032122e-03, 9.32527124e-04, 3.03057116e-03, 7.82770148e-05,\n",
       "         1.27057405e-03, 3.48358299e-03],\n",
       "        [4.60414495e-03, 8.01628223e-04, 2.49649491e-03, 6.43115709e-05,\n",
       "         1.72407238e-03, 2.19165860e-03],\n",
       "        [5.64274844e-03, 7.69336184e-04, 5.10331336e-03, 8.51317454e-05,\n",
       "         1.64923270e-03, 1.29804702e-03],\n",
       "        [1.20486245e-02, 1.05891144e-03, 6.46368554e-03, 3.12916993e-04,\n",
       "         4.58208704e-03, 1.46872317e-03]]], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
