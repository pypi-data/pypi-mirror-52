{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('id_gsd-ud-train.conllu.txt') as fopen:\n",
    "    corpus = fopen.read().split('\\n')\n",
    "    \n",
    "with open('id_gsd-ud-test.conllu.txt') as fopen:\n",
    "    corpus.extend(fopen.read().split('\\n'))\n",
    "    \n",
    "with open('id_gsd-ud-dev.conllu.txt') as fopen:\n",
    "    corpus.extend(fopen.read().split('\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2idx = {'PAD': 0,'NUM':1,'UNK':2}\n",
    "tag2idx = {'PAD': 0}\n",
    "char2idx = {'PAD': 0,'NUM':1,'UNK':2}\n",
    "word_idx = 3\n",
    "tag_idx = 1\n",
    "char_idx = 3\n",
    "\n",
    "def process_string(string):\n",
    "    string = re.sub('[^A-Za-z0-9\\-\\/ ]+', ' ', string).split()\n",
    "    return [to_title(y.strip()) for y in string]\n",
    "\n",
    "def to_title(string):\n",
    "    if string.isupper():\n",
    "        string = string.title()\n",
    "    return string\n",
    "\n",
    "def process_corpus(corpus, until = None):\n",
    "    global word2idx, tag2idx, char2idx, word_idx, tag_idx, char_idx\n",
    "    sentences, words, depends, labels = [], [], [], []\n",
    "    temp_sentence, temp_word, temp_depend, temp_label = [], [], [], []\n",
    "    for sentence in corpus:\n",
    "        if len(sentence):\n",
    "            if sentence[0] == '#':\n",
    "                continue\n",
    "            sentence = sentence.split('\\t')\n",
    "            temp = process_string(sentence[1])\n",
    "            if not len(temp):\n",
    "                sentence[1] = 'EMPTY'\n",
    "            sentence[1] = process_string(sentence[1])[0]\n",
    "            for c in sentence[1]:\n",
    "                if c not in char2idx:\n",
    "                    char2idx[c] = char_idx\n",
    "                    char_idx += 1\n",
    "            if sentence[7] not in tag2idx:\n",
    "                tag2idx[sentence[7]] = tag_idx\n",
    "                tag_idx += 1\n",
    "            if sentence[1] not in word2idx:\n",
    "                word2idx[sentence[1]] = word_idx\n",
    "                word_idx += 1\n",
    "            temp_word.append(word2idx[sentence[1]])\n",
    "            temp_depend.append(int(sentence[6]) + 1)\n",
    "            temp_label.append(tag2idx[sentence[7]])\n",
    "            temp_sentence.append(sentence[1])\n",
    "        else:\n",
    "            words.append(temp_word)\n",
    "            depends.append(temp_depend)\n",
    "            labels.append(temp_label)\n",
    "            sentences.append(temp_sentence)\n",
    "            temp_word = []\n",
    "            temp_depend = []\n",
    "            temp_label = []\n",
    "            temp_sentence = []\n",
    "    return sentences[:-1], words[:-1], depends[:-1], labels[:-1]\n",
    "        \n",
    "sentences, words, depends, labels = process_corpus(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('augmented.json') as fopen:\n",
    "    augmented = json.load(fopen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_XY(texts):\n",
    "    global word2idx, tag2idx, char2idx, word_idx, tag_idx, char_idx\n",
    "    outside, sentences = [], []\n",
    "    for no, text in enumerate(texts):\n",
    "        s = process_string(text)\n",
    "        sentences.append(s)\n",
    "        inside = []\n",
    "        for w in s:\n",
    "            for c in w:\n",
    "                if c not in char2idx:\n",
    "                    char2idx[c] = char_idx\n",
    "                    char_idx += 1\n",
    "            \n",
    "            if w not in word2idx:\n",
    "                word2idx[w] = word_idx\n",
    "                word_idx += 1\n",
    "                \n",
    "            inside.append(word2idx[w])\n",
    "        outside.append(inside)\n",
    "    return outside, sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_augmented = []\n",
    "for a in augmented:\n",
    "    text_augmented.extend(a[0])\n",
    "    depends.extend(a[1])\n",
    "    labels.extend(a[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "outside, new_sentences = parse_XY(text_augmented)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "words.extend(outside)\n",
    "sentences.extend(new_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50365, 50365, 50365, 50365)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words), len(depends), len(labels), len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_char_seq(batch, UNK = 2):\n",
    "    maxlen_c = max([len(k) for k in batch])\n",
    "    x = [[len(i) for i in k] for k in batch]\n",
    "    maxlen = max([j for i in x for j in i])\n",
    "    temp = np.zeros((len(batch),maxlen_c,maxlen),dtype=np.int32)\n",
    "    for i in range(len(batch)):\n",
    "        for k in range(len(batch[i])):\n",
    "            for no, c in enumerate(batch[i][k][:maxlen][::-1]):\n",
    "                temp[i,k,-1-no] = char2idx.get(c, UNK)\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx2word = {idx: tag for tag, idx in word2idx.items()}\n",
    "idx2tag = {i: w for w, i in tag2idx.items()}\n",
    "char = generate_char_seq(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50365, 189)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = pad_sequences(words,padding='post')\n",
    "depends = pad_sequences(depends,padding='post')\n",
    "labels = pad_sequences(labels,padding='post')\n",
    "words.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "train_X, test_X, train_Y, test_Y, train_depends, test_depends, train_char, test_char = train_test_split(\n",
    "                                                                           words,\n",
    "                                                                           labels,\n",
    "                                                                           depends,\n",
    "                                                                           char,\n",
    "                                                                           test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(\n",
    "        self,\n",
    "        dim_word,\n",
    "        dim_char,\n",
    "        dropout,\n",
    "        learning_rate,\n",
    "        hidden_size_char,\n",
    "        hidden_size_word,\n",
    "        num_layers,\n",
    "        maxlen\n",
    "    ):\n",
    "        def cells(size, reuse = False):\n",
    "            return tf.contrib.rnn.DropoutWrapper(\n",
    "                tf.nn.rnn_cell.LSTMCell(\n",
    "                    size,\n",
    "                    initializer = tf.orthogonal_initializer(),\n",
    "                    reuse = reuse,\n",
    "                ),\n",
    "                output_keep_prob = dropout,\n",
    "            )\n",
    "        \n",
    "        self.word_ids = tf.placeholder(tf.int32, shape = [None, None])\n",
    "        self.char_ids = tf.placeholder(tf.int32, shape = [None, None, None])\n",
    "        self.labels = tf.placeholder(tf.int32, shape = [None, None])\n",
    "        self.depends = tf.placeholder(tf.int32, shape = [None, None])\n",
    "        self.maxlen = tf.shape(self.word_ids)[1]\n",
    "        self.lengths = tf.count_nonzero(self.word_ids, 1)\n",
    "\n",
    "        self.word_embeddings = tf.Variable(\n",
    "            tf.truncated_normal(\n",
    "                [len(word2idx), dim_word], stddev = 1.0 / np.sqrt(dim_word)\n",
    "            )\n",
    "        )\n",
    "        self.char_embeddings = tf.Variable(\n",
    "            tf.truncated_normal(\n",
    "                [len(char2idx), dim_char], stddev = 1.0 / np.sqrt(dim_char)\n",
    "            )\n",
    "        )\n",
    "\n",
    "        word_embedded = tf.nn.embedding_lookup(\n",
    "            self.word_embeddings, self.word_ids\n",
    "        )\n",
    "        char_embedded = tf.nn.embedding_lookup(\n",
    "            self.char_embeddings, self.char_ids\n",
    "        )\n",
    "        s = tf.shape(char_embedded)\n",
    "        char_embedded = tf.reshape(\n",
    "            char_embedded, shape = [s[0] * s[1], s[-2], dim_char]\n",
    "        )\n",
    "\n",
    "        for n in range(num_layers):\n",
    "            (out_fw, out_bw), (\n",
    "                state_fw,\n",
    "                state_bw,\n",
    "            ) = tf.nn.bidirectional_dynamic_rnn(\n",
    "                cell_fw = cells(hidden_size_char),\n",
    "                cell_bw = cells(hidden_size_char),\n",
    "                inputs = char_embedded,\n",
    "                dtype = tf.float32,\n",
    "                scope = 'bidirectional_rnn_char_%d' % (n),\n",
    "            )\n",
    "            char_embedded = tf.concat((out_fw, out_bw), 2)\n",
    "        output = tf.reshape(\n",
    "            char_embedded[:, -1], shape = [s[0], s[1], 2 * hidden_size_char]\n",
    "        )\n",
    "        word_embedded = tf.concat([word_embedded, output], axis = -1)\n",
    "\n",
    "        for n in range(num_layers):\n",
    "            (out_fw, out_bw), (\n",
    "                state_fw,\n",
    "                state_bw,\n",
    "            ) = tf.nn.bidirectional_dynamic_rnn(\n",
    "                cell_fw = cells(hidden_size_word),\n",
    "                cell_bw = cells(hidden_size_word),\n",
    "                inputs = word_embedded,\n",
    "                dtype = tf.float32,\n",
    "                scope = 'bidirectional_rnn_word_%d' % (n),\n",
    "            )\n",
    "            word_embedded = tf.concat((out_fw, out_bw), 2)\n",
    "\n",
    "        logits = tf.layers.dense(word_embedded, len(idx2tag))\n",
    "        \n",
    "        tag_embeddings = tf.Variable(\n",
    "            tf.truncated_normal(\n",
    "                [len(idx2tag), dim_word], stddev = 1.0 / np.sqrt(dim_word)\n",
    "            )\n",
    "        )\n",
    "        logits_max = tf.argmax(logits,axis=2,output_type=tf.int32)\n",
    "        lookup_logits = tf.nn.embedding_lookup(\n",
    "            tag_embeddings, logits_max\n",
    "        )\n",
    "        (out_fw, out_bw), _ = tf.nn.bidirectional_dynamic_rnn(\n",
    "                cell_fw = cells(hidden_size_word),\n",
    "                cell_bw = cells(hidden_size_word),\n",
    "                inputs = word_embedded,\n",
    "                dtype = tf.float32,\n",
    "                scope = 'bidirectional_rnn_word_%d' % (10),\n",
    "            )\n",
    "        \n",
    "        cast_mask = tf.cast(tf.sequence_mask(self.lengths + 1, maxlen = maxlen), dtype = tf.float32)\n",
    "        cast_mask = tf.tile(tf.expand_dims(cast_mask,axis=1),[1,self.maxlen,1]) * 10\n",
    "        \n",
    "        lookup_logits = tf.concat((out_fw, out_bw), 2)\n",
    "        logits_depends = tf.layers.dense(lookup_logits, maxlen)\n",
    "        \n",
    "        logits_depends = tf.multiply(logits_depends, cast_mask)\n",
    "        \n",
    "        log_likelihood, transition_params = tf.contrib.crf.crf_log_likelihood(\n",
    "            logits, self.labels, self.lengths\n",
    "        )\n",
    "        with tf.variable_scope(\"depends\"):\n",
    "            log_likelihood_depends, transition_params_depends = tf.contrib.crf.crf_log_likelihood(\n",
    "                logits_depends, self.depends, self.lengths\n",
    "            )\n",
    "        self.cost = tf.reduce_mean(-log_likelihood) + tf.reduce_mean(-log_likelihood_depends)\n",
    "        self.optimizer = tf.train.AdamOptimizer(\n",
    "            learning_rate = learning_rate\n",
    "        ).minimize(self.cost)\n",
    "        \n",
    "        mask = tf.sequence_mask(self.lengths, maxlen = self.maxlen)\n",
    "        \n",
    "        self.tags_seq, _ = tf.contrib.crf.crf_decode(\n",
    "            logits, transition_params, self.lengths\n",
    "        )\n",
    "        self.tags_seq = tf.identity(self.tags_seq, name = 'logits')\n",
    "        \n",
    "        self.tags_seq_depends, _ = tf.contrib.crf.crf_decode(\n",
    "            logits_depends, transition_params_depends, self.lengths\n",
    "        )\n",
    "        self.tags_seq_depends = tf.identity(self.tags_seq_depends, name = 'logits_depends')\n",
    "\n",
    "        self.prediction = tf.boolean_mask(self.tags_seq, mask)\n",
    "        mask_label = tf.boolean_mask(self.labels, mask)\n",
    "        correct_pred = tf.equal(self.prediction, mask_label)\n",
    "        correct_index = tf.cast(correct_pred, tf.float32)\n",
    "        self.accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "        \n",
    "        self.prediction = tf.boolean_mask(self.tags_seq_depends, mask)\n",
    "        mask_label = tf.boolean_mask(self.depends, mask)\n",
    "        correct_pred = tf.equal(self.prediction, mask_label)\n",
    "        correct_index = tf.cast(correct_pred, tf.float32)\n",
    "        self.accuracy_depends = tf.reduce_mean(tf.cast(correct_pred, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_impl.py:112: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "dim_word = 128\n",
    "dim_char = 256\n",
    "dropout = 0.9\n",
    "learning_rate = 1e-3\n",
    "hidden_size_char = 128\n",
    "hidden_size_word = 64\n",
    "num_layers = 2\n",
    "batch_size = 16\n",
    "\n",
    "model = Model(dim_word,dim_char,dropout,learning_rate,hidden_size_char,hidden_size_word,num_layers,\n",
    "             words.shape[1])\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train minibatch loop: 100%|██████████| 2833/2833 [55:45<00:00,  1.17s/it, accuracy=0.818, accuracy_depends=0.592, cost=32.4]\n",
      "test minibatch loop: 100%|██████████| 315/315 [02:34<00:00,  2.12it/s, accuracy=0.879, accuracy_depends=0.56, cost=37.3] \n",
      "train minibatch loop:   0%|          | 0/2833 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken: 3499.9400725364685\n",
      "epoch: 0, training loss: 61.394930, training acc: 0.717017, training depends: 0.385134, valid loss: 40.262435, valid acc: 0.835491, valid depends: 0.558672\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train minibatch loop: 100%|██████████| 2833/2833 [55:43<00:00,  1.17s/it, accuracy=0.906, accuracy_depends=0.755, cost=20.1]\n",
      "test minibatch loop: 100%|██████████| 315/315 [02:34<00:00,  2.13it/s, accuracy=0.903, accuracy_depends=0.728, cost=26.1]\n",
      "train minibatch loop:   0%|          | 0/2833 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken: 3498.635225534439\n",
      "epoch: 1, training loss: 32.005057, training acc: 0.867122, training depends: 0.644789, valid loss: 28.865218, valid acc: 0.873998, valid depends: 0.695539\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train minibatch loop: 100%|██████████| 2833/2833 [55:40<00:00,  1.16s/it, accuracy=0.922, accuracy_depends=0.843, cost=13.8]\n",
      "test minibatch loop: 100%|██████████| 315/315 [02:34<00:00,  2.12it/s, accuracy=0.896, accuracy_depends=0.762, cost=24.1]\n",
      "train minibatch loop:   0%|          | 0/2833 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken: 3495.000473022461\n",
      "epoch: 2, training loss: 22.238423, training acc: 0.903136, training depends: 0.756233, valid loss: 22.973688, valid acc: 0.893954, valid depends: 0.775838\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train minibatch loop: 100%|██████████| 2833/2833 [55:40<00:00,  1.17s/it, accuracy=0.94, accuracy_depends=0.871, cost=9.31] \n",
      "test minibatch loop: 100%|██████████| 315/315 [02:34<00:00,  2.12it/s, accuracy=0.94, accuracy_depends=0.768, cost=19.1] \n",
      "train minibatch loop:   0%|          | 0/2833 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken: 3494.9204516410828\n",
      "epoch: 3, training loss: 16.122365, training acc: 0.926224, training depends: 0.829008, valid loss: 19.624100, valid acc: 0.906612, valid depends: 0.818411\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train minibatch loop: 100%|██████████| 2833/2833 [55:39<00:00,  1.17s/it, accuracy=0.969, accuracy_depends=0.922, cost=7.06]\n",
      "test minibatch loop: 100%|██████████| 315/315 [02:34<00:00,  2.11it/s, accuracy=0.926, accuracy_depends=0.815, cost=18.7]\n",
      "train minibatch loop:   0%|          | 0/2833 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken: 3494.005749940872\n",
      "epoch: 4, training loss: 12.054353, training acc: 0.943319, training depends: 0.875051, valid loss: 17.211692, valid acc: 0.917632, valid depends: 0.853567\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train minibatch loop: 100%|██████████| 2833/2833 [55:39<00:00,  1.17s/it, accuracy=0.956, accuracy_depends=0.925, cost=5.91]\n",
      "test minibatch loop: 100%|██████████| 315/315 [02:34<00:00,  2.11it/s, accuracy=0.923, accuracy_depends=0.832, cost=16.6]\n",
      "train minibatch loop:   0%|          | 0/2833 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken: 3493.91433262825\n",
      "epoch: 5, training loss: 9.444567, training acc: 0.954951, training depends: 0.902535, valid loss: 15.432670, valid acc: 0.925205, valid depends: 0.874938\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train minibatch loop: 100%|██████████| 2833/2833 [55:40<00:00,  1.16s/it, accuracy=0.984, accuracy_depends=0.944, cost=3.98]\n",
      "test minibatch loop: 100%|██████████| 315/315 [02:34<00:00,  2.12it/s, accuracy=0.933, accuracy_depends=0.869, cost=14]  \n",
      "train minibatch loop:   0%|          | 0/2833 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken: 3495.283851146698\n",
      "epoch: 6, training loss: 7.452240, training acc: 0.965058, training depends: 0.922973, valid loss: 14.489255, valid acc: 0.930936, valid depends: 0.888087\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train minibatch loop: 100%|██████████| 2833/2833 [55:40<00:00,  1.17s/it, accuracy=0.994, accuracy_depends=0.94, cost=4.72] \n",
      "test minibatch loop: 100%|██████████| 315/315 [02:34<00:00,  2.13it/s, accuracy=0.963, accuracy_depends=0.879, cost=10.8]\n",
      "train minibatch loop:   0%|          | 0/2833 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken: 3494.487522125244\n",
      "epoch: 7, training loss: 6.025082, training acc: 0.972536, training depends: 0.937287, valid loss: 13.715300, valid acc: 0.937034, valid depends: 0.900252\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train minibatch loop: 100%|██████████| 2833/2833 [55:39<00:00,  1.17s/it, accuracy=0.991, accuracy_depends=0.95, cost=3.05]  \n",
      "test minibatch loop: 100%|██████████| 315/315 [02:34<00:00,  2.12it/s, accuracy=0.966, accuracy_depends=0.906, cost=10.5]\n",
      "train minibatch loop:   0%|          | 0/2833 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken: 3494.0114550590515\n",
      "epoch: 8, training loss: 5.112749, training acc: 0.977126, training depends: 0.946466, valid loss: 12.850036, valid acc: 0.940592, valid depends: 0.909303\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train minibatch loop: 100%|██████████| 2833/2833 [55:42<00:00,  1.17s/it, accuracy=0.987, accuracy_depends=0.959, cost=2.69]\n",
      "test minibatch loop: 100%|██████████| 315/315 [02:34<00:00,  2.10it/s, accuracy=0.946, accuracy_depends=0.889, cost=12.9]\n",
      "train minibatch loop:   0%|          | 0/2833 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken: 3497.181762933731\n",
      "epoch: 9, training loss: 4.459866, training acc: 0.980873, training depends: 0.952571, valid loss: 12.666941, valid acc: 0.942265, valid depends: 0.913658\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train minibatch loop: 100%|██████████| 2833/2833 [55:43<00:00,  1.16s/it, accuracy=0.994, accuracy_depends=0.969, cost=1.96] \n",
      "test minibatch loop: 100%|██████████| 315/315 [02:34<00:00,  2.12it/s, accuracy=0.963, accuracy_depends=0.916, cost=12.1]\n",
      "train minibatch loop:   0%|          | 0/2833 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken: 3497.9769966602325\n",
      "epoch: 10, training loss: 3.719997, training acc: 0.984097, training depends: 0.960447, valid loss: 12.421102, valid acc: 0.945554, valid depends: 0.918851\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train minibatch loop: 100%|██████████| 2833/2833 [55:43<00:00,  1.17s/it, accuracy=0.987, accuracy_depends=0.984, cost=1.43] \n",
      "test minibatch loop: 100%|██████████| 315/315 [02:34<00:00,  2.09it/s, accuracy=0.956, accuracy_depends=0.903, cost=12.5]\n",
      "train minibatch loop:   0%|          | 0/2833 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken: 3498.7708554267883\n",
      "epoch: 11, training loss: 3.262921, training acc: 0.986176, training depends: 0.965447, valid loss: 12.296852, valid acc: 0.947707, valid depends: 0.922254\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train minibatch loop: 100%|██████████| 2833/2833 [55:45<00:00,  1.17s/it, accuracy=0.997, accuracy_depends=0.978, cost=1.73] \n",
      "test minibatch loop: 100%|██████████| 315/315 [02:34<00:00,  2.10it/s, accuracy=0.966, accuracy_depends=0.916, cost=12.8]\n",
      "train minibatch loop:   0%|          | 0/2833 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken: 3499.6522147655487\n",
      "epoch: 12, training loss: 3.065945, training acc: 0.987473, training depends: 0.967189, valid loss: 12.074139, valid acc: 0.948292, valid depends: 0.926556\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train minibatch loop: 100%|██████████| 2833/2833 [55:44<00:00,  1.16s/it, accuracy=0.997, accuracy_depends=0.984, cost=1.2]  \n",
      "test minibatch loop: 100%|██████████| 315/315 [02:34<00:00,  2.11it/s, accuracy=0.966, accuracy_depends=0.919, cost=12.5]\n",
      "train minibatch loop:   0%|          | 0/2833 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken: 3499.439937353134\n",
      "epoch: 13, training loss: 2.730451, training acc: 0.988901, training depends: 0.970606, valid loss: 11.942601, valid acc: 0.950129, valid depends: 0.930428\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train minibatch loop: 100%|██████████| 2833/2833 [55:44<00:00,  1.18s/it, accuracy=0.984, accuracy_depends=0.972, cost=2.77] \n",
      "test minibatch loop: 100%|██████████| 315/315 [02:34<00:00,  2.11it/s, accuracy=0.977, accuracy_depends=0.899, cost=12]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken: 3498.874011993408\n",
      "epoch: 14, training loss: 2.494391, training acc: 0.989733, training depends: 0.973406, valid loss: 11.962246, valid acc: 0.950911, valid depends: 0.931331\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "for e in range(15):\n",
    "    lasttime = time.time()\n",
    "    train_acc, train_loss, test_acc, test_loss, train_acc_depends, test_acc_depends = 0, 0, 0, 0, 0, 0\n",
    "    pbar = tqdm(\n",
    "        range(0, len(train_X), batch_size), desc = 'train minibatch loop'\n",
    "    )\n",
    "    for i in pbar:\n",
    "        batch_x = train_X[i : min(i + batch_size, train_X.shape[0])]\n",
    "        batch_char = train_char[i : min(i + batch_size, train_X.shape[0])]\n",
    "        batch_y = train_Y[i : min(i + batch_size, train_X.shape[0])]\n",
    "        batch_depends = train_depends[i : min(i + batch_size, train_X.shape[0])]\n",
    "        acc_depends, acc, cost, _ = sess.run(\n",
    "            [model.accuracy_depends, model.accuracy, model.cost, model.optimizer],\n",
    "            feed_dict = {\n",
    "                model.word_ids: batch_x,\n",
    "                model.char_ids: batch_char,\n",
    "                model.labels: batch_y,\n",
    "                model.depends: batch_depends\n",
    "            },\n",
    "        )\n",
    "        assert not np.isnan(cost)\n",
    "        train_loss += cost\n",
    "        train_acc += acc\n",
    "        train_acc_depends += acc_depends\n",
    "        pbar.set_postfix(cost = cost, accuracy = acc, accuracy_depends = acc_depends)\n",
    "        \n",
    "    pbar = tqdm(\n",
    "        range(0, len(test_X), batch_size), desc = 'test minibatch loop'\n",
    "    )\n",
    "    for i in pbar:\n",
    "        batch_x = test_X[i : min(i + batch_size, test_X.shape[0])]\n",
    "        batch_char = test_char[i : min(i + batch_size, test_X.shape[0])]\n",
    "        batch_y = test_Y[i : min(i + batch_size, test_X.shape[0])]\n",
    "        batch_depends = test_depends[i : min(i + batch_size, test_X.shape[0])]\n",
    "        acc_depends, acc, cost = sess.run(\n",
    "            [model.accuracy_depends, model.accuracy, model.cost],\n",
    "            feed_dict = {\n",
    "                model.word_ids: batch_x,\n",
    "                model.char_ids: batch_char,\n",
    "                model.labels: batch_y,\n",
    "                model.depends: batch_depends\n",
    "            },\n",
    "        )\n",
    "        assert not np.isnan(cost)\n",
    "        test_loss += cost\n",
    "        test_acc += acc\n",
    "        test_acc_depends += acc_depends\n",
    "        pbar.set_postfix(cost = cost, accuracy = acc, accuracy_depends = acc_depends)\n",
    "    \n",
    "    train_loss /= len(train_X) / batch_size\n",
    "    train_acc /= len(train_X) / batch_size\n",
    "    train_acc_depends /= len(train_X) / batch_size\n",
    "    test_loss /= len(test_X) / batch_size\n",
    "    test_acc /= len(test_X) / batch_size\n",
    "    test_acc_depends /= len(test_X) / batch_size\n",
    "\n",
    "    print('time taken:', time.time() - lasttime)\n",
    "    print(\n",
    "        'epoch: %d, training loss: %f, training acc: %f, training depends: %f, valid loss: %f, valid acc: %f, valid depends: %f\\n'\n",
    "        % (e, train_loss, train_acc, train_acc_depends, test_loss, test_acc, test_acc_depends)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred2label(pred):\n",
    "    out = []\n",
    "    for pred_i in pred:\n",
    "        out_i = []\n",
    "        for p in pred_i:\n",
    "            out_i.append(idx2tag[p])\n",
    "        out.append(out_i)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "validation minibatch loop:   0%|          | 0/315 [00:00<?, ?it/s]\u001b[A\n",
      "validation minibatch loop:   0%|          | 1/315 [00:00<02:28,  2.11it/s]\u001b[A\n",
      "validation minibatch loop:   1%|          | 2/315 [00:00<02:28,  2.11it/s]\u001b[A\n",
      "validation minibatch loop:   1%|          | 3/315 [00:01<02:27,  2.11it/s]\u001b[A\n",
      "validation minibatch loop:   1%|▏         | 4/315 [00:01<02:27,  2.11it/s]\u001b[A\n",
      "validation minibatch loop:   2%|▏         | 5/315 [00:02<02:26,  2.11it/s]\u001b[A\n",
      "validation minibatch loop:   2%|▏         | 6/315 [00:02<02:25,  2.13it/s]\u001b[A\n",
      "validation minibatch loop:   2%|▏         | 7/315 [00:03<02:23,  2.14it/s]\u001b[A\n",
      "validation minibatch loop:   3%|▎         | 8/315 [00:03<02:23,  2.14it/s]\u001b[A\n",
      "validation minibatch loop:   3%|▎         | 9/315 [00:04<02:25,  2.10it/s]\u001b[A\n",
      "validation minibatch loop:   3%|▎         | 10/315 [00:04<02:25,  2.09it/s]\u001b[A\n",
      "validation minibatch loop:   3%|▎         | 11/315 [00:05<02:24,  2.11it/s]\u001b[A\n",
      "validation minibatch loop:   4%|▍         | 12/315 [00:05<02:23,  2.11it/s]\u001b[A\n",
      "validation minibatch loop:   4%|▍         | 13/315 [00:06<02:23,  2.11it/s]\u001b[A\n",
      "validation minibatch loop:   4%|▍         | 14/315 [00:06<02:21,  2.12it/s]\u001b[A\n",
      "validation minibatch loop:   5%|▍         | 15/315 [00:07<02:24,  2.08it/s]\u001b[A\n",
      "validation minibatch loop:   5%|▌         | 16/315 [00:07<02:24,  2.07it/s]\u001b[A\n",
      "validation minibatch loop:   5%|▌         | 17/315 [00:08<02:22,  2.09it/s]\u001b[A\n",
      "validation minibatch loop:   6%|▌         | 18/315 [00:08<02:20,  2.12it/s]\u001b[A\n",
      "validation minibatch loop:   6%|▌         | 19/315 [00:08<02:19,  2.13it/s]\u001b[A\n",
      "validation minibatch loop:   6%|▋         | 20/315 [00:09<02:20,  2.11it/s]\u001b[A\n",
      "validation minibatch loop:   7%|▋         | 21/315 [00:09<02:19,  2.11it/s]\u001b[A\n",
      "validation minibatch loop:   7%|▋         | 22/315 [00:10<02:18,  2.12it/s]\u001b[A\n",
      "validation minibatch loop:   7%|▋         | 23/315 [00:10<02:16,  2.14it/s]\u001b[A\n",
      "validation minibatch loop:   8%|▊         | 24/315 [00:11<02:16,  2.13it/s]\u001b[A\n",
      "validation minibatch loop:   8%|▊         | 25/315 [00:11<02:15,  2.14it/s]\u001b[A\n",
      "validation minibatch loop:   8%|▊         | 26/315 [00:12<02:14,  2.15it/s]\u001b[A\n",
      "validation minibatch loop:   9%|▊         | 27/315 [00:12<02:14,  2.14it/s]\u001b[A\n",
      "validation minibatch loop:   9%|▉         | 28/315 [00:13<02:15,  2.12it/s]\u001b[A\n",
      "validation minibatch loop:   9%|▉         | 29/315 [00:13<02:15,  2.12it/s]\u001b[A\n",
      "validation minibatch loop:  10%|▉         | 30/315 [00:14<02:15,  2.10it/s]\u001b[A\n",
      "validation minibatch loop:  10%|▉         | 31/315 [00:14<02:14,  2.12it/s]\u001b[A\n",
      "validation minibatch loop:  10%|█         | 32/315 [00:15<02:14,  2.10it/s]\u001b[A\n",
      "validation minibatch loop:  10%|█         | 33/315 [00:15<02:13,  2.11it/s]\u001b[A\n",
      "validation minibatch loop:  11%|█         | 34/315 [00:16<02:11,  2.13it/s]\u001b[A\n",
      "validation minibatch loop:  11%|█         | 35/315 [00:16<02:11,  2.13it/s]\u001b[A\n",
      "validation minibatch loop:  11%|█▏        | 36/315 [00:17<02:12,  2.10it/s]\u001b[A\n",
      "validation minibatch loop:  12%|█▏        | 37/315 [00:17<02:11,  2.11it/s]\u001b[A\n",
      "validation minibatch loop:  12%|█▏        | 38/315 [00:17<02:11,  2.10it/s]\u001b[A\n",
      "validation minibatch loop:  12%|█▏        | 39/315 [00:18<02:10,  2.11it/s]\u001b[A\n",
      "validation minibatch loop:  13%|█▎        | 40/315 [00:18<02:10,  2.11it/s]\u001b[A\n",
      "validation minibatch loop:  13%|█▎        | 41/315 [00:19<02:12,  2.07it/s]\u001b[A\n",
      "validation minibatch loop:  13%|█▎        | 42/315 [00:19<02:10,  2.10it/s]\u001b[A\n",
      "validation minibatch loop:  14%|█▎        | 43/315 [00:20<02:08,  2.12it/s]\u001b[A\n",
      "validation minibatch loop:  14%|█▍        | 44/315 [00:20<02:07,  2.13it/s]\u001b[A\n",
      "validation minibatch loop:  14%|█▍        | 45/315 [00:21<02:07,  2.12it/s]\u001b[A\n",
      "validation minibatch loop:  15%|█▍        | 46/315 [00:21<02:10,  2.06it/s]\u001b[A\n",
      "validation minibatch loop:  15%|█▍        | 47/315 [00:22<02:09,  2.07it/s]\u001b[A\n",
      "validation minibatch loop:  15%|█▌        | 48/315 [00:22<02:09,  2.06it/s]\u001b[A\n",
      "validation minibatch loop:  16%|█▌        | 49/315 [00:23<02:07,  2.09it/s]\u001b[A\n",
      "validation minibatch loop:  16%|█▌        | 50/315 [00:23<02:06,  2.10it/s]\u001b[A\n",
      "validation minibatch loop:  16%|█▌        | 51/315 [00:24<02:05,  2.11it/s]\u001b[A\n",
      "validation minibatch loop:  17%|█▋        | 52/315 [00:24<02:03,  2.13it/s]\u001b[A\n",
      "validation minibatch loop:  17%|█▋        | 53/315 [00:25<02:02,  2.14it/s]\u001b[A\n",
      "validation minibatch loop:  17%|█▋        | 54/315 [00:25<02:01,  2.15it/s]\u001b[A\n",
      "validation minibatch loop:  17%|█▋        | 55/315 [00:26<02:00,  2.15it/s]\u001b[A\n",
      "validation minibatch loop:  18%|█▊        | 56/315 [00:26<02:00,  2.15it/s]\u001b[A\n",
      "validation minibatch loop:  18%|█▊        | 57/315 [00:26<02:00,  2.15it/s]\u001b[A\n",
      "validation minibatch loop:  18%|█▊        | 58/315 [00:27<01:59,  2.15it/s]\u001b[A\n",
      "validation minibatch loop:  19%|█▊        | 59/315 [00:27<01:58,  2.16it/s]\u001b[A\n",
      "validation minibatch loop:  19%|█▉        | 60/315 [00:28<01:59,  2.13it/s]\u001b[A\n",
      "validation minibatch loop:  19%|█▉        | 61/315 [00:28<02:01,  2.09it/s]\u001b[A\n",
      "validation minibatch loop:  20%|█▉        | 62/315 [00:29<02:00,  2.10it/s]\u001b[A\n",
      "validation minibatch loop:  20%|██        | 63/315 [00:29<01:58,  2.12it/s]\u001b[A\n",
      "validation minibatch loop:  20%|██        | 64/315 [00:30<01:57,  2.14it/s]\u001b[A\n",
      "validation minibatch loop:  21%|██        | 65/315 [00:30<01:57,  2.13it/s]\u001b[A\n",
      "validation minibatch loop:  21%|██        | 66/315 [00:31<01:57,  2.13it/s]\u001b[A\n",
      "validation minibatch loop:  21%|██▏       | 67/315 [00:31<01:58,  2.10it/s]\u001b[A\n",
      "validation minibatch loop:  22%|██▏       | 68/315 [00:32<01:56,  2.11it/s]\u001b[A\n",
      "validation minibatch loop:  22%|██▏       | 69/315 [00:32<01:56,  2.11it/s]\u001b[A\n",
      "validation minibatch loop:  22%|██▏       | 70/315 [00:33<01:57,  2.08it/s]\u001b[A\n",
      "validation minibatch loop:  23%|██▎       | 71/315 [00:33<01:57,  2.08it/s]\u001b[A\n",
      "validation minibatch loop:  23%|██▎       | 72/315 [00:34<01:56,  2.09it/s]\u001b[A\n",
      "validation minibatch loop:  23%|██▎       | 73/315 [00:34<01:55,  2.10it/s]\u001b[A\n",
      "validation minibatch loop:  23%|██▎       | 74/315 [00:35<01:55,  2.09it/s]\u001b[A\n",
      "validation minibatch loop:  24%|██▍       | 75/315 [00:35<01:55,  2.08it/s]\u001b[A\n",
      "validation minibatch loop:  24%|██▍       | 76/315 [00:35<01:54,  2.10it/s]\u001b[A\n",
      "validation minibatch loop:  24%|██▍       | 77/315 [00:36<01:54,  2.08it/s]\u001b[A\n",
      "validation minibatch loop:  25%|██▍       | 78/315 [00:36<01:52,  2.11it/s]\u001b[A\n",
      "validation minibatch loop:  25%|██▌       | 79/315 [00:37<01:52,  2.10it/s]\u001b[A\n",
      "validation minibatch loop:  25%|██▌       | 80/315 [00:37<01:52,  2.09it/s]\u001b[A\n",
      "validation minibatch loop:  26%|██▌       | 81/315 [00:38<01:52,  2.09it/s]\u001b[A\n",
      "validation minibatch loop:  26%|██▌       | 82/315 [00:38<01:51,  2.09it/s]\u001b[A\n",
      "validation minibatch loop:  26%|██▋       | 83/315 [00:39<01:50,  2.09it/s]\u001b[A\n",
      "validation minibatch loop:  27%|██▋       | 84/315 [00:39<01:49,  2.12it/s]\u001b[A\n",
      "validation minibatch loop:  27%|██▋       | 85/315 [00:40<01:50,  2.08it/s]\u001b[A\n",
      "validation minibatch loop:  27%|██▋       | 86/315 [00:40<01:48,  2.10it/s]\u001b[A\n",
      "validation minibatch loop:  28%|██▊       | 87/315 [00:41<01:49,  2.08it/s]\u001b[A\n",
      "validation minibatch loop:  28%|██▊       | 88/315 [00:41<01:50,  2.05it/s]\u001b[A\n",
      "validation minibatch loop:  28%|██▊       | 89/315 [00:42<01:50,  2.04it/s]\u001b[A\n",
      "validation minibatch loop:  29%|██▊       | 90/315 [00:42<01:48,  2.08it/s]\u001b[A\n",
      "validation minibatch loop:  29%|██▉       | 91/315 [00:43<01:49,  2.05it/s]\u001b[A\n",
      "validation minibatch loop:  29%|██▉       | 92/315 [00:43<01:48,  2.05it/s]\u001b[A\n",
      "validation minibatch loop:  30%|██▉       | 93/315 [00:44<01:47,  2.07it/s]\u001b[A\n",
      "validation minibatch loop:  30%|██▉       | 94/315 [00:44<01:45,  2.09it/s]\u001b[A\n",
      "validation minibatch loop:  30%|███       | 95/315 [00:45<01:44,  2.10it/s]\u001b[A\n",
      "validation minibatch loop:  30%|███       | 96/315 [00:45<01:43,  2.11it/s]\u001b[A\n",
      "validation minibatch loop:  31%|███       | 97/315 [00:46<01:43,  2.10it/s]\u001b[A\n",
      "validation minibatch loop:  31%|███       | 98/315 [00:46<01:43,  2.09it/s]\u001b[A\n",
      "validation minibatch loop:  31%|███▏      | 99/315 [00:47<01:42,  2.12it/s]\u001b[A\n",
      "validation minibatch loop:  32%|███▏      | 100/315 [00:47<01:41,  2.13it/s]\u001b[A\n",
      "validation minibatch loop:  32%|███▏      | 101/315 [00:47<01:40,  2.13it/s]\u001b[A\n",
      "validation minibatch loop:  32%|███▏      | 102/315 [00:48<01:39,  2.13it/s]\u001b[A\n",
      "validation minibatch loop:  33%|███▎      | 103/315 [00:48<01:39,  2.14it/s]\u001b[A\n",
      "validation minibatch loop:  33%|███▎      | 104/315 [00:49<01:38,  2.13it/s]\u001b[A\n",
      "validation minibatch loop:  33%|███▎      | 105/315 [00:49<01:37,  2.15it/s]\u001b[A\n",
      "validation minibatch loop:  34%|███▎      | 106/315 [00:50<01:39,  2.10it/s]\u001b[A\n",
      "validation minibatch loop:  34%|███▍      | 107/315 [00:50<01:39,  2.08it/s]\u001b[A\n",
      "validation minibatch loop:  34%|███▍      | 108/315 [00:51<01:39,  2.08it/s]\u001b[A\n",
      "validation minibatch loop:  35%|███▍      | 109/315 [00:51<01:38,  2.09it/s]\u001b[A\n",
      "validation minibatch loop:  35%|███▍      | 110/315 [00:52<01:39,  2.06it/s]\u001b[A\n",
      "validation minibatch loop:  35%|███▌      | 111/315 [00:52<01:38,  2.08it/s]\u001b[A\n",
      "validation minibatch loop:  36%|███▌      | 112/315 [00:53<01:39,  2.04it/s]\u001b[A\n",
      "validation minibatch loop:  36%|███▌      | 113/315 [00:53<01:38,  2.06it/s]\u001b[A\n",
      "validation minibatch loop:  36%|███▌      | 114/315 [00:54<01:35,  2.10it/s]\u001b[A\n",
      "validation minibatch loop:  37%|███▋      | 115/315 [00:54<01:35,  2.10it/s]\u001b[A\n",
      "validation minibatch loop:  37%|███▋      | 116/315 [00:55<01:33,  2.12it/s]\u001b[A\n",
      "validation minibatch loop:  37%|███▋      | 117/315 [00:55<01:33,  2.11it/s]\u001b[A\n",
      "validation minibatch loop:  37%|███▋      | 118/315 [00:56<01:35,  2.06it/s]\u001b[A\n",
      "validation minibatch loop:  38%|███▊      | 119/315 [00:56<01:35,  2.06it/s]\u001b[A\n",
      "validation minibatch loop:  38%|███▊      | 120/315 [00:57<01:34,  2.06it/s]\u001b[A\n",
      "validation minibatch loop:  38%|███▊      | 121/315 [00:57<01:33,  2.07it/s]\u001b[A\n",
      "validation minibatch loop:  39%|███▊      | 122/315 [00:58<01:33,  2.07it/s]\u001b[A\n",
      "validation minibatch loop:  39%|███▉      | 123/315 [00:58<01:33,  2.05it/s]\u001b[A\n",
      "validation minibatch loop:  39%|███▉      | 124/315 [00:58<01:31,  2.08it/s]\u001b[A\n",
      "validation minibatch loop:  40%|███▉      | 125/315 [00:59<01:31,  2.07it/s]\u001b[A\n",
      "validation minibatch loop:  40%|████      | 126/315 [00:59<01:31,  2.08it/s]\u001b[A\n",
      "validation minibatch loop:  40%|████      | 127/315 [01:00<01:30,  2.08it/s]\u001b[A\n",
      "validation minibatch loop:  41%|████      | 128/315 [01:00<01:29,  2.10it/s]\u001b[A\n",
      "validation minibatch loop:  41%|████      | 129/315 [01:01<01:27,  2.12it/s]\u001b[A\n",
      "validation minibatch loop:  41%|████▏     | 130/315 [01:01<01:27,  2.11it/s]\u001b[A\n",
      "validation minibatch loop:  42%|████▏     | 131/315 [01:02<01:28,  2.09it/s]\u001b[A\n",
      "validation minibatch loop:  42%|████▏     | 132/315 [01:02<01:27,  2.09it/s]\u001b[A\n",
      "validation minibatch loop:  42%|████▏     | 133/315 [01:03<01:26,  2.10it/s]\u001b[A\n",
      "validation minibatch loop:  43%|████▎     | 134/315 [01:03<01:25,  2.12it/s]\u001b[A\n",
      "validation minibatch loop:  43%|████▎     | 135/315 [01:04<01:25,  2.10it/s]\u001b[A\n",
      "validation minibatch loop:  43%|████▎     | 136/315 [01:04<01:26,  2.08it/s]\u001b[A\n",
      "validation minibatch loop:  43%|████▎     | 137/315 [01:05<01:24,  2.10it/s]\u001b[A\n",
      "validation minibatch loop:  44%|████▍     | 138/315 [01:05<01:25,  2.06it/s]\u001b[A\n",
      "validation minibatch loop:  44%|████▍     | 139/315 [01:06<01:24,  2.07it/s]\u001b[A\n",
      "validation minibatch loop:  44%|████▍     | 140/315 [01:06<01:26,  2.02it/s]\u001b[A\n",
      "validation minibatch loop:  45%|████▍     | 141/315 [01:07<01:24,  2.05it/s]\u001b[A\n",
      "validation minibatch loop:  45%|████▌     | 142/315 [01:07<01:23,  2.07it/s]\u001b[A\n",
      "validation minibatch loop:  45%|████▌     | 143/315 [01:08<01:21,  2.10it/s]\u001b[A\n",
      "validation minibatch loop:  46%|████▌     | 144/315 [01:08<01:21,  2.10it/s]\u001b[A\n",
      "validation minibatch loop:  46%|████▌     | 145/315 [01:09<01:20,  2.11it/s]\u001b[A\n",
      "validation minibatch loop:  46%|████▋     | 146/315 [01:09<01:19,  2.13it/s]\u001b[A\n",
      "validation minibatch loop:  47%|████▋     | 147/315 [01:09<01:18,  2.13it/s]\u001b[A\n",
      "validation minibatch loop:  47%|████▋     | 148/315 [01:10<01:19,  2.11it/s]\u001b[A\n",
      "validation minibatch loop:  47%|████▋     | 149/315 [01:10<01:19,  2.09it/s]\u001b[A\n",
      "validation minibatch loop:  48%|████▊     | 150/315 [01:11<01:19,  2.08it/s]\u001b[A\n",
      "validation minibatch loop:  48%|████▊     | 151/315 [01:11<01:18,  2.10it/s]\u001b[A\n",
      "validation minibatch loop:  48%|████▊     | 152/315 [01:12<01:16,  2.12it/s]\u001b[A\n",
      "validation minibatch loop:  49%|████▊     | 153/315 [01:12<01:16,  2.12it/s]\u001b[A\n",
      "validation minibatch loop:  49%|████▉     | 154/315 [01:13<01:15,  2.14it/s]\u001b[A\n",
      "validation minibatch loop:  49%|████▉     | 155/315 [01:13<01:15,  2.12it/s]\u001b[A\n",
      "validation minibatch loop:  50%|████▉     | 156/315 [01:14<01:14,  2.13it/s]\u001b[A\n",
      "validation minibatch loop:  50%|████▉     | 157/315 [01:14<01:14,  2.12it/s]\u001b[A\n",
      "validation minibatch loop:  50%|█████     | 158/315 [01:15<01:14,  2.12it/s]\u001b[A\n",
      "validation minibatch loop:  50%|█████     | 159/315 [01:15<01:13,  2.11it/s]\u001b[A\n",
      "validation minibatch loop:  51%|█████     | 160/315 [01:16<01:14,  2.09it/s]\u001b[A\n",
      "validation minibatch loop:  51%|█████     | 161/315 [01:16<01:13,  2.09it/s]\u001b[A\n",
      "validation minibatch loop:  51%|█████▏    | 162/315 [01:17<01:12,  2.10it/s]\u001b[A\n",
      "validation minibatch loop:  52%|█████▏    | 163/315 [01:17<01:12,  2.11it/s]\u001b[A\n",
      "validation minibatch loop:  52%|█████▏    | 164/315 [01:18<01:11,  2.12it/s]\u001b[A\n",
      "validation minibatch loop:  52%|█████▏    | 165/315 [01:18<01:12,  2.07it/s]\u001b[A\n",
      "validation minibatch loop:  53%|█████▎    | 166/315 [01:19<01:12,  2.05it/s]\u001b[A\n",
      "validation minibatch loop:  53%|█████▎    | 167/315 [01:19<01:12,  2.05it/s]\u001b[A\n",
      "validation minibatch loop:  53%|█████▎    | 168/315 [01:19<01:10,  2.08it/s]\u001b[A\n",
      "validation minibatch loop:  54%|█████▎    | 169/315 [01:20<01:09,  2.10it/s]\u001b[A\n",
      "validation minibatch loop:  54%|█████▍    | 170/315 [01:20<01:08,  2.13it/s]\u001b[A\n",
      "validation minibatch loop:  54%|█████▍    | 171/315 [01:21<01:10,  2.03it/s]\u001b[A\n",
      "validation minibatch loop:  55%|█████▍    | 172/315 [01:21<01:09,  2.07it/s]\u001b[A\n",
      "validation minibatch loop:  55%|█████▍    | 173/315 [01:22<01:08,  2.08it/s]\u001b[A\n",
      "validation minibatch loop:  55%|█████▌    | 174/315 [01:22<01:08,  2.06it/s]\u001b[A\n",
      "validation minibatch loop:  56%|█████▌    | 175/315 [01:23<01:09,  2.02it/s]\u001b[A\n",
      "validation minibatch loop:  56%|█████▌    | 176/315 [01:23<01:07,  2.05it/s]\u001b[A\n",
      "validation minibatch loop:  56%|█████▌    | 177/315 [01:24<01:06,  2.06it/s]\u001b[A\n",
      "validation minibatch loop:  57%|█████▋    | 178/315 [01:24<01:05,  2.10it/s]\u001b[A\n",
      "validation minibatch loop:  57%|█████▋    | 179/315 [01:25<01:04,  2.11it/s]\u001b[A\n",
      "validation minibatch loop:  57%|█████▋    | 180/315 [01:25<01:04,  2.10it/s]\u001b[A\n",
      "validation minibatch loop:  57%|█████▋    | 181/315 [01:26<01:03,  2.10it/s]\u001b[A\n",
      "validation minibatch loop:  58%|█████▊    | 182/315 [01:26<01:03,  2.09it/s]\u001b[A\n",
      "validation minibatch loop:  58%|█████▊    | 183/315 [01:27<01:03,  2.09it/s]\u001b[A\n",
      "validation minibatch loop:  58%|█████▊    | 184/315 [01:27<01:02,  2.08it/s]\u001b[A\n",
      "validation minibatch loop:  59%|█████▊    | 185/315 [01:28<01:01,  2.10it/s]\u001b[A\n",
      "validation minibatch loop:  59%|█████▉    | 186/315 [01:28<01:01,  2.11it/s]\u001b[A\n",
      "validation minibatch loop:  59%|█████▉    | 187/315 [01:29<01:02,  2.06it/s]\u001b[A\n",
      "validation minibatch loop:  60%|█████▉    | 188/315 [01:29<01:00,  2.09it/s]\u001b[A\n",
      "validation minibatch loop:  60%|██████    | 189/315 [01:30<00:59,  2.12it/s]\u001b[A\n",
      "validation minibatch loop:  60%|██████    | 190/315 [01:30<00:58,  2.13it/s]\u001b[A\n",
      "validation minibatch loop:  61%|██████    | 191/315 [01:30<00:57,  2.14it/s]\u001b[A\n",
      "validation minibatch loop:  61%|██████    | 192/315 [01:31<00:57,  2.15it/s]\u001b[A\n",
      "validation minibatch loop:  61%|██████▏   | 193/315 [01:31<00:56,  2.14it/s]\u001b[A\n",
      "validation minibatch loop:  62%|██████▏   | 194/315 [01:32<00:57,  2.09it/s]\u001b[A\n",
      "validation minibatch loop:  62%|██████▏   | 195/315 [01:32<00:56,  2.12it/s]\u001b[A\n",
      "validation minibatch loop:  62%|██████▏   | 196/315 [01:33<00:56,  2.11it/s]\u001b[A\n",
      "validation minibatch loop:  63%|██████▎   | 197/315 [01:33<00:55,  2.11it/s]\u001b[A\n",
      "validation minibatch loop:  63%|██████▎   | 198/315 [01:34<00:55,  2.13it/s]\u001b[A\n",
      "validation minibatch loop:  63%|██████▎   | 199/315 [01:34<00:55,  2.10it/s]\u001b[A\n",
      "validation minibatch loop:  63%|██████▎   | 200/315 [01:35<00:56,  2.02it/s]\u001b[A\n",
      "validation minibatch loop:  64%|██████▍   | 201/315 [01:35<00:56,  2.00it/s]\u001b[A\n",
      "validation minibatch loop:  64%|██████▍   | 202/315 [01:36<00:55,  2.04it/s]\u001b[A\n",
      "validation minibatch loop:  64%|██████▍   | 203/315 [01:36<00:54,  2.05it/s]\u001b[A\n",
      "validation minibatch loop:  65%|██████▍   | 204/315 [01:37<00:54,  2.04it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "validation minibatch loop:  65%|██████▌   | 205/315 [01:37<00:53,  2.07it/s]\u001b[A\n",
      "validation minibatch loop:  65%|██████▌   | 206/315 [01:38<00:52,  2.08it/s]\u001b[A\n",
      "validation minibatch loop:  66%|██████▌   | 207/315 [01:38<00:51,  2.10it/s]\u001b[A\n",
      "validation minibatch loop:  66%|██████▌   | 208/315 [01:39<00:51,  2.09it/s]\u001b[A\n",
      "validation minibatch loop:  66%|██████▋   | 209/315 [01:39<00:51,  2.07it/s]\u001b[A\n",
      "validation minibatch loop:  67%|██████▋   | 210/315 [01:40<00:50,  2.08it/s]\u001b[A\n",
      "validation minibatch loop:  67%|██████▋   | 211/315 [01:40<00:49,  2.11it/s]\u001b[A\n",
      "validation minibatch loop:  67%|██████▋   | 212/315 [01:41<00:48,  2.10it/s]\u001b[A\n",
      "validation minibatch loop:  68%|██████▊   | 213/315 [01:41<00:48,  2.09it/s]\u001b[A\n",
      "validation minibatch loop:  68%|██████▊   | 214/315 [01:42<00:47,  2.11it/s]\u001b[A\n",
      "validation minibatch loop:  68%|██████▊   | 215/315 [01:42<00:47,  2.10it/s]\u001b[A\n",
      "validation minibatch loop:  69%|██████▊   | 216/315 [01:42<00:46,  2.12it/s]\u001b[A\n",
      "validation minibatch loop:  69%|██████▉   | 217/315 [01:43<00:46,  2.09it/s]\u001b[A\n",
      "validation minibatch loop:  69%|██████▉   | 218/315 [01:43<00:46,  2.10it/s]\u001b[A\n",
      "validation minibatch loop:  70%|██████▉   | 219/315 [01:44<00:45,  2.11it/s]\u001b[A\n",
      "validation minibatch loop:  70%|██████▉   | 220/315 [01:44<00:45,  2.11it/s]\u001b[A\n",
      "validation minibatch loop:  70%|███████   | 221/315 [01:45<00:44,  2.13it/s]\u001b[A\n",
      "validation minibatch loop:  70%|███████   | 222/315 [01:45<00:43,  2.14it/s]\u001b[A\n",
      "validation minibatch loop:  71%|███████   | 223/315 [01:46<00:45,  2.04it/s]\u001b[A\n",
      "validation minibatch loop:  71%|███████   | 224/315 [01:46<00:43,  2.07it/s]\u001b[A\n",
      "validation minibatch loop:  71%|███████▏  | 225/315 [01:47<00:43,  2.06it/s]\u001b[A\n",
      "validation minibatch loop:  72%|███████▏  | 226/315 [01:47<00:42,  2.08it/s]\u001b[A\n",
      "validation minibatch loop:  72%|███████▏  | 227/315 [01:48<00:42,  2.07it/s]\u001b[A\n",
      "validation minibatch loop:  72%|███████▏  | 228/315 [01:48<00:41,  2.10it/s]\u001b[A\n",
      "validation minibatch loop:  73%|███████▎  | 229/315 [01:49<00:40,  2.11it/s]\u001b[A\n",
      "validation minibatch loop:  73%|███████▎  | 230/315 [01:49<00:40,  2.12it/s]\u001b[A\n",
      "validation minibatch loop:  73%|███████▎  | 231/315 [01:50<00:39,  2.12it/s]\u001b[A\n",
      "validation minibatch loop:  74%|███████▎  | 232/315 [01:50<00:38,  2.13it/s]\u001b[A\n",
      "validation minibatch loop:  74%|███████▍  | 233/315 [01:51<00:38,  2.12it/s]\u001b[A\n",
      "validation minibatch loop:  74%|███████▍  | 234/315 [01:51<00:38,  2.12it/s]\u001b[A\n",
      "validation minibatch loop:  75%|███████▍  | 235/315 [01:52<00:38,  2.10it/s]\u001b[A\n",
      "validation minibatch loop:  75%|███████▍  | 236/315 [01:52<00:37,  2.11it/s]\u001b[A\n",
      "validation minibatch loop:  75%|███████▌  | 237/315 [01:53<00:38,  2.04it/s]\u001b[A\n",
      "validation minibatch loop:  76%|███████▌  | 238/315 [01:53<00:37,  2.07it/s]\u001b[A\n",
      "validation minibatch loop:  76%|███████▌  | 239/315 [01:53<00:36,  2.08it/s]\u001b[A\n",
      "validation minibatch loop:  76%|███████▌  | 240/315 [01:54<00:36,  2.05it/s]\u001b[A\n",
      "validation minibatch loop:  77%|███████▋  | 241/315 [01:54<00:35,  2.06it/s]\u001b[A\n",
      "validation minibatch loop:  77%|███████▋  | 242/315 [01:55<00:35,  2.08it/s]\u001b[A\n",
      "validation minibatch loop:  77%|███████▋  | 243/315 [01:55<00:34,  2.11it/s]\u001b[A\n",
      "validation minibatch loop:  77%|███████▋  | 244/315 [01:56<00:34,  2.05it/s]\u001b[A\n",
      "validation minibatch loop:  78%|███████▊  | 245/315 [01:56<00:33,  2.09it/s]\u001b[A\n",
      "validation minibatch loop:  78%|███████▊  | 246/315 [01:57<00:32,  2.10it/s]\u001b[A\n",
      "validation minibatch loop:  78%|███████▊  | 247/315 [01:57<00:32,  2.11it/s]\u001b[A\n",
      "validation minibatch loop:  79%|███████▊  | 248/315 [01:58<00:31,  2.11it/s]\u001b[A\n",
      "validation minibatch loop:  79%|███████▉  | 249/315 [01:58<00:31,  2.12it/s]\u001b[A\n",
      "validation minibatch loop:  79%|███████▉  | 250/315 [01:59<00:30,  2.13it/s]\u001b[A\n",
      "validation minibatch loop:  80%|███████▉  | 251/315 [01:59<00:31,  2.06it/s]\u001b[A\n",
      "validation minibatch loop:  80%|████████  | 252/315 [02:00<00:30,  2.08it/s]\u001b[A\n",
      "validation minibatch loop:  80%|████████  | 253/315 [02:00<00:29,  2.09it/s]\u001b[A\n",
      "validation minibatch loop:  81%|████████  | 254/315 [02:01<00:29,  2.10it/s]\u001b[A\n",
      "validation minibatch loop:  81%|████████  | 255/315 [02:01<00:28,  2.08it/s]\u001b[A\n",
      "validation minibatch loop:  81%|████████▏ | 256/315 [02:02<00:28,  2.10it/s]\u001b[A\n",
      "validation minibatch loop:  82%|████████▏ | 257/315 [02:02<00:27,  2.10it/s]\u001b[A\n",
      "validation minibatch loop:  82%|████████▏ | 258/315 [02:03<00:26,  2.12it/s]\u001b[A\n",
      "validation minibatch loop:  82%|████████▏ | 259/315 [02:03<00:26,  2.10it/s]\u001b[A\n",
      "validation minibatch loop:  83%|████████▎ | 260/315 [02:03<00:26,  2.11it/s]\u001b[A\n",
      "validation minibatch loop:  83%|████████▎ | 261/315 [02:04<00:25,  2.12it/s]\u001b[A\n",
      "validation minibatch loop:  83%|████████▎ | 262/315 [02:04<00:25,  2.09it/s]\u001b[A\n",
      "validation minibatch loop:  83%|████████▎ | 263/315 [02:05<00:24,  2.09it/s]\u001b[A\n",
      "validation minibatch loop:  84%|████████▍ | 264/315 [02:05<00:24,  2.10it/s]\u001b[A\n",
      "validation minibatch loop:  84%|████████▍ | 265/315 [02:06<00:23,  2.12it/s]\u001b[A\n",
      "validation minibatch loop:  84%|████████▍ | 266/315 [02:06<00:23,  2.09it/s]\u001b[A\n",
      "validation minibatch loop:  85%|████████▍ | 267/315 [02:07<00:23,  2.06it/s]\u001b[A\n",
      "validation minibatch loop:  85%|████████▌ | 268/315 [02:07<00:23,  2.02it/s]\u001b[A\n",
      "validation minibatch loop:  85%|████████▌ | 269/315 [02:08<00:22,  2.05it/s]\u001b[A\n",
      "validation minibatch loop:  86%|████████▌ | 270/315 [02:08<00:21,  2.07it/s]\u001b[A\n",
      "validation minibatch loop:  86%|████████▌ | 271/315 [02:09<00:20,  2.10it/s]\u001b[A\n",
      "validation minibatch loop:  86%|████████▋ | 272/315 [02:09<00:20,  2.11it/s]\u001b[A\n",
      "validation minibatch loop:  87%|████████▋ | 273/315 [02:10<00:19,  2.11it/s]\u001b[A\n",
      "validation minibatch loop:  87%|████████▋ | 274/315 [02:10<00:19,  2.10it/s]\u001b[A\n",
      "validation minibatch loop:  87%|████████▋ | 275/315 [02:11<00:19,  2.09it/s]\u001b[A\n",
      "validation minibatch loop:  88%|████████▊ | 276/315 [02:11<00:18,  2.11it/s]\u001b[A\n",
      "validation minibatch loop:  88%|████████▊ | 277/315 [02:12<00:18,  2.10it/s]\u001b[A\n",
      "validation minibatch loop:  88%|████████▊ | 278/315 [02:12<00:17,  2.09it/s]\u001b[A\n",
      "validation minibatch loop:  89%|████████▊ | 279/315 [02:13<00:17,  2.10it/s]\u001b[A\n",
      "validation minibatch loop:  89%|████████▉ | 280/315 [02:13<00:16,  2.10it/s]\u001b[A\n",
      "validation minibatch loop:  89%|████████▉ | 281/315 [02:14<00:16,  2.10it/s]\u001b[A\n",
      "validation minibatch loop:  90%|████████▉ | 282/315 [02:14<00:15,  2.11it/s]\u001b[A\n",
      "validation minibatch loop:  90%|████████▉ | 283/315 [02:14<00:15,  2.11it/s]\u001b[A\n",
      "validation minibatch loop:  90%|█████████ | 284/315 [02:15<00:15,  2.06it/s]\u001b[A\n",
      "validation minibatch loop:  90%|█████████ | 285/315 [02:15<00:14,  2.09it/s]\u001b[A\n",
      "validation minibatch loop:  91%|█████████ | 286/315 [02:16<00:14,  2.07it/s]\u001b[A\n",
      "validation minibatch loop:  91%|█████████ | 287/315 [02:16<00:13,  2.02it/s]\u001b[A\n",
      "validation minibatch loop:  91%|█████████▏| 288/315 [02:17<00:13,  2.04it/s]\u001b[A\n",
      "validation minibatch loop:  92%|█████████▏| 289/315 [02:17<00:12,  2.07it/s]\u001b[A\n",
      "validation minibatch loop:  92%|█████████▏| 290/315 [02:18<00:12,  2.05it/s]\u001b[A\n",
      "validation minibatch loop:  92%|█████████▏| 291/315 [02:18<00:11,  2.09it/s]\u001b[A\n",
      "validation minibatch loop:  93%|█████████▎| 292/315 [02:19<00:10,  2.11it/s]\u001b[A\n",
      "validation minibatch loop:  93%|█████████▎| 293/315 [02:19<00:10,  2.12it/s]\u001b[A\n",
      "validation minibatch loop:  93%|█████████▎| 294/315 [02:20<00:09,  2.13it/s]\u001b[A\n",
      "validation minibatch loop:  94%|█████████▎| 295/315 [02:20<00:09,  2.12it/s]\u001b[A\n",
      "validation minibatch loop:  94%|█████████▍| 296/315 [02:21<00:09,  2.07it/s]\u001b[A\n",
      "validation minibatch loop:  94%|█████████▍| 297/315 [02:21<00:08,  2.09it/s]\u001b[A\n",
      "validation minibatch loop:  95%|█████████▍| 298/315 [02:22<00:08,  2.08it/s]\u001b[A\n",
      "validation minibatch loop:  95%|█████████▍| 299/315 [02:22<00:07,  2.06it/s]\u001b[A\n",
      "validation minibatch loop:  95%|█████████▌| 300/315 [02:23<00:07,  2.08it/s]\u001b[A\n",
      "validation minibatch loop:  96%|█████████▌| 301/315 [02:23<00:06,  2.10it/s]\u001b[A\n",
      "validation minibatch loop:  96%|█████████▌| 302/315 [02:24<00:06,  2.12it/s]\u001b[A\n",
      "validation minibatch loop:  96%|█████████▌| 303/315 [02:24<00:05,  2.12it/s]\u001b[A\n",
      "validation minibatch loop:  97%|█████████▋| 304/315 [02:25<00:05,  2.10it/s]\u001b[A\n",
      "validation minibatch loop:  97%|█████████▋| 305/315 [02:25<00:05,  1.99it/s]\u001b[A\n",
      "validation minibatch loop:  97%|█████████▋| 306/315 [02:26<00:04,  2.03it/s]\u001b[A\n",
      "validation minibatch loop:  97%|█████████▋| 307/315 [02:26<00:03,  2.06it/s]\u001b[A\n",
      "validation minibatch loop:  98%|█████████▊| 308/315 [02:27<00:03,  2.09it/s]\u001b[A\n",
      "validation minibatch loop:  98%|█████████▊| 309/315 [02:27<00:02,  2.09it/s]\u001b[A\n",
      "validation minibatch loop:  98%|█████████▊| 310/315 [02:27<00:02,  2.11it/s]\u001b[A\n",
      "validation minibatch loop:  99%|█████████▊| 311/315 [02:28<00:01,  2.09it/s]\u001b[A\n",
      "validation minibatch loop:  99%|█████████▉| 312/315 [02:28<00:01,  2.11it/s]\u001b[A\n",
      "validation minibatch loop:  99%|█████████▉| 313/315 [02:29<00:00,  2.10it/s]\u001b[A\n",
      "validation minibatch loop: 100%|█████████▉| 314/315 [02:29<00:00,  2.12it/s]\u001b[A\n",
      "validation minibatch loop: 100%|██████████| 315/315 [02:30<00:00,  2.18it/s]\u001b[A\n",
      "\u001b[A"
     ]
    }
   ],
   "source": [
    "real_Y, predict_Y, real_depends, predict_depends = [], [], [], []\n",
    "\n",
    "pbar = tqdm(\n",
    "    range(0, len(test_X), batch_size), desc = 'validation minibatch loop'\n",
    ")\n",
    "for i in pbar:\n",
    "    batch_x = test_X[i : min(i + batch_size, test_X.shape[0])]\n",
    "    batch_char = test_char[i : min(i + batch_size, test_X.shape[0])]\n",
    "    batch_y = test_Y[i : min(i + batch_size, test_X.shape[0])]\n",
    "    batch_depends = test_depends[i : min(i + batch_size, test_X.shape[0])]\n",
    "    seq, deps = sess.run([model.tags_seq, model.tags_seq_depends],\n",
    "            feed_dict = {\n",
    "                model.word_ids: batch_x,\n",
    "                model.char_ids: batch_char,\n",
    "            },\n",
    "    )\n",
    "    predicted = pred2label(seq)\n",
    "    real = pred2label(batch_y)\n",
    "    predict_Y.extend(predicted)\n",
    "    real_Y.extend(real)\n",
    "    \n",
    "    real_depends.extend(batch_depends.tolist())\n",
    "    predict_depends.extend(deps.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "          PAD     1.0000    1.0000    1.0000    841717\n",
      "          acl     0.9501    0.9110    0.9301      2965\n",
      "        advcl     0.8127    0.8719    0.8413      1249\n",
      "       advmod     0.9423    0.9329    0.9376      4846\n",
      "         amod     0.9141    0.9104    0.9123      4208\n",
      "        appos     0.9282    0.9266    0.9274      2412\n",
      "         case     0.9757    0.9756    0.9756     10896\n",
      "           cc     0.9613    0.9726    0.9669      3171\n",
      "        ccomp     0.8115    0.7094    0.7570       437\n",
      "     compound     0.9176    0.9350    0.9263      6804\n",
      "compound:plur     0.9172    0.9767    0.9460       601\n",
      "         conj     0.9504    0.9493    0.9498      4119\n",
      "          cop     0.9621    0.9761    0.9690       962\n",
      "        csubj     0.8095    0.7083    0.7556        24\n",
      "   csubj:pass     0.7500    0.6000    0.6667        10\n",
      "          dep     0.8712    0.8333    0.8519       552\n",
      "          det     0.9288    0.9339    0.9313      4082\n",
      "        fixed     0.9229    0.8288    0.8733       549\n",
      "         flat     0.9619    0.9712    0.9666     10328\n",
      "         iobj     0.7273    0.8000    0.7619        10\n",
      "         mark     0.9059    0.9260    0.9159      1487\n",
      "         nmod     0.9159    0.9318    0.9238      4105\n",
      "        nsubj     0.9284    0.9550    0.9415      6316\n",
      "   nsubj:pass     0.9367    0.8999    0.9179      2007\n",
      "       nummod     0.9743    0.9617    0.9680      4024\n",
      "          obj     0.9428    0.9340    0.9384      5184\n",
      "          obl     0.9598    0.9292    0.9442      5776\n",
      "    parataxis     0.8301    0.7537    0.7900       337\n",
      "        punct     0.9957    0.9984    0.9971     16529\n",
      "         root     0.9654    0.9694    0.9674      5037\n",
      "        xcomp     0.8955    0.8575    0.8761      1249\n",
      "\n",
      "  avg / total     0.9943    0.9943    0.9943    951993\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(np.array(real_Y).ravel(), np.array(predict_Y).ravel(), digits = 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     1.0000    1.0000    1.0000    841717\n",
      "          1     0.9638    0.9676    0.9657      5037\n",
      "          2     0.9526    0.9295    0.9409      4367\n",
      "          3     0.9410    0.9395    0.9403      4942\n",
      "          4     0.9544    0.9516    0.9530      6440\n",
      "          5     0.9453    0.9514    0.9484      6035\n",
      "          6     0.9376    0.9633    0.9503      6024\n",
      "          7     0.9456    0.9491    0.9473      5398\n",
      "          8     0.9506    0.9438    0.9472      5482\n",
      "          9     0.9488    0.9455    0.9472      4977\n",
      "         10     0.9331    0.9578    0.9453      4430\n",
      "         11     0.9453    0.9468    0.9460      4583\n",
      "         12     0.9364    0.9420    0.9392      3673\n",
      "         13     0.9495    0.9298    0.9395      3719\n",
      "         14     0.9425    0.9343    0.9384      3316\n",
      "         15     0.9460    0.9197    0.9327      3065\n",
      "         16     0.9125    0.9443    0.9281      3071\n",
      "         17     0.9350    0.9228    0.9289      2667\n",
      "         18     0.9377    0.9198    0.9286      2469\n",
      "         19     0.9167    0.9267    0.9217      2197\n",
      "         20     0.9076    0.9286    0.9180      2031\n",
      "         21     0.9355    0.8701    0.9016      1917\n",
      "         22     0.8985    0.8980    0.8983      1834\n",
      "         23     0.9038    0.9011    0.9025      1689\n",
      "         24     0.9066    0.8968    0.9017      1667\n",
      "         25     0.8782    0.9227    0.8999      1320\n",
      "         26     0.8769    0.9204    0.8982      1169\n",
      "         27     0.9041    0.9049    0.9045      1094\n",
      "         28     0.9054    0.8825    0.8938       987\n",
      "         29     0.9352    0.8799    0.9067      1099\n",
      "         30     0.8952    0.9110    0.9031       910\n",
      "         31     0.8745    0.8951    0.8847       810\n",
      "         32     0.8978    0.8772    0.8874       741\n",
      "         33     0.8782    0.9206    0.8989       705\n",
      "         34     0.9467    0.8692    0.9063       818\n",
      "         35     0.8893    0.8745    0.8819       542\n",
      "         36     0.9258    0.8794    0.9020       539\n",
      "         37     0.8603    0.9259    0.8919       459\n",
      "         38     0.9019    0.8458    0.8729       402\n",
      "         39     0.8577    0.9035    0.8800       487\n",
      "         40     0.8374    0.9071    0.8709       420\n",
      "         41     0.9148    0.8496    0.8810       379\n",
      "         42     0.8424    0.9393    0.8882       313\n",
      "         43     0.8852    0.8415    0.8628       284\n",
      "         44     0.9130    0.8571    0.8842       245\n",
      "         45     0.8829    0.9009    0.8918       343\n",
      "         46     0.8036    0.8654    0.8333       208\n",
      "         47     0.8803    0.8834    0.8818       283\n",
      "         48     0.9158    0.7699    0.8365       226\n",
      "         49     0.9074    0.8376    0.8711       234\n",
      "         50     0.7014    0.9136    0.7936       162\n",
      "         51     0.8268    0.9080    0.8655       163\n",
      "         52     0.8539    0.8889    0.8711       171\n",
      "         53     0.9136    0.8457    0.8783       175\n",
      "         54     0.8881    0.8581    0.8729       148\n",
      "         55     0.9073    0.8354    0.8698       164\n",
      "         56     0.8456    0.9200    0.8812       125\n",
      "         57     0.9000    0.8250    0.8609       120\n",
      "         58     0.9027    0.8430    0.8718       121\n",
      "         59     0.7947    0.9231    0.8541       130\n",
      "         60     0.7705    0.7833    0.7769        60\n",
      "         61     0.9315    0.8774    0.9037       155\n",
      "         62     0.8611    0.8493    0.8552        73\n",
      "         63     0.8172    0.9048    0.8588        84\n",
      "         64     0.8571    0.7273    0.7869        66\n",
      "         65     0.9130    0.8750    0.8936        72\n",
      "         66     0.7500    0.9398    0.8342        83\n",
      "         67     0.8409    0.8315    0.8362        89\n",
      "         68     0.9545    0.7590    0.8456        83\n",
      "         69     0.8916    0.8810    0.8862        84\n",
      "         70     0.7727    0.8644    0.8160        59\n",
      "         71     0.8679    0.8846    0.8762        52\n",
      "         72     0.8876    0.8404    0.8634        94\n",
      "         73     0.9298    0.8833    0.9060        60\n",
      "         74     0.9273    0.8226    0.8718        62\n",
      "         75     0.9070    0.8298    0.8667        47\n",
      "         76     0.7885    0.8723    0.8283        47\n",
      "         77     0.8000    0.8780    0.8372        41\n",
      "         78     0.8542    1.0000    0.9213        41\n",
      "         79     0.8696    0.9091    0.8889        44\n",
      "         80     0.9375    0.8571    0.8955        70\n",
      "         81     0.8667    0.7222    0.7879        36\n",
      "         82     0.8514    0.9130    0.8811        69\n",
      "         83     0.9024    0.9250    0.9136        40\n",
      "         84     0.9444    1.0000    0.9714        34\n",
      "         85     0.9189    0.9444    0.9315        36\n",
      "         86     0.8810    0.9487    0.9136        39\n",
      "         87     0.9310    0.8710    0.9000        31\n",
      "         88     0.8857    1.0000    0.9394        31\n",
      "         89     0.9200    0.9200    0.9200        25\n",
      "         90     0.8667    0.8125    0.8387        32\n",
      "         91     0.8519    0.9200    0.8846        25\n",
      "         92     0.8913    0.9535    0.9213        43\n",
      "         93     0.8500    0.9444    0.8947        18\n",
      "         94     0.9231    0.8571    0.8889        28\n",
      "         95     0.7500    0.8571    0.8000         7\n",
      "         96     0.9375    0.7143    0.8108        21\n",
      "         97     0.9688    0.8158    0.8857        38\n",
      "         98     0.9091    0.8696    0.8889        23\n",
      "         99     0.8462    1.0000    0.9167        33\n",
      "        100     1.0000    0.7778    0.8750         9\n",
      "        101     0.9744    0.9744    0.9744        39\n",
      "        102     0.8636    0.8636    0.8636        22\n",
      "        103     0.9677    0.9677    0.9677        31\n",
      "        104     1.0000    1.0000    1.0000         7\n",
      "        105     1.0000    0.6471    0.7857        17\n",
      "        106     0.9600    1.0000    0.9796        24\n",
      "        107     0.9750    1.0000    0.9873        39\n",
      "        108     0.8947    1.0000    0.9444        17\n",
      "        109     1.0000    1.0000    1.0000        14\n",
      "        110     0.9524    1.0000    0.9756        20\n",
      "        111     0.9091    0.8333    0.8696        12\n",
      "        112     0.9259    0.9259    0.9259        27\n",
      "        113     0.8889    1.0000    0.9412        16\n",
      "        114     0.8000    0.9231    0.8571        13\n",
      "        115     0.8235    1.0000    0.9032        14\n",
      "        116     1.0000    0.8095    0.8947        21\n",
      "        117     1.0000    0.8571    0.9231         7\n",
      "        118     0.7692    0.8333    0.8000        12\n",
      "        119     1.0000    1.0000    1.0000         4\n",
      "        120     0.9500    1.0000    0.9744        19\n",
      "        121     1.0000    1.0000    1.0000         7\n",
      "        122     0.8235    0.9333    0.8750        15\n",
      "        123     1.0000    1.0000    1.0000         6\n",
      "        124     1.0000    0.3333    0.5000         3\n",
      "        125     1.0000    0.8889    0.9412        18\n",
      "        126     1.0000    0.9667    0.9831        30\n",
      "        127     0.8750    1.0000    0.9333         7\n",
      "        128     0.8333    0.8333    0.8333         6\n",
      "        129     0.9412    0.9412    0.9412        17\n",
      "        130     0.9333    1.0000    0.9655        14\n",
      "        131     1.0000    1.0000    1.0000         9\n",
      "        132     1.0000    1.0000    1.0000         3\n",
      "        133     1.0000    1.0000    1.0000        11\n",
      "        134     0.9412    1.0000    0.9697        16\n",
      "        135     1.0000    1.0000    1.0000         6\n",
      "        136     1.0000    0.8000    0.8889        10\n",
      "        137     1.0000    0.8000    0.8889        10\n",
      "        138     1.0000    1.0000    1.0000        22\n",
      "        139     0.0000    0.0000    0.0000         1\n",
      "        140     1.0000    1.0000    1.0000         2\n",
      "        141     1.0000    1.0000    1.0000         2\n",
      "        142     1.0000    1.0000    1.0000         4\n",
      "        144     1.0000    1.0000    1.0000         4\n",
      "        146     1.0000    1.0000    1.0000         3\n",
      "        147     0.8889    1.0000    0.9412         8\n",
      "        149     1.0000    1.0000    1.0000         4\n",
      "        150     0.7500    1.0000    0.8571         3\n",
      "        151     1.0000    1.0000    1.0000         2\n",
      "        152     1.0000    1.0000    1.0000         1\n",
      "        153     1.0000    1.0000    1.0000         1\n",
      "        154     1.0000    1.0000    1.0000         2\n",
      "        156     1.0000    0.8333    0.9091         6\n",
      "        157     1.0000    1.0000    1.0000         1\n",
      "        158     1.0000    1.0000    1.0000         5\n",
      "        159     1.0000    1.0000    1.0000         1\n",
      "        160     1.0000    1.0000    1.0000         2\n",
      "        162     1.0000    1.0000    1.0000         3\n",
      "        163     0.0000    0.0000    0.0000         2\n",
      "        164     1.0000    1.0000    1.0000         2\n",
      "        167     0.6667    1.0000    0.8000         4\n",
      "        174     1.0000    1.0000    1.0000         2\n",
      "        176     1.0000    0.7500    0.8571         4\n",
      "        177     1.0000    1.0000    1.0000         2\n",
      "        178     1.0000    1.0000    1.0000         1\n",
      "        179     1.0000    1.0000    1.0000         1\n",
      "        182     1.0000    1.0000    1.0000         4\n",
      "        183     1.0000    1.0000    1.0000         4\n",
      "\n",
      "avg / total     0.9921    0.9920    0.9920    951993\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(np.array(real_depends).ravel(), \n",
    "                            np.array(predict_depends).ravel(), digits = 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tolong', 'tangkap', 'gambar', 'kami']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string = 'tolong tangkap gambar kami'\n",
    "\n",
    "def char_str_idx(corpus, dic, UNK = 0):\n",
    "    maxlen = max([len(i) for i in corpus])\n",
    "    X = np.zeros((len(corpus), maxlen))\n",
    "    for i in range(len(corpus)):\n",
    "        for no, k in enumerate(corpus[i][:maxlen]):\n",
    "            val = dic[k] if k in dic else UNK\n",
    "            X[i, no] = val\n",
    "    return X\n",
    "\n",
    "def generate_char_seq(batch, UNK = 2):\n",
    "    maxlen_c = max([len(k) for k in batch])\n",
    "    x = [[len(i) for i in k] for k in batch]\n",
    "    maxlen = max([j for i in x for j in i])\n",
    "    temp = np.zeros((len(batch),maxlen_c,maxlen),dtype=np.int32)\n",
    "    for i in range(len(batch)):\n",
    "        for k in range(len(batch[i])):\n",
    "            for no, c in enumerate(batch[i][k][::-1]):\n",
    "                temp[i,k,-1-no] = char2idx.get(c, UNK)\n",
    "    return temp\n",
    "\n",
    "sequence = process_string(string)\n",
    "sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_seq = char_str_idx([sequence], word2idx, 2)\n",
    "X_char_seq = generate_char_seq([sequence])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq, deps = sess.run([model.tags_seq, model.tags_seq_depends],\n",
    "        feed_dict={model.word_ids:X_seq,\n",
    "                  model.char_ids:X_char_seq})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 0, 2, 3]], dtype=int32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deps - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['advmod', 'xcomp', 'obj', 'det']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[idx2tag[i] for i in seq[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[14, 23, 16,  3]], dtype=int32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "string = []\n",
    "for i in range(len(seq[0])):\n",
    "    string.append('%d\\t%s\\t_\\t_\\t_\\t_\\t%d\\t%s'%(i+1,sequence[i],deps[0,i],idx2tag[seq[0,i]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1\\ttolong\\t_\\t_\\t_\\t_\\t3\\tadvmod',\n",
       " '2\\ttangkap\\t_\\t_\\t_\\t_\\t1\\txcomp',\n",
       " '3\\tgambar\\t_\\t_\\t_\\t_\\t3\\tobj',\n",
       " '4\\tkami\\t_\\t_\\t_\\t_\\t4\\tdet']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Placeholder',\n",
       " 'Placeholder_1',\n",
       " 'Placeholder_2',\n",
       " 'Placeholder_3',\n",
       " 'Variable',\n",
       " 'Variable_1',\n",
       " 'bidirectional_rnn_char_0/fw/lstm_cell/kernel',\n",
       " 'bidirectional_rnn_char_0/fw/lstm_cell/bias',\n",
       " 'bidirectional_rnn_char_0/bw/lstm_cell/kernel',\n",
       " 'bidirectional_rnn_char_0/bw/lstm_cell/bias',\n",
       " 'bidirectional_rnn_char_1/fw/lstm_cell/kernel',\n",
       " 'bidirectional_rnn_char_1/fw/lstm_cell/bias',\n",
       " 'bidirectional_rnn_char_1/bw/lstm_cell/kernel',\n",
       " 'bidirectional_rnn_char_1/bw/lstm_cell/bias',\n",
       " 'bidirectional_rnn_word_0/fw/lstm_cell/kernel',\n",
       " 'bidirectional_rnn_word_0/fw/lstm_cell/bias',\n",
       " 'bidirectional_rnn_word_0/bw/lstm_cell/kernel',\n",
       " 'bidirectional_rnn_word_0/bw/lstm_cell/bias',\n",
       " 'bidirectional_rnn_word_1/fw/lstm_cell/kernel',\n",
       " 'bidirectional_rnn_word_1/fw/lstm_cell/bias',\n",
       " 'bidirectional_rnn_word_1/bw/lstm_cell/kernel',\n",
       " 'bidirectional_rnn_word_1/bw/lstm_cell/bias',\n",
       " 'dense/kernel',\n",
       " 'dense/bias',\n",
       " 'Variable_2',\n",
       " 'bidirectional_rnn_word_10/fw/lstm_cell/kernel',\n",
       " 'bidirectional_rnn_word_10/fw/lstm_cell/bias',\n",
       " 'bidirectional_rnn_word_10/bw/lstm_cell/kernel',\n",
       " 'bidirectional_rnn_word_10/bw/lstm_cell/bias',\n",
       " 'dense_1/kernel',\n",
       " 'dense_1/bias',\n",
       " 'transitions',\n",
       " 'depends/transitions',\n",
       " 'logits',\n",
       " 'logits_depends']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saver = tf.train.Saver(tf.trainable_variables())\n",
    "saver.save(sess, 'concat-dependency/model.ckpt')\n",
    "\n",
    "strings = ','.join(\n",
    "    [\n",
    "        n.name\n",
    "        for n in tf.get_default_graph().as_graph_def().node\n",
    "        if ('Variable' in n.op\n",
    "        or 'Placeholder' in n.name\n",
    "        or 'logits' in n.name\n",
    "        or 'logits_depends' in n.name\n",
    "        or 'alphas' in n.name)\n",
    "        and 'Adam' not in n.name\n",
    "        and 'beta' not in n.name\n",
    "        and 'OptimizeLoss' not in n.name\n",
    "        and 'Global_Step' not in n.name\n",
    "        and 'Epoch_Step' not in n.name\n",
    "        and 'learning_rate' not in n.name\n",
    "    ]\n",
    ")\n",
    "strings.split(',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('concat-dependency.json','w') as fopen:\n",
    "    fopen.write(json.dumps({'idx2tag':idx2tag,'idx2word':idx2word,\n",
    "           'word2idx':word2idx,'tag2idx':tag2idx,'char2idx':char2idx}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freeze_graph(model_dir, output_node_names):\n",
    "\n",
    "    if not tf.gfile.Exists(model_dir):\n",
    "        raise AssertionError(\n",
    "            \"Export directory doesn't exists. Please specify an export \"\n",
    "            'directory: %s' % model_dir\n",
    "        )\n",
    "\n",
    "    checkpoint = tf.train.get_checkpoint_state(model_dir)\n",
    "    input_checkpoint = checkpoint.model_checkpoint_path\n",
    "\n",
    "    absolute_model_dir = '/'.join(input_checkpoint.split('/')[:-1])\n",
    "    output_graph = absolute_model_dir + '/frozen_model.pb'\n",
    "    clear_devices = True\n",
    "    with tf.Session(graph = tf.Graph()) as sess:\n",
    "        saver = tf.train.import_meta_graph(\n",
    "            input_checkpoint + '.meta', clear_devices = clear_devices\n",
    "        )\n",
    "        saver.restore(sess, input_checkpoint)\n",
    "        output_graph_def = tf.graph_util.convert_variables_to_constants(\n",
    "            sess,\n",
    "            tf.get_default_graph().as_graph_def(),\n",
    "            output_node_names.split(','),\n",
    "        )\n",
    "        with tf.gfile.GFile(output_graph, 'wb') as f:\n",
    "            f.write(output_graph_def.SerializeToString())\n",
    "        print('%d ops in the final graph.' % len(output_graph_def.node))\n",
    "        \n",
    "def load_graph(frozen_graph_filename):\n",
    "    with tf.gfile.GFile(frozen_graph_filename, 'rb') as f:\n",
    "        graph_def = tf.GraphDef()\n",
    "        graph_def.ParseFromString(f.read())\n",
    "    with tf.Graph().as_default() as graph:\n",
    "        tf.import_graph_def(graph_def)\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from concat-dependency/model.ckpt\n",
      "INFO:tensorflow:Froze 29 variables.\n",
      "INFO:tensorflow:Converted 29 variables to const ops.\n",
      "2135 ops in the final graph.\n"
     ]
    }
   ],
   "source": [
    "freeze_graph('concat-dependency', strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = load_graph('concat-dependency/frozen_model.pb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py:1702: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
      "  warnings.warn('An interactive session is already active. This can '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[14 16 13  3]] [[3 1 3 4]]\n"
     ]
    }
   ],
   "source": [
    "word_ids = g.get_tensor_by_name('import/Placeholder:0')\n",
    "char_ids = g.get_tensor_by_name('import/Placeholder_1:0')\n",
    "tags_seq = g.get_tensor_by_name('import/logits:0')\n",
    "depends_seq = g.get_tensor_by_name('import/logits_depends:0')\n",
    "test_sess = tf.InteractiveSession(graph = g)\n",
    "seq, deps = test_sess.run([tags_seq, depends_seq],\n",
    "            feed_dict = {\n",
    "                word_ids: X_seq,\n",
    "                char_ids: X_char_seq,\n",
    "            })\n",
    "\n",
    "print(seq,deps)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
