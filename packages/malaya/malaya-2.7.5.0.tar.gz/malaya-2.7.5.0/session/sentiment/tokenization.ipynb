{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from unidecode import unidecode\n",
    "import malaya\n",
    "import json\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = malaya.preprocessing._SocialTokenizer().tokenize\n",
    "rules_normalizer = malaya.texts._tatabahasa.rules_normalizer\n",
    "\n",
    "def is_number_regex(s):\n",
    "    if re.match(\"^\\d+?\\.\\d+?$\", s) is None:\n",
    "        return s.isdigit()\n",
    "    return True\n",
    "\n",
    "def detect_money(word):\n",
    "    if word[:2] == 'rm' and is_number_regex(word[2:]):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def preprocessing(string):\n",
    "    tokenized = tokenizer(unidecode(string))\n",
    "    tokenized = [malaya.stem.naive(w) for w in tokenized]\n",
    "    tokenized = [w.lower() for w in tokenized if len(w) > 1]\n",
    "    tokenized = [rules_normalizer.get(w, w) for w in tokenized]\n",
    "    tokenized = ['<NUM>' if is_number_regex(w) else w for w in tokenized]\n",
    "    tokenized = ['<MONEY>' if detect_money(w) else w for w in tokenized]\n",
    "    return tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('sentiment-data-v2.csv')\n",
    "Y = LabelEncoder().fit_transform(df.label)\n",
    "with open('polarity-negative-translated.txt','r') as fopen:\n",
    "    texts = fopen.read().split('\\n')\n",
    "labels = [0] * len(texts)\n",
    "\n",
    "with open('polarity-positive-translated.txt','r') as fopen:\n",
    "    positive_texts = fopen.read().split('\\n')\n",
    "labels += [1] * len(positive_texts)\n",
    "texts += positive_texts\n",
    "texts += df.iloc[:,1].tolist()\n",
    "labels += Y.tolist()\n",
    "\n",
    "assert len(labels) == len(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('bm-amazon.json') as fopen:\n",
    "    amazon = json.load(fopen)\n",
    "    \n",
    "with open('bm-imdb.json') as fopen:\n",
    "    imdb = json.load(fopen)\n",
    "    \n",
    "with open('bm-yelp.json') as fopen:\n",
    "    yelp = json.load(fopen)\n",
    "    \n",
    "texts += amazon['negative']\n",
    "labels += [0] * len(amazon['negative'])\n",
    "texts += amazon['positive']\n",
    "labels += [1] * len(amazon['positive'])\n",
    "\n",
    "texts += imdb['negative']\n",
    "labels += [0] * len(imdb['negative'])\n",
    "texts += imdb['positive']\n",
    "labels += [1] * len(imdb['positive'])\n",
    "\n",
    "texts += yelp['negative']\n",
    "labels += [0] * len(yelp['negative'])\n",
    "texts += yelp['positive']\n",
    "labels += [1] * len(yelp['positive'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "for i in [i for i in os.listdir('negative') if 'Store' not in i]:\n",
    "    with open('negative/'+i) as fopen:\n",
    "        a = json.load(fopen)\n",
    "        texts += a\n",
    "        labels += [0] * len(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [i for i in os.listdir('positive') if 'Store' not in i]:\n",
    "    with open('positive/'+i) as fopen:\n",
    "        a = json.load(fopen)\n",
    "        texts += a\n",
    "        labels += [1] * len(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(675023, 675023)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(texts),len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 675023/675023 [01:42<00:00, 6568.58it/s]\n"
     ]
    }
   ],
   "source": [
    "pbar = tqdm(range(len(texts)))\n",
    "for i in pbar:\n",
    "    texts[i] = preprocessing(texts[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['ada',\n",
       "  'anda',\n",
       "  'yiar',\n",
       "  'tentang',\n",
       "  'gatur',\n",
       "  'tidur',\n",
       "  'yang',\n",
       "  'baru',\n",
       "  'tidak',\n",
       "  'lama',\n",
       "  'lagi',\n",
       "  'yusun',\n",
       "  'mula',\n",
       "  'ada',\n",
       "  'yang',\n",
       "  'baik',\n",
       "  'ntiasa',\n",
       "  'asa',\n",
       "  'begitu',\n",
       "  'jaya',\n",
       "  'lepas',\n",
       "  'itu'],\n",
       " ['lamat', 'pagi', 'dunia'],\n",
       " ['sini', 'rumah', 'pupu', 'saya'],\n",
       " ['mungkin', 'ini', 'lebih', 'anda'],\n",
       " ['ima', 'kasih', 'saya', 'erlukan'],\n",
       " ['neraka',\n",
       "  'windows',\n",
       "  'luar',\n",
       "  'dari',\n",
       "  'julat',\n",
       "  'harga',\n",
       "  'saya',\n",
       "  'cuali',\n",
       "  'jika',\n",
       "  'tidak'],\n",
       " ['neah',\n",
       "  'saya',\n",
       "  'harap',\n",
       "  'ha',\n",
       "  'enang',\n",
       "  'mbali',\n",
       "  'catat',\n",
       "  'dalam',\n",
       "  'tweet',\n",
       "  'akhir',\n",
       "  'saya'],\n",
       " ['aww',\n",
       "  'saya',\n",
       "  'benar',\n",
       "  'benar',\n",
       "  'minta',\n",
       "  'maaf',\n",
       "  'tentang',\n",
       "  'itu',\n",
       "  'tidak',\n",
       "  'ada',\n",
       "  'apa',\n",
       "  'apa',\n",
       "  'yang',\n",
       "  'sa',\n",
       "  'deng',\n",
       "  'jadi',\n",
       "  'asi',\n",
       "  'tidak',\n",
       "  'anda',\n",
       "  'lihat',\n",
       "  'quot',\n",
       "  'quot',\n",
       "  'malam',\n",
       "  'kido'],\n",
       " ['saya',\n",
       "  'tidak',\n",
       "  'sabar',\n",
       "  'untuk',\n",
       "  'lihat',\n",
       "  'apa',\n",
       "  'kara',\n",
       "  'yang',\n",
       "  'akjub',\n",
       "  'yang',\n",
       "  'anda',\n",
       "  'datang',\n",
       "  'tidak',\n",
       "  'nah',\n",
       "  'lupa',\n",
       "  'anda',\n",
       "  'luar',\n",
       "  'biasa'],\n",
       " ['deng',\n",
       "  'cara',\n",
       "  'saya',\n",
       "  'embali',\n",
       "  'dewi',\n",
       "  'matahari',\n",
       "  'malam',\n",
       "  'tadi',\n",
       "  'anda',\n",
       "  'sasha',\n",
       "  'sangat',\n",
       "  'agum',\n",
       "  'saya',\n",
       "  'boleh',\n",
       "  'onton',\n",
       "  'filem',\n",
       "  'itu',\n",
       "  'ulang',\n",
       "  'kali']]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('tokenization.json','w') as fopen:\n",
    "    json.dump({'texts':texts, 'labels':labels}, fopen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
