

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>The model_selection package &mdash; Surprise 1 documentation</title>
  

  
  
  
  

  

  
  
    

  

  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="_static/graphviz.css" type="text/css" />
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="similarities module" href="similarities.html" />
    <link rel="prev" title="Co-clustering" href="co_clustering.html" /> 

  
  <script src="_static/js/modernizr.min.js"></script>

</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          
            <a href="index.html" class="icon icon-home"> Surprise
          

          
          </a>

          
            
            
              <div class="version">
                0
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">User Guide</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="getting_started.html">Getting Started</a></li>
<li class="toctree-l1"><a class="reference internal" href="prediction_algorithms.html">Using prediction algorithms</a></li>
<li class="toctree-l1"><a class="reference internal" href="building_custom_algo.html">How to build your own prediction algorithm</a></li>
<li class="toctree-l1"><a class="reference internal" href="notation_standards.html">Notation standards, References</a></li>
<li class="toctree-l1"><a class="reference internal" href="FAQ.html">FAQ</a></li>
</ul>
<p class="caption"><span class="caption-text">API Reference</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="prediction_algorithms_package.html">prediction_algorithms package</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">The model_selection package</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#module-surprise.model_selection.split">Cross validation iterators</a></li>
<li class="toctree-l2"><a class="reference internal" href="#cross-validation">Cross validation</a></li>
<li class="toctree-l2"><a class="reference internal" href="#parameter-search">Parameter search</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="similarities.html">similarities module</a></li>
<li class="toctree-l1"><a class="reference internal" href="accuracy.html">accuracy module</a></li>
<li class="toctree-l1"><a class="reference internal" href="dataset.html">dataset module</a></li>
<li class="toctree-l1"><a class="reference internal" href="trainset.html">Trainset class</a></li>
<li class="toctree-l1"><a class="reference internal" href="reader.html">Reader class</a></li>
<li class="toctree-l1"><a class="reference internal" href="dump.html">dump module</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">Surprise</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="index.html">Docs</a> &raquo;</li>
        
      <li>The model_selection package</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="_sources/model_selection.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="the-model-selection-package">
<span id="model-selection"></span><h1>The model_selection package<a class="headerlink" href="#the-model-selection-package" title="Permalink to this headline">¶</a></h1>
<p>Surprise provides various tools to run cross-validation procedures and search
the best parameters for a prediction algorithm. The tools presented here are
all heavily inspired from the excellent <a class="reference external" href="http://scikit-learn.org/stable/modules/classes.html#module-sklearn.model_selection">scikit learn</a>
library.</p>
<div class="section" id="module-surprise.model_selection.split">
<span id="cross-validation-iterators"></span><span id="cross-validation-iterators-api"></span><h2>Cross validation iterators<a class="headerlink" href="#module-surprise.model_selection.split" title="Permalink to this headline">¶</a></h2>
<p>The <a class="reference internal" href="#module-surprise.model_selection.split" title="surprise.model_selection.split"><code class="xref py py-mod docutils literal notranslate"><span class="pre">model_selection.split</span></code></a> module
contains various cross-validation iterators. Design and tools are inspired from
the mighty scikit learn.</p>
<p>The available iterators are:</p>
<table border="1" class="longtable docutils">
<colgroup>
<col width="10%" />
<col width="90%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><a class="reference internal" href="#surprise.model_selection.split.KFold" title="surprise.model_selection.split.KFold"><code class="xref py py-obj docutils literal notranslate"><span class="pre">KFold</span></code></a></td>
<td>A basic cross-validation iterator.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#surprise.model_selection.split.RepeatedKFold" title="surprise.model_selection.split.RepeatedKFold"><code class="xref py py-obj docutils literal notranslate"><span class="pre">RepeatedKFold</span></code></a></td>
<td>Repeated <a class="reference internal" href="#surprise.model_selection.split.KFold" title="surprise.model_selection.split.KFold"><code class="xref py py-class docutils literal notranslate"><span class="pre">KFold</span></code></a> cross validator.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#surprise.model_selection.split.ShuffleSplit" title="surprise.model_selection.split.ShuffleSplit"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ShuffleSplit</span></code></a></td>
<td>A basic cross-validation iterator with random trainsets and testsets.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#surprise.model_selection.split.LeaveOneOut" title="surprise.model_selection.split.LeaveOneOut"><code class="xref py py-obj docutils literal notranslate"><span class="pre">LeaveOneOut</span></code></a></td>
<td>Cross-validation iterator where each user has exactly one rating in the testset.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#surprise.model_selection.split.PredefinedKFold" title="surprise.model_selection.split.PredefinedKFold"><code class="xref py py-obj docutils literal notranslate"><span class="pre">PredefinedKFold</span></code></a></td>
<td>A cross-validation iterator to when a dataset has been loaded with the <a class="reference internal" href="dataset.html#surprise.dataset.Dataset.load_from_folds" title="surprise.dataset.Dataset.load_from_folds"><code class="xref py py-meth docutils literal notranslate"><span class="pre">load_from_folds</span></code></a> method.</td>
</tr>
</tbody>
</table>
<p>This module also contains a function for splitting datasets into trainset and
testset:</p>
<table border="1" class="longtable docutils">
<colgroup>
<col width="10%" />
<col width="90%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><a class="reference internal" href="#surprise.model_selection.split.train_test_split" title="surprise.model_selection.split.train_test_split"><code class="xref py py-obj docutils literal notranslate"><span class="pre">train_test_split</span></code></a></td>
<td>Split a dataset into trainset and testset.</td>
</tr>
</tbody>
</table>
<dl class="class">
<dt id="surprise.model_selection.split.KFold">
<em class="property">class </em><code class="descclassname">surprise.model_selection.split.</code><code class="descname">KFold</code><span class="sig-paren">(</span><em>n_splits=5</em>, <em>random_state=None</em>, <em>shuffle=True</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/surprise/model_selection/split.html#KFold"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#surprise.model_selection.split.KFold" title="Permalink to this definition">¶</a></dt>
<dd><p>A basic cross-validation iterator.</p>
<p>Each fold is used once as a testset while the k - 1 remaining folds are
used for training.</p>
<p>See an example in the <a class="reference internal" href="getting_started.html#use-cross-validation-iterators"><span class="std std-ref">User Guide</span></a>.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>n_splits</strong> (<em>int</em>) – The number of folds.</li>
<li><strong>random_state</strong> (int, RandomState instance from numpy, or <code class="docutils literal notranslate"><span class="pre">None</span></code>) – Determines the RNG that will be used for determining the folds. If
int, <code class="docutils literal notranslate"><span class="pre">random_state</span></code> will be used as a seed for a new RNG. This is
useful to get the same splits over multiple calls to <code class="docutils literal notranslate"><span class="pre">split()</span></code>.
If RandomState instance, this same instance is used as RNG. If
<code class="docutils literal notranslate"><span class="pre">None</span></code>, the current RNG from numpy is used. <code class="docutils literal notranslate"><span class="pre">random_state</span></code> is
only used if <code class="docutils literal notranslate"><span class="pre">shuffle</span></code> is <code class="docutils literal notranslate"><span class="pre">True</span></code>.  Default is <code class="docutils literal notranslate"><span class="pre">None</span></code>.</li>
<li><strong>shuffle</strong> (<em>bool</em>) – Whether to shuffle the ratings in the <code class="docutils literal notranslate"><span class="pre">data</span></code> parameter
of the <code class="docutils literal notranslate"><span class="pre">split()</span></code> method. Shuffling is not done in-place. Default
is <code class="docutils literal notranslate"><span class="pre">True</span></code>.</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="surprise.model_selection.split.KFold.split">
<code class="descname">split</code><span class="sig-paren">(</span><em>data</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/surprise/model_selection/split.html#KFold.split"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#surprise.model_selection.split.KFold.split" title="Permalink to this definition">¶</a></dt>
<dd><p>Generator function to iterate over trainsets and testsets.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>data</strong> (<a class="reference internal" href="dataset.html#surprise.dataset.Dataset" title="surprise.dataset.Dataset"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Dataset</span></code></a>) – The data containing
ratings that will be devided into trainsets and testsets.</td>
</tr>
<tr class="field-even field"><th class="field-name">Yields:</th><td class="field-body">tuple of (trainset, testset)</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="surprise.model_selection.split.LeaveOneOut">
<em class="property">class </em><code class="descclassname">surprise.model_selection.split.</code><code class="descname">LeaveOneOut</code><span class="sig-paren">(</span><em>n_splits=5</em>, <em>random_state=None</em>, <em>min_n_ratings=0</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/surprise/model_selection/split.html#LeaveOneOut"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#surprise.model_selection.split.LeaveOneOut" title="Permalink to this definition">¶</a></dt>
<dd><p>Cross-validation iterator where each user has exactly one rating in the
testset.</p>
<p>Contrary to other cross-validation strategies, <code class="docutils literal notranslate"><span class="pre">LeaveOneOut</span></code> does not
guarantee that all folds will be different, although this is still very
likely for sizeable datasets.</p>
<p>See an example in the <a class="reference internal" href="getting_started.html#use-cross-validation-iterators"><span class="std std-ref">User Guide</span></a>.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>n_splits</strong> (<em>int</em>) – The number of folds.</li>
<li><strong>random_state</strong> (int, RandomState instance from numpy, or <code class="docutils literal notranslate"><span class="pre">None</span></code>) – Determines the RNG that will be used for determining the folds. If
int, <code class="docutils literal notranslate"><span class="pre">random_state</span></code> will be used as a seed for a new RNG. This is
useful to get the same splits over multiple calls to <code class="docutils literal notranslate"><span class="pre">split()</span></code>.
If RandomState instance, this same instance is used as RNG. If
<code class="docutils literal notranslate"><span class="pre">None</span></code>, the current RNG from numpy is used. <code class="docutils literal notranslate"><span class="pre">random_state</span></code> is
only used if <code class="docutils literal notranslate"><span class="pre">shuffle</span></code> is <code class="docutils literal notranslate"><span class="pre">True</span></code>.  Default is <code class="docutils literal notranslate"><span class="pre">None</span></code>.</li>
<li><strong>min_n_ratings</strong> (<em>int</em>) – Minimum number of ratings for each user in the
trainset. E.g. if <code class="docutils literal notranslate"><span class="pre">min_n_ratings</span></code> is <code class="docutils literal notranslate"><span class="pre">2</span></code>, we are sure each user
has at least <code class="docutils literal notranslate"><span class="pre">2</span></code> ratings in the trainset (and <code class="docutils literal notranslate"><span class="pre">1</span></code> in the
testset). Other users are discarded. Default is <code class="docutils literal notranslate"><span class="pre">0</span></code>, so some
users (having only one rating) may be in the testset and not in the
trainset.</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="surprise.model_selection.split.LeaveOneOut.split">
<code class="descname">split</code><span class="sig-paren">(</span><em>data</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/surprise/model_selection/split.html#LeaveOneOut.split"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#surprise.model_selection.split.LeaveOneOut.split" title="Permalink to this definition">¶</a></dt>
<dd><p>Generator function to iterate over trainsets and testsets.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>data</strong> (<a class="reference internal" href="dataset.html#surprise.dataset.Dataset" title="surprise.dataset.Dataset"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Dataset</span></code></a>) – The data containing
ratings that will be devided into trainsets and testsets.</td>
</tr>
<tr class="field-even field"><th class="field-name">Yields:</th><td class="field-body">tuple of (trainset, testset)</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="surprise.model_selection.split.PredefinedKFold">
<em class="property">class </em><code class="descclassname">surprise.model_selection.split.</code><code class="descname">PredefinedKFold</code><a class="reference internal" href="_modules/surprise/model_selection/split.html#PredefinedKFold"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#surprise.model_selection.split.PredefinedKFold" title="Permalink to this definition">¶</a></dt>
<dd><p>A cross-validation iterator to when a dataset has been loaded with the
<a class="reference internal" href="dataset.html#surprise.dataset.Dataset.load_from_folds" title="surprise.dataset.Dataset.load_from_folds"><code class="xref py py-meth docutils literal notranslate"><span class="pre">load_from_folds</span></code></a>
method.</p>
<p>See an example in the <a class="reference internal" href="getting_started.html#load-from-folds-example"><span class="std std-ref">User Guide</span></a>.</p>
<dl class="method">
<dt id="surprise.model_selection.split.PredefinedKFold.split">
<code class="descname">split</code><span class="sig-paren">(</span><em>data</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/surprise/model_selection/split.html#PredefinedKFold.split"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#surprise.model_selection.split.PredefinedKFold.split" title="Permalink to this definition">¶</a></dt>
<dd><p>Generator function to iterate over trainsets and testsets.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>data</strong> (<a class="reference internal" href="dataset.html#surprise.dataset.Dataset" title="surprise.dataset.Dataset"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Dataset</span></code></a>) – The data containing
ratings that will be devided into trainsets and testsets.</td>
</tr>
<tr class="field-even field"><th class="field-name">Yields:</th><td class="field-body">tuple of (trainset, testset)</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="surprise.model_selection.split.RepeatedKFold">
<em class="property">class </em><code class="descclassname">surprise.model_selection.split.</code><code class="descname">RepeatedKFold</code><span class="sig-paren">(</span><em>n_splits=5</em>, <em>n_repeats=10</em>, <em>random_state=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/surprise/model_selection/split.html#RepeatedKFold"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#surprise.model_selection.split.RepeatedKFold" title="Permalink to this definition">¶</a></dt>
<dd><p>Repeated <a class="reference internal" href="#surprise.model_selection.split.KFold" title="surprise.model_selection.split.KFold"><code class="xref py py-class docutils literal notranslate"><span class="pre">KFold</span></code></a> cross validator.</p>
<p>Repeats <a class="reference internal" href="#surprise.model_selection.split.KFold" title="surprise.model_selection.split.KFold"><code class="xref py py-class docutils literal notranslate"><span class="pre">KFold</span></code></a> n times with different randomization in each
repetition.</p>
<p>See an example in the <a class="reference internal" href="getting_started.html#use-cross-validation-iterators"><span class="std std-ref">User Guide</span></a>.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>n_splits</strong> (<em>int</em>) – The number of folds.</li>
<li><strong>n_repeats</strong> (<em>int</em>) – The number of repetitions.</li>
<li><strong>random_state</strong> (int, RandomState instance from numpy, or <code class="docutils literal notranslate"><span class="pre">None</span></code>) – Determines the RNG that will be used for determining the folds. If
int, <code class="docutils literal notranslate"><span class="pre">random_state</span></code> will be used as a seed for a new RNG. This is
useful to get the same splits over multiple calls to <code class="docutils literal notranslate"><span class="pre">split()</span></code>.
If RandomState instance, this same instance is used as RNG. If
<code class="docutils literal notranslate"><span class="pre">None</span></code>, the current RNG from numpy is used. <code class="docutils literal notranslate"><span class="pre">random_state</span></code> is
only used if <code class="docutils literal notranslate"><span class="pre">shuffle</span></code> is <code class="docutils literal notranslate"><span class="pre">True</span></code>.  Default is <code class="docutils literal notranslate"><span class="pre">None</span></code>.</li>
<li><strong>shuffle</strong> (<em>bool</em>) – Whether to shuffle the ratings in the <code class="docutils literal notranslate"><span class="pre">data</span></code> parameter
of the <code class="docutils literal notranslate"><span class="pre">split()</span></code> method. Shuffling is not done in-place. Default
is <code class="docutils literal notranslate"><span class="pre">True</span></code>.</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="surprise.model_selection.split.RepeatedKFold.split">
<code class="descname">split</code><span class="sig-paren">(</span><em>data</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/surprise/model_selection/split.html#RepeatedKFold.split"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#surprise.model_selection.split.RepeatedKFold.split" title="Permalink to this definition">¶</a></dt>
<dd><p>Generator function to iterate over trainsets and testsets.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>data</strong> (<a class="reference internal" href="dataset.html#surprise.dataset.Dataset" title="surprise.dataset.Dataset"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Dataset</span></code></a>) – The data containing
ratings that will be devided into trainsets and testsets.</td>
</tr>
<tr class="field-even field"><th class="field-name">Yields:</th><td class="field-body">tuple of (trainset, testset)</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="surprise.model_selection.split.ShuffleSplit">
<em class="property">class </em><code class="descclassname">surprise.model_selection.split.</code><code class="descname">ShuffleSplit</code><span class="sig-paren">(</span><em>n_splits=5</em>, <em>test_size=0.2</em>, <em>train_size=None</em>, <em>random_state=None</em>, <em>shuffle=True</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/surprise/model_selection/split.html#ShuffleSplit"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#surprise.model_selection.split.ShuffleSplit" title="Permalink to this definition">¶</a></dt>
<dd><p>A basic cross-validation iterator with random trainsets and testsets.</p>
<p>Contrary to other cross-validation strategies, random splits do not
guarantee that all folds will be different, although this is still very
likely for sizeable datasets.</p>
<p>See an example in the <a class="reference internal" href="getting_started.html#use-cross-validation-iterators"><span class="std std-ref">User Guide</span></a>.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>n_splits</strong> (<em>int</em>) – The number of folds.</li>
<li><strong>test_size</strong> (float or int <code class="docutils literal notranslate"><span class="pre">None</span></code>) – If float, it represents the
proportion of ratings to include in the testset. If int,
represents the absolute number of ratings in the testset. If
<code class="docutils literal notranslate"><span class="pre">None</span></code>, the value is set to the complement of the trainset size.
Default is <code class="docutils literal notranslate"><span class="pre">.2</span></code>.</li>
<li><strong>train_size</strong> (float or int or <code class="docutils literal notranslate"><span class="pre">None</span></code>) – If float, it represents the
proportion of ratings to include in the trainset. If int,
represents the absolute number of ratings in the trainset. If
<code class="docutils literal notranslate"><span class="pre">None</span></code>, the value is set to the complement of the testset size.
Default is <code class="docutils literal notranslate"><span class="pre">None</span></code>.</li>
<li><strong>random_state</strong> (int, RandomState instance from numpy, or <code class="docutils literal notranslate"><span class="pre">None</span></code>) – Determines the RNG that will be used for determining the folds. If
int, <code class="docutils literal notranslate"><span class="pre">random_state</span></code> will be used as a seed for a new RNG. This is
useful to get the same splits over multiple calls to <code class="docutils literal notranslate"><span class="pre">split()</span></code>.
If RandomState instance, this same instance is used as RNG. If
<code class="docutils literal notranslate"><span class="pre">None</span></code>, the current RNG from numpy is used. <code class="docutils literal notranslate"><span class="pre">random_state</span></code> is
only used if <code class="docutils literal notranslate"><span class="pre">shuffle</span></code> is <code class="docutils literal notranslate"><span class="pre">True</span></code>.  Default is <code class="docutils literal notranslate"><span class="pre">None</span></code>.</li>
<li><strong>shuffle</strong> (<em>bool</em>) – Whether to shuffle the ratings in the <code class="docutils literal notranslate"><span class="pre">data</span></code> parameter
of the <code class="docutils literal notranslate"><span class="pre">split()</span></code> method. Shuffling is not done in-place. Setting
this to <cite>False</cite> defeats the purpose of this iterator, but it’s
useful for the implementation of <a class="reference internal" href="#surprise.model_selection.split.train_test_split" title="surprise.model_selection.split.train_test_split"><code class="xref py py-func docutils literal notranslate"><span class="pre">train_test_split()</span></code></a>. Default
is <code class="docutils literal notranslate"><span class="pre">True</span></code>.</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="surprise.model_selection.split.ShuffleSplit.split">
<code class="descname">split</code><span class="sig-paren">(</span><em>data</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/surprise/model_selection/split.html#ShuffleSplit.split"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#surprise.model_selection.split.ShuffleSplit.split" title="Permalink to this definition">¶</a></dt>
<dd><p>Generator function to iterate over trainsets and testsets.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>data</strong> (<a class="reference internal" href="dataset.html#surprise.dataset.Dataset" title="surprise.dataset.Dataset"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Dataset</span></code></a>) – The data containing
ratings that will be devided into trainsets and testsets.</td>
</tr>
<tr class="field-even field"><th class="field-name">Yields:</th><td class="field-body">tuple of (trainset, testset)</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

<dl class="function">
<dt id="surprise.model_selection.split.train_test_split">
<code class="descclassname">surprise.model_selection.split.</code><code class="descname">train_test_split</code><span class="sig-paren">(</span><em>data</em>, <em>test_size=0.2</em>, <em>train_size=None</em>, <em>random_state=None</em>, <em>shuffle=True</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/surprise/model_selection/split.html#train_test_split"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#surprise.model_selection.split.train_test_split" title="Permalink to this definition">¶</a></dt>
<dd><p>Split a dataset into trainset and testset.</p>
<p>See an example in the <a class="reference internal" href="getting_started.html#train-test-split-example"><span class="std std-ref">User Guide</span></a>.</p>
<p>Note: this function cannot be used as a cross-validation iterator.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>data</strong> (<a class="reference internal" href="dataset.html#surprise.dataset.Dataset" title="surprise.dataset.Dataset"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Dataset</span></code></a>) – The dataset to split
into trainset and testset.</li>
<li><strong>test_size</strong> (float or int <code class="docutils literal notranslate"><span class="pre">None</span></code>) – If float, it represents the
proportion of ratings to include in the testset. If int,
represents the absolute number of ratings in the testset. If
<code class="docutils literal notranslate"><span class="pre">None</span></code>, the value is set to the complement of the trainset size.
Default is <code class="docutils literal notranslate"><span class="pre">.2</span></code>.</li>
<li><strong>train_size</strong> (float or int or <code class="docutils literal notranslate"><span class="pre">None</span></code>) – If float, it represents the
proportion of ratings to include in the trainset. If int,
represents the absolute number of ratings in the trainset. If
<code class="docutils literal notranslate"><span class="pre">None</span></code>, the value is set to the complement of the testset size.
Default is <code class="docutils literal notranslate"><span class="pre">None</span></code>.</li>
<li><strong>random_state</strong> (int, RandomState instance from numpy, or <code class="docutils literal notranslate"><span class="pre">None</span></code>) – Determines the RNG that will be used for determining the folds. If
int, <code class="docutils literal notranslate"><span class="pre">random_state</span></code> will be used as a seed for a new RNG. This is
useful to get the same splits over multiple calls to <code class="docutils literal notranslate"><span class="pre">split()</span></code>.
If RandomState instance, this same instance is used as RNG. If
<code class="docutils literal notranslate"><span class="pre">None</span></code>, the current RNG from numpy is used. <code class="docutils literal notranslate"><span class="pre">random_state</span></code> is
only used if <code class="docutils literal notranslate"><span class="pre">shuffle</span></code> is <code class="docutils literal notranslate"><span class="pre">True</span></code>.  Default is <code class="docutils literal notranslate"><span class="pre">None</span></code>.</li>
<li><strong>shuffle</strong> (<em>bool</em>) – Whether to shuffle the ratings in the <code class="docutils literal notranslate"><span class="pre">data</span></code>
parameter. Shuffling is not done in-place. Default is <code class="docutils literal notranslate"><span class="pre">True</span></code>.</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</div>
<div class="section" id="cross-validation">
<h2>Cross validation<a class="headerlink" href="#cross-validation" title="Permalink to this headline">¶</a></h2>
<dl class="function">
<dt id="surprise.model_selection.validation.cross_validate">
<code class="descclassname">surprise.model_selection.validation.</code><code class="descname">cross_validate</code><span class="sig-paren">(</span><em>algo, data, measures=['rmse', 'mae'], cv=None, return_train_measures=False, n_jobs=1, pre_dispatch='2*n_jobs', verbose=False</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/surprise/model_selection/validation.html#cross_validate"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#surprise.model_selection.validation.cross_validate" title="Permalink to this definition">¶</a></dt>
<dd><p>Run a cross validation procedure for a given algorithm, reporting accuracy
measures and computation times.</p>
<p>See an example in the <a class="reference internal" href="getting_started.html#cross-validate-example"><span class="std std-ref">User Guide</span></a>.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>algo</strong> (<a class="reference internal" href="algobase.html#surprise.prediction_algorithms.algo_base.AlgoBase" title="surprise.prediction_algorithms.algo_base.AlgoBase"><code class="xref py py-obj docutils literal notranslate"><span class="pre">AlgoBase</span></code></a>) – The algorithm to evaluate.</li>
<li><strong>data</strong> (<a class="reference internal" href="dataset.html#surprise.dataset.Dataset" title="surprise.dataset.Dataset"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Dataset</span></code></a>) – The dataset on which
to evaluate the algorithm.</li>
<li><strong>measures</strong> (<em>list of string</em>) – The performance measures to compute. Allowed
names are function names as defined in the <a class="reference internal" href="accuracy.html#module-surprise.accuracy" title="surprise.accuracy"><code class="xref py py-mod docutils literal notranslate"><span class="pre">accuracy</span></code></a> module. Default is <code class="docutils literal notranslate"><span class="pre">['rmse',</span> <span class="pre">'mae']</span></code>.</li>
<li><strong>cv</strong> (cross-validation iterator, int or <code class="docutils literal notranslate"><span class="pre">None</span></code>) – Determines how the
<code class="docutils literal notranslate"><span class="pre">data</span></code> parameter will be split (i.e. how trainsets and testsets
will be defined). If an int is passed, <a class="reference internal" href="#surprise.model_selection.split.KFold" title="surprise.model_selection.split.KFold"><code class="xref py py-class docutils literal notranslate"><span class="pre">KFold</span></code></a> is used with the
appropriate <code class="docutils literal notranslate"><span class="pre">n_splits</span></code> parameter. If <code class="docutils literal notranslate"><span class="pre">None</span></code>, <a class="reference internal" href="#surprise.model_selection.split.KFold" title="surprise.model_selection.split.KFold"><code class="xref py py-class docutils literal notranslate"><span class="pre">KFold</span></code></a> is used with
<code class="docutils literal notranslate"><span class="pre">n_splits=5</span></code>.</li>
<li><strong>return_train_measures</strong> (<em>bool</em>) – Whether to compute performance measures on
the trainsets. Default is <code class="docutils literal notranslate"><span class="pre">False</span></code>.</li>
<li><strong>n_jobs</strong> (<em>int</em>) – <p>The maximum number of folds evaluated in parallel.</p>
<ul>
<li>If <code class="docutils literal notranslate"><span class="pre">-1</span></code>, all CPUs are used.</li>
<li>If <code class="docutils literal notranslate"><span class="pre">1</span></code> is given, no parallel computing code is used at all,                which is useful for debugging.</li>
<li>For <code class="docutils literal notranslate"><span class="pre">n_jobs</span></code> below <code class="docutils literal notranslate"><span class="pre">-1</span></code>, <code class="docutils literal notranslate"><span class="pre">(n_cpus</span> <span class="pre">+</span> <span class="pre">n_jobs</span> <span class="pre">+</span> <span class="pre">1)</span></code> are                used.  For example, with <code class="docutils literal notranslate"><span class="pre">n_jobs</span> <span class="pre">=</span> <span class="pre">-2</span></code> all CPUs but one are                used.</li>
</ul>
<p>Default is <code class="docutils literal notranslate"><span class="pre">1</span></code>.</p>
</li>
<li><strong>pre_dispatch</strong> (<em>int</em><em> or </em><em>string</em>) – <p>Controls the number of jobs that get
dispatched during parallel execution. Reducing this number can be
useful to avoid an explosion of memory consumption when more jobs
get dispatched than CPUs can process. This parameter can be:</p>
<ul>
<li><code class="docutils literal notranslate"><span class="pre">None</span></code>, in which case all the jobs are immediately created                and spawned. Use this for lightweight and fast-running                jobs, to avoid delays due to on-demand spawning of the                jobs.</li>
<li>An int, giving the exact number of total jobs that are                spawned.</li>
<li>A string, giving an expression as a function of <code class="docutils literal notranslate"><span class="pre">n_jobs</span></code>,                as in <code class="docutils literal notranslate"><span class="pre">'2*n_jobs'</span></code>.</li>
</ul>
<p>Default is <code class="docutils literal notranslate"><span class="pre">'2*n_jobs'</span></code>.</p>
</li>
<li><strong>verbose</strong> (<em>int</em>) – If <code class="docutils literal notranslate"><span class="pre">True</span></code> accuracy measures for each split are printed,
as well as train and test times. Averages and standard deviations
over all splits are also reported. Default is <code class="docutils literal notranslate"><span class="pre">False</span></code>: nothing is
printed.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><p>A dict with the following keys:</p>
<blockquote>
<div><ul class="simple">
<li><code class="docutils literal notranslate"><span class="pre">'test_*'</span></code> where <code class="docutils literal notranslate"><span class="pre">*</span></code> corresponds to a lower-case accuracy
measure, e.g. <code class="docutils literal notranslate"><span class="pre">'test_rmse'</span></code>: numpy array with accuracy values
for each testset.</li>
<li><code class="docutils literal notranslate"><span class="pre">'train_*'</span></code> where <code class="docutils literal notranslate"><span class="pre">*</span></code> corresponds to a lower-case accuracy
measure, e.g. <code class="docutils literal notranslate"><span class="pre">'train_rmse'</span></code>: numpy array with accuracy values
for each trainset. Only available if <code class="docutils literal notranslate"><span class="pre">return_train_measures</span></code> is
<code class="docutils literal notranslate"><span class="pre">True</span></code>.</li>
<li><code class="docutils literal notranslate"><span class="pre">'fit_time'</span></code>: numpy array with the training time in seconds for
each split.</li>
<li><code class="docutils literal notranslate"><span class="pre">'test_time'</span></code>: numpy array with the testing time in seconds for
each split.</li>
</ul>
</div></blockquote>
</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">dict</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</div>
<div class="section" id="parameter-search">
<h2>Parameter search<a class="headerlink" href="#parameter-search" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="surprise.model_selection.search.GridSearchCV">
<em class="property">class </em><code class="descclassname">surprise.model_selection.search.</code><code class="descname">GridSearchCV</code><span class="sig-paren">(</span><em>algo_class, param_grid, measures=['rmse', 'mae'], cv=None, refit=False, return_train_measures=False, n_jobs=1, pre_dispatch='2*n_jobs', joblib_verbose=0</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/surprise/model_selection/search.html#GridSearchCV"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#surprise.model_selection.search.GridSearchCV" title="Permalink to this definition">¶</a></dt>
<dd><p>The <a class="reference internal" href="#surprise.model_selection.search.GridSearchCV" title="surprise.model_selection.search.GridSearchCV"><code class="xref py py-class docutils literal notranslate"><span class="pre">GridSearchCV</span></code></a> class computes accuracy metrics for an
algorithm on various combinations of parameters, over a cross-validation
procedure. This is useful for finding the best set of parameters for a
prediction algorithm. It is analogous to <a class="reference external" href="http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html">GridSearchCV</a> from scikit-learn.</p>
<p>See an example in the <a class="reference internal" href="getting_started.html#tuning-algorithm-parameters"><span class="std std-ref">User Guide</span></a>.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>algo_class</strong> (<a class="reference internal" href="algobase.html#surprise.prediction_algorithms.algo_base.AlgoBase" title="surprise.prediction_algorithms.algo_base.AlgoBase"><code class="xref py py-obj docutils literal notranslate"><span class="pre">AlgoBase</span></code></a>) – The class
of the algorithm to evaluate.</li>
<li><strong>param_grid</strong> (<em>dict</em>) – Dictionary with algorithm parameters as keys and
list of values as keys. All combinations will be evaluated with
desired algorithm. Dict parameters such as <code class="docutils literal notranslate"><span class="pre">sim_options</span></code> require
special treatment, see <a class="reference internal" href="getting_started.html#grid-search-note"><span class="std std-ref">this note</span></a>.</li>
<li><strong>measures</strong> (<em>list of string</em>) – The performance measures to compute. Allowed
names are function names as defined in the <a class="reference internal" href="accuracy.html#module-surprise.accuracy" title="surprise.accuracy"><code class="xref py py-mod docutils literal notranslate"><span class="pre">accuracy</span></code></a> module.  Default is <code class="docutils literal notranslate"><span class="pre">['rmse',</span> <span class="pre">'mae']</span></code>.</li>
<li><strong>cv</strong> (cross-validation iterator, int or <code class="docutils literal notranslate"><span class="pre">None</span></code>) – Determines how the
<code class="docutils literal notranslate"><span class="pre">data</span></code> parameter will be split (i.e. how trainsets and testsets
will be defined). If an int is passed, <a class="reference internal" href="#surprise.model_selection.split.KFold" title="surprise.model_selection.split.KFold"><code class="xref py py-class docutils literal notranslate"><span class="pre">KFold</span></code></a> is used with the
appropriate <code class="docutils literal notranslate"><span class="pre">n_splits</span></code> parameter. If <code class="docutils literal notranslate"><span class="pre">None</span></code>, <a class="reference internal" href="#surprise.model_selection.split.KFold" title="surprise.model_selection.split.KFold"><code class="xref py py-class docutils literal notranslate"><span class="pre">KFold</span></code></a> is used with
<code class="docutils literal notranslate"><span class="pre">n_splits=5</span></code>.</li>
<li><strong>refit</strong> (<em>bool</em><em> or </em><em>str</em>) – If <code class="docutils literal notranslate"><span class="pre">True</span></code>, refit the algorithm on the whole
dataset using the set of parameters that gave the best average
performance for the first measure of <code class="docutils literal notranslate"><span class="pre">measures</span></code>. Other measures
can be used by passing a string (corresponding to the measure
name). Then, you can use the <code class="docutils literal notranslate"><span class="pre">test()</span></code> and <code class="docutils literal notranslate"><span class="pre">predict()</span></code> methods.
<code class="docutils literal notranslate"><span class="pre">refit</span></code> can only be used if the <code class="docutils literal notranslate"><span class="pre">data</span></code> parameter given to
<code class="docutils literal notranslate"><span class="pre">fit()</span></code> hasn’t been loaded with <a class="reference internal" href="dataset.html#surprise.dataset.Dataset.load_from_folds" title="surprise.dataset.Dataset.load_from_folds"><code class="xref py py-meth docutils literal notranslate"><span class="pre">load_from_folds()</span></code></a>. Default is <code class="docutils literal notranslate"><span class="pre">False</span></code>.</li>
<li><strong>return_train_measures</strong> (<em>bool</em>) – Whether to compute performance measures on
the trainsets. If <code class="docutils literal notranslate"><span class="pre">True</span></code>, the <code class="docutils literal notranslate"><span class="pre">cv_results</span></code> attribute will
also contain measures for trainsets. Default is <code class="docutils literal notranslate"><span class="pre">False</span></code>.</li>
<li><strong>n_jobs</strong> (<em>int</em>) – <p>The maximum number of parallel training procedures.</p>
<ul>
<li>If <code class="docutils literal notranslate"><span class="pre">-1</span></code>, all CPUs are used.</li>
<li>If <code class="docutils literal notranslate"><span class="pre">1</span></code> is given, no parallel computing code is used at all,                which is useful for debugging.</li>
<li>For <code class="docutils literal notranslate"><span class="pre">n_jobs</span></code> below <code class="docutils literal notranslate"><span class="pre">-1</span></code>, <code class="docutils literal notranslate"><span class="pre">(n_cpus</span> <span class="pre">+</span> <span class="pre">n_jobs</span> <span class="pre">+</span> <span class="pre">1)</span></code> are                used.  For example, with <code class="docutils literal notranslate"><span class="pre">n_jobs</span> <span class="pre">=</span> <span class="pre">-2</span></code> all CPUs but one are                used.</li>
</ul>
<p>Default is <code class="docutils literal notranslate"><span class="pre">1</span></code>.</p>
</li>
<li><strong>pre_dispatch</strong> (<em>int</em><em> or </em><em>string</em>) – <p>Controls the number of jobs that get
dispatched during parallel execution. Reducing this number can be
useful to avoid an explosion of memory consumption when more jobs
get dispatched than CPUs can process. This parameter can be:</p>
<ul>
<li><code class="docutils literal notranslate"><span class="pre">None</span></code>, in which case all the jobs are immediately created                and spawned. Use this for lightweight and fast-running                jobs, to avoid delays due to on-demand spawning of the                jobs.</li>
<li>An int, giving the exact number of total jobs that are                spawned.</li>
<li>A string, giving an expression as a function of <code class="docutils literal notranslate"><span class="pre">n_jobs</span></code>,                as in <code class="docutils literal notranslate"><span class="pre">'2*n_jobs'</span></code>.</li>
</ul>
<p>Default is <code class="docutils literal notranslate"><span class="pre">'2*n_jobs'</span></code>.</p>
</li>
<li><strong>joblib_verbose</strong> (<em>int</em>) – Controls the verbosity of joblib: the higher, the
more messages.</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="attribute">
<dt id="surprise.model_selection.search.GridSearchCV.best_estimator">
<code class="descname">best_estimator</code><a class="headerlink" href="#surprise.model_selection.search.GridSearchCV.best_estimator" title="Permalink to this definition">¶</a></dt>
<dd><p>Using an accuracy measure as key, get the algorithm that gave the
best accuracy results for the chosen measure, averaged over all
splits.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Type:</th><td class="field-body">dict of AlgoBase</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="attribute">
<dt id="surprise.model_selection.search.GridSearchCV.best_score">
<code class="descname">best_score</code><a class="headerlink" href="#surprise.model_selection.search.GridSearchCV.best_score" title="Permalink to this definition">¶</a></dt>
<dd><p>Using an accuracy measure as key, get the best average score
achieved for that measure.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Type:</th><td class="field-body">dict of floats</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="attribute">
<dt id="surprise.model_selection.search.GridSearchCV.best_params">
<code class="descname">best_params</code><a class="headerlink" href="#surprise.model_selection.search.GridSearchCV.best_params" title="Permalink to this definition">¶</a></dt>
<dd><p>Using an accuracy measure as key, get the parameters combination
that gave the best accuracy results for the chosen measure (on
average).</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Type:</th><td class="field-body">dict of dicts</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="attribute">
<dt id="surprise.model_selection.search.GridSearchCV.best_index">
<code class="descname">best_index</code><a class="headerlink" href="#surprise.model_selection.search.GridSearchCV.best_index" title="Permalink to this definition">¶</a></dt>
<dd><p>Using an accuracy measure as key, get the index that can be used
with <code class="docutils literal notranslate"><span class="pre">cv_results</span></code> that achieved the highest accuracy for that
measure (on average).</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Type:</th><td class="field-body">dict of ints</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="attribute">
<dt id="surprise.model_selection.search.GridSearchCV.cv_results">
<code class="descname">cv_results</code><a class="headerlink" href="#surprise.model_selection.search.GridSearchCV.cv_results" title="Permalink to this definition">¶</a></dt>
<dd><p>A dict that contains accuracy measures over all splits, as well as
train and test time for each parameter combination. Can be imported
into a pandas <cite>DataFrame</cite> (see <a class="reference internal" href="getting_started.html#cv-results-example"><span class="std std-ref">example</span></a>).</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Type:</th><td class="field-body">dict of arrays</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="surprise.model_selection.search.GridSearchCV.fit">
<code class="descname">fit</code><span class="sig-paren">(</span><em>data</em><span class="sig-paren">)</span><a class="headerlink" href="#surprise.model_selection.search.GridSearchCV.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Runs the <code class="docutils literal notranslate"><span class="pre">fit()</span></code> method of the algorithm for all parameter
combinations, over different splits given by the <code class="docutils literal notranslate"><span class="pre">cv</span></code> parameter.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>data</strong> (<a class="reference internal" href="dataset.html#surprise.dataset.Dataset" title="surprise.dataset.Dataset"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Dataset</span></code></a>) – The dataset on
which to evaluate the algorithm, in parallel.</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="surprise.model_selection.search.GridSearchCV.predict">
<code class="descname">predict</code><span class="sig-paren">(</span><em>*args</em><span class="sig-paren">)</span><a class="headerlink" href="#surprise.model_selection.search.GridSearchCV.predict" title="Permalink to this definition">¶</a></dt>
<dd><p>Call <code class="docutils literal notranslate"><span class="pre">predict()</span></code> on the estimator with the best found parameters
(according the the <code class="docutils literal notranslate"><span class="pre">refit</span></code> parameter). See <a class="reference internal" href="algobase.html#surprise.prediction_algorithms.algo_base.AlgoBase.predict" title="surprise.prediction_algorithms.algo_base.AlgoBase.predict"><code class="xref py py-meth docutils literal notranslate"><span class="pre">AlgoBase.predict()</span></code></a>.</p>
<p>Only available if <code class="docutils literal notranslate"><span class="pre">refit</span></code> is not <code class="docutils literal notranslate"><span class="pre">False</span></code>.</p>
</dd></dl>

<dl class="method">
<dt id="surprise.model_selection.search.GridSearchCV.test">
<code class="descname">test</code><span class="sig-paren">(</span><em>testset</em>, <em>verbose=False</em><span class="sig-paren">)</span><a class="headerlink" href="#surprise.model_selection.search.GridSearchCV.test" title="Permalink to this definition">¶</a></dt>
<dd><p>Call <code class="docutils literal notranslate"><span class="pre">test()</span></code> on the estimator with the best found parameters
(according the the <code class="docutils literal notranslate"><span class="pre">refit</span></code> parameter). See <a class="reference internal" href="algobase.html#surprise.prediction_algorithms.algo_base.AlgoBase.test" title="surprise.prediction_algorithms.algo_base.AlgoBase.test"><code class="xref py py-meth docutils literal notranslate"><span class="pre">AlgoBase.test()</span></code></a>.</p>
<p>Only available if <code class="docutils literal notranslate"><span class="pre">refit</span></code> is not <code class="docutils literal notranslate"><span class="pre">False</span></code>.</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="surprise.model_selection.search.RandomizedSearchCV">
<em class="property">class </em><code class="descclassname">surprise.model_selection.search.</code><code class="descname">RandomizedSearchCV</code><span class="sig-paren">(</span><em>algo_class, param_distributions, n_iter=10, measures=['rmse', 'mae'], cv=None, refit=False, return_train_measures=False, n_jobs=1, pre_dispatch='2*n_jobs', random_state=None, joblib_verbose=0</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/surprise/model_selection/search.html#RandomizedSearchCV"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#surprise.model_selection.search.RandomizedSearchCV" title="Permalink to this definition">¶</a></dt>
<dd><p>The <a class="reference internal" href="#surprise.model_selection.search.RandomizedSearchCV" title="surprise.model_selection.search.RandomizedSearchCV"><code class="xref py py-class docutils literal notranslate"><span class="pre">RandomizedSearchCV</span></code></a> class computes accuracy metrics for an
algorithm on various combinations of parameters, over a cross-validation
procedure. As opposed to GridSearchCV, which uses an exhaustive
combinatorial approach, RandomizedSearchCV samples randomly from the
parameter space. This is useful for finding the best set of parameters
for a prediction algorithm, especially using a coarse to fine approach.
It is analogous to <a class="reference external" href="http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html">RandomizedSearchCV</a> from
scikit-learn.</p>
<p>See an example in the <a class="reference internal" href="getting_started.html#tuning-algorithm-parameters"><span class="std std-ref">User Guide</span></a>.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>algo_class</strong> (<a class="reference internal" href="algobase.html#surprise.prediction_algorithms.algo_base.AlgoBase" title="surprise.prediction_algorithms.algo_base.AlgoBase"><code class="xref py py-obj docutils literal notranslate"><span class="pre">AlgoBase</span></code></a>) – The class
of the algorithm to evaluate.</li>
<li><strong>param_distributions</strong> (<em>dict</em>) – Dictionary with algorithm parameters as
keys and distributions or lists of parameters to try. Distributions
must provide a rvs method for sampling (such as those from
scipy.stats.distributions). If a list is given, it is sampled
uniformly. Parameters will be sampled n_iter times.</li>
<li><strong>n_iter</strong> (<em>int</em>) – Number of times parameter settings are sampled. Default is
<code class="docutils literal notranslate"><span class="pre">10</span></code>.</li>
<li><strong>measures</strong> (<em>list of string</em>) – The performance measures to compute. Allowed
names are function names as defined in the <a class="reference internal" href="accuracy.html#module-surprise.accuracy" title="surprise.accuracy"><code class="xref py py-mod docutils literal notranslate"><span class="pre">accuracy</span></code></a> module.  Default is <code class="docutils literal notranslate"><span class="pre">['rmse',</span> <span class="pre">'mae']</span></code>.</li>
<li><strong>cv</strong> (cross-validation iterator, int or <code class="docutils literal notranslate"><span class="pre">None</span></code>) – Determines how the
<code class="docutils literal notranslate"><span class="pre">data</span></code> parameter will be split (i.e. how trainsets and testsets
will be defined). If an int is passed, <a class="reference internal" href="#surprise.model_selection.split.KFold" title="surprise.model_selection.split.KFold"><code class="xref py py-class docutils literal notranslate"><span class="pre">KFold</span></code></a> is used with the
appropriate <code class="docutils literal notranslate"><span class="pre">n_splits</span></code> parameter. If <code class="docutils literal notranslate"><span class="pre">None</span></code>, <a class="reference internal" href="#surprise.model_selection.split.KFold" title="surprise.model_selection.split.KFold"><code class="xref py py-class docutils literal notranslate"><span class="pre">KFold</span></code></a> is used with
<code class="docutils literal notranslate"><span class="pre">n_splits=5</span></code>.</li>
<li><strong>refit</strong> (<em>bool</em><em> or </em><em>str</em>) – If <code class="docutils literal notranslate"><span class="pre">True</span></code>, refit the algorithm on the whole
dataset using the set of parameters that gave the best average
performance for the first measure of <code class="docutils literal notranslate"><span class="pre">measures</span></code>. Other measures
can be used by passing a string (corresponding to the measure
name). Then, you can use the <code class="docutils literal notranslate"><span class="pre">test()</span></code> and <code class="docutils literal notranslate"><span class="pre">predict()</span></code> methods.
<code class="docutils literal notranslate"><span class="pre">refit</span></code> can only be used if the <code class="docutils literal notranslate"><span class="pre">data</span></code> parameter given to
<code class="docutils literal notranslate"><span class="pre">fit()</span></code> hasn’t been loaded with <a class="reference internal" href="dataset.html#surprise.dataset.Dataset.load_from_folds" title="surprise.dataset.Dataset.load_from_folds"><code class="xref py py-meth docutils literal notranslate"><span class="pre">load_from_folds()</span></code></a>. Default is <code class="docutils literal notranslate"><span class="pre">False</span></code>.</li>
<li><strong>return_train_measures</strong> (<em>bool</em>) – Whether to compute performance measures on
the trainsets. If <code class="docutils literal notranslate"><span class="pre">True</span></code>, the <code class="docutils literal notranslate"><span class="pre">cv_results</span></code> attribute will
also contain measures for trainsets. Default is <code class="docutils literal notranslate"><span class="pre">False</span></code>.</li>
<li><strong>n_jobs</strong> (<em>int</em>) – <p>The maximum number of parallel training procedures.</p>
<ul>
<li>If <code class="docutils literal notranslate"><span class="pre">-1</span></code>, all CPUs are used.</li>
<li>If <code class="docutils literal notranslate"><span class="pre">1</span></code> is given, no parallel computing code is used at all,                which is useful for debugging.</li>
<li>For <code class="docutils literal notranslate"><span class="pre">n_jobs</span></code> below <code class="docutils literal notranslate"><span class="pre">-1</span></code>, <code class="docutils literal notranslate"><span class="pre">(n_cpus</span> <span class="pre">+</span> <span class="pre">n_jobs</span> <span class="pre">+</span> <span class="pre">1)</span></code> are                used.  For example, with <code class="docutils literal notranslate"><span class="pre">n_jobs</span> <span class="pre">=</span> <span class="pre">-2</span></code> all CPUs but one are                used.</li>
</ul>
<p>Default is <code class="docutils literal notranslate"><span class="pre">1</span></code>.</p>
</li>
<li><strong>pre_dispatch</strong> (<em>int</em><em> or </em><em>string</em>) – <p>Controls the number of jobs that get
dispatched during parallel execution. Reducing this number can be
useful to avoid an explosion of memory consumption when more jobs
get dispatched than CPUs can process. This parameter can be:</p>
<ul>
<li><code class="docutils literal notranslate"><span class="pre">None</span></code>, in which case all the jobs are immediately created                and spawned. Use this for lightweight and fast-running                jobs, to avoid delays due to on-demand spawning of the                jobs.</li>
<li>An int, giving the exact number of total jobs that are                spawned.</li>
<li>A string, giving an expression as a function of <code class="docutils literal notranslate"><span class="pre">n_jobs</span></code>,                as in <code class="docutils literal notranslate"><span class="pre">'2*n_jobs'</span></code>.</li>
</ul>
<p>Default is <code class="docutils literal notranslate"><span class="pre">'2*n_jobs'</span></code>.</p>
</li>
<li><strong>random_state</strong> (<em>int</em><em>, </em><em>RandomState</em><em> or </em><em>None</em>) – Pseudo random number
generator seed used for random uniform sampling from lists of
possible values instead of scipy.stats distributions. If int,
<code class="docutils literal notranslate"><span class="pre">random_state</span></code> is the seed used by the random number generator.
If <code class="docutils literal notranslate"><span class="pre">RandomState</span></code> instance, <code class="docutils literal notranslate"><span class="pre">random_state</span></code> is the random number
generator. If <code class="docutils literal notranslate"><span class="pre">None</span></code>, the random number generator is the
RandomState instance used by <code class="docutils literal notranslate"><span class="pre">np.random</span></code>.  Default is <code class="docutils literal notranslate"><span class="pre">None</span></code>.</li>
<li><strong>joblib_verbose</strong> (<em>int</em>) – Controls the verbosity of joblib: the higher, the
more messages.</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="attribute">
<dt id="surprise.model_selection.search.RandomizedSearchCV.best_estimator">
<code class="descname">best_estimator</code><a class="headerlink" href="#surprise.model_selection.search.RandomizedSearchCV.best_estimator" title="Permalink to this definition">¶</a></dt>
<dd><p>Using an accuracy measure as key, get the algorithm that gave the
best accuracy results for the chosen measure, averaged over all
splits.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Type:</th><td class="field-body">dict of AlgoBase</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="attribute">
<dt id="surprise.model_selection.search.RandomizedSearchCV.best_score">
<code class="descname">best_score</code><a class="headerlink" href="#surprise.model_selection.search.RandomizedSearchCV.best_score" title="Permalink to this definition">¶</a></dt>
<dd><p>Using an accuracy measure as key, get the best average score
achieved for that measure.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Type:</th><td class="field-body">dict of floats</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="attribute">
<dt id="surprise.model_selection.search.RandomizedSearchCV.best_params">
<code class="descname">best_params</code><a class="headerlink" href="#surprise.model_selection.search.RandomizedSearchCV.best_params" title="Permalink to this definition">¶</a></dt>
<dd><p>Using an accuracy measure as key, get the parameters combination
that gave the best accuracy results for the chosen measure (on
average).</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Type:</th><td class="field-body">dict of dicts</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="attribute">
<dt id="surprise.model_selection.search.RandomizedSearchCV.best_index">
<code class="descname">best_index</code><a class="headerlink" href="#surprise.model_selection.search.RandomizedSearchCV.best_index" title="Permalink to this definition">¶</a></dt>
<dd><p>Using an accuracy measure as key, get the index that can be used
with <code class="docutils literal notranslate"><span class="pre">cv_results</span></code> that achieved the highest accuracy for that
measure (on average).</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Type:</th><td class="field-body">dict of ints</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="attribute">
<dt id="surprise.model_selection.search.RandomizedSearchCV.cv_results">
<code class="descname">cv_results</code><a class="headerlink" href="#surprise.model_selection.search.RandomizedSearchCV.cv_results" title="Permalink to this definition">¶</a></dt>
<dd><p>A dict that contains accuracy measures over all splits, as well as
train and test time for each parameter combination. Can be imported
into a pandas <cite>DataFrame</cite> (see <a class="reference internal" href="getting_started.html#cv-results-example"><span class="std std-ref">example</span></a>).</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Type:</th><td class="field-body">dict of arrays</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="surprise.model_selection.search.RandomizedSearchCV.fit">
<code class="descname">fit</code><span class="sig-paren">(</span><em>data</em><span class="sig-paren">)</span><a class="headerlink" href="#surprise.model_selection.search.RandomizedSearchCV.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Runs the <code class="docutils literal notranslate"><span class="pre">fit()</span></code> method of the algorithm for all parameter
combinations, over different splits given by the <code class="docutils literal notranslate"><span class="pre">cv</span></code> parameter.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>data</strong> (<a class="reference internal" href="dataset.html#surprise.dataset.Dataset" title="surprise.dataset.Dataset"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Dataset</span></code></a>) – The dataset on
which to evaluate the algorithm, in parallel.</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="surprise.model_selection.search.RandomizedSearchCV.predict">
<code class="descname">predict</code><span class="sig-paren">(</span><em>*args</em><span class="sig-paren">)</span><a class="headerlink" href="#surprise.model_selection.search.RandomizedSearchCV.predict" title="Permalink to this definition">¶</a></dt>
<dd><p>Call <code class="docutils literal notranslate"><span class="pre">predict()</span></code> on the estimator with the best found parameters
(according the the <code class="docutils literal notranslate"><span class="pre">refit</span></code> parameter). See <a class="reference internal" href="algobase.html#surprise.prediction_algorithms.algo_base.AlgoBase.predict" title="surprise.prediction_algorithms.algo_base.AlgoBase.predict"><code class="xref py py-meth docutils literal notranslate"><span class="pre">AlgoBase.predict()</span></code></a>.</p>
<p>Only available if <code class="docutils literal notranslate"><span class="pre">refit</span></code> is not <code class="docutils literal notranslate"><span class="pre">False</span></code>.</p>
</dd></dl>

<dl class="method">
<dt id="surprise.model_selection.search.RandomizedSearchCV.test">
<code class="descname">test</code><span class="sig-paren">(</span><em>testset</em>, <em>verbose=False</em><span class="sig-paren">)</span><a class="headerlink" href="#surprise.model_selection.search.RandomizedSearchCV.test" title="Permalink to this definition">¶</a></dt>
<dd><p>Call <code class="docutils literal notranslate"><span class="pre">test()</span></code> on the estimator with the best found parameters
(according the the <code class="docutils literal notranslate"><span class="pre">refit</span></code> parameter). See <a class="reference internal" href="algobase.html#surprise.prediction_algorithms.algo_base.AlgoBase.test" title="surprise.prediction_algorithms.algo_base.AlgoBase.test"><code class="xref py py-meth docutils literal notranslate"><span class="pre">AlgoBase.test()</span></code></a>.</p>
<p>Only available if <code class="docutils literal notranslate"><span class="pre">refit</span></code> is not <code class="docutils literal notranslate"><span class="pre">False</span></code>.</p>
</dd></dl>

</dd></dl>

</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="similarities.html" class="btn btn-neutral float-right" title="similarities module" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="co_clustering.html" class="btn btn-neutral" title="Co-clustering" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2015, Nicolas Hug.

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  

    <script type="text/javascript">
        var DOCUMENTATION_OPTIONS = {
            URL_ROOT:'./',
            VERSION:'1',
            LANGUAGE:'None',
            COLLAPSE_INDEX:false,
            FILE_SUFFIX:'.html',
            HAS_SOURCE:  true,
            SOURCELINK_SUFFIX: '.txt'
        };
    </script>
      <script type="text/javascript" src="_static/jquery.js"></script>
      <script type="text/javascript" src="_static/underscore.js"></script>
      <script type="text/javascript" src="_static/doctools.js"></script>
      <script type="text/javascript" src="_static/language_data.js"></script>
      <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>

  

  <script type="text/javascript" src="_static/js/theme.js"></script>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>