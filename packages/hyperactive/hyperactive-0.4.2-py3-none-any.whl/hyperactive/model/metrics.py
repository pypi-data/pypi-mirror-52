scores = [
    "accuracy_score",
    "balanced_accuracy_score",
    "average_precision_score",
    "f1_score",
    "precision_score",
    "recall_score",
    "jaccard_score",
    "roc_auc_score",
    "explained_variance_score",
    "r2_score",
]

losses = [
    "brier_score_loss",
    "log_loss",
    "max_error",
    "mean_absolute_error",
    "mean_squared_error",
    "mean_squared_log_error",
    "median_absolute_error",
]


dl_scores = [
    "accuracy",
    "binary_accuracy",
    "categorical_accuracy",
    "sparse_categorical_accuracy",
    "top_k_categorical_accuracy",
    "sparse_top_k_categorical_accuracy",
]

dl_losses = [
    "mean_squared_error",
    "mean_absolute_error",
    "mean_absolute_percentage_error",
    "mean_squared_logarithmic_error",
    "squared_hinge",
    "hinge",
    "categorical_hinge",
    "logcosh",
    "categorical_crossentropy",
    "sparse_categorical_crossentropy",
    "binary_crossentropy",
    "kullback_leibler_divergence",
    "poisson",
    "cosine_proximity",
]
